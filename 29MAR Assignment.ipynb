{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8190fa0-1e07-4413-8416-5245e0537507",
   "metadata": {},
   "source": [
    "## 29MAR\n",
    "### Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccef0347-cfb4-4602-942e-d9f7dc91e690",
   "metadata": {},
   "source": [
    "### Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47904cc3-3889-4e75-a975-ab9dcdf3fe8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is Lasso Regression, and how does it differ from other regression techniques?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de0d18e-466c-43e2-a08e-8554c3a121d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans:- Lasso Regression, also known as L1 regularization, is a type of linear regression that adds a penalty term to\n",
    "the cost function of the regression model. This penalty term is proportional to the sum of the absolute values of\n",
    "the coefficients of the independent variables. The purpose of this penalty term is to encourage the model to select\n",
    "only the most important independent variables, while setting the coefficients of the less important variables to\n",
    "zero.\n",
    "\n",
    "Lasso Regression differs from other regression techniques, such as Ridge Regression and ordinary least squares \n",
    "regression, in the way it selects the independent variables. Ridge Regression adds a penalty term that is \n",
    "proportional to the square of the coefficients, while ordinary least squares regression does not add any penalty \n",
    "term. Unlike Ridge Regression, Lasso Regression can set the coefficients of the less important independent \n",
    "variables to exactly zero, effectively removing them from the model. This makes Lasso Regression useful for feature\n",
    "selection and can lead to simpler models that are easier to interpret.\n",
    "\n",
    "Another difference is that Lasso Regression can be used for sparse data, where the number of independent variables \n",
    "is much larger than the number of observations. This is because Lasso Regression can set the coefficients of the \n",
    "less important independent variables to zero, effectively reducing the number of independent variables used in the\n",
    "model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16821db-6214-4275-a9c9-d9f68274bf13",
   "metadata": {},
   "source": [
    "### Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce8b43e-0472-48ef-9b4d-aef996dd3efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. What is the main advantage of using Lasso Regression in feature selection?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e40328-af81-4b65-a82a-4833a30c105e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans:- The main advantage of using Lasso Regression in feature selection is that it can automatically perform \n",
    "variable selection by setting the coefficients of some independent variables to zero. This allows for the\n",
    "identification of the most important predictors for a given response variable, which can lead to a more \n",
    "parsimonious and interpretable model. In contrast to other regression techniques, such as Ordinary Least Squares\n",
    "or Ridge Regression, which can only shrink the coefficient estimates towards zero, Lasso Regression can perform\n",
    "variable selection by eliminating predictors with small or no effect on the response variable. This property of \n",
    "Lasso Regression is particularly useful in situations where the number of predictors is large relative to the \n",
    "sample size, and where only a few of the predictors are expected to be important for the response variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b72b18-4229-4dd4-8d66-9d20d7301a72",
   "metadata": {},
   "source": [
    "### Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482f932e-f935-4655-b4e1-7ec5b4707c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. How do you interpret the coefficients of a Lasso Regression model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4391600-5d25-40de-9183-07940721e4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans:- In Lasso Regression, the magnitude of the coefficients can be used to interpret the importance of each \n",
    "feature in the model. The coefficients that are close to zero or equal to zero are considered to be less important\n",
    "or non-contributing to the model.\n",
    "\n",
    "The Lasso Regression model performs both regularization and feature selection by shrinking the coefficients of less\n",
    "important features to zero, which results in a simpler model with fewer features. Therefore, the non-zero \n",
    "coefficients indicate the important features that have a significant impact on the response variable.\n",
    "\n",
    "For example, if the coefficient for the variable \"age\" in a Lasso Regression model is -0.5, it means that a \n",
    "one-unit increase in age results in a 0.5-unit decrease in the response variable, holding all other features \n",
    "constant. Conversely, if the coefficient for the variable \"income\" is 0.8, it means that a one-unit increase in\n",
    "income results in a 0.8-unit increase in the response variable, holding all other features constant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b709a64-53f1-4dac-9b99-c5d3b123d0b7",
   "metadata": {},
   "source": [
    "### Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601f7406-fa91-4c56-aed0-48ec513fb6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. What are the tuning parameters that can be adjusted in Lasso Regression, and how do they affect the\n",
    "model's performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d32e93-233f-4bb4-aeb8-00a46e5aaaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans:- There are two tuning parameters in Lasso Regression that can be adjusted:\n",
    "\n",
    "=> Lambda (Î±): This is the regularization parameter that controls the strength of the penalty applied to the \n",
    "coefficients. A higher value of lambda leads to greater shrinkage of the coefficients, which can help to prevent \n",
    "overfitting but may also result in underfitting. On the other hand, a lower value of lambda results in less \n",
    "shrinkage and may lead to overfitting.\n",
    "\n",
    "=> Normalize: This parameter determines whether the independent variables should be standardized before fitting the\n",
    "model. If set to True, the independent variables are scaled to have unit variance, which can help to avoid bias due\n",
    "to differences in variable scales. However, if the variables are already on a similar scale, normalization may not\n",
    "be necessary.\n",
    "\n",
    "The value of lambda is typically chosen using cross-validation techniques, such as k-fold cross-validation or \n",
    "leave-one-out cross-validation. The optimal value of lambda is the one that results in the lowest cross-validation\n",
    "error.\n",
    "\n",
    "The choice of tuning parameters in Lasso Regression can have a significant impact on the model's performance. If\n",
    "lambda is set too high, the model may be too simple and may not capture all the relevant information in the data.\n",
    "On the other hand, if lambda is set too low, the model may be too complex and may overfit the data. The Normalize \n",
    "parameter can also affect the model's performance, as normalization may not always be necessary or appropriate for\n",
    "all datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8dcdcc3-0500-466d-8a6f-361233d15e5a",
   "metadata": {},
   "source": [
    "### Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6935949-cffb-4ce1-8e90-14208711c0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. Can Lasso Regression be used for non-linear regression problems? If yes, how?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f436c2-9154-43af-b8f9-a44cf3d98f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans:- Lasso Regression is primarily used for linear regression problems, where the relationship between the \n",
    "independent and dependent variables is assumed to be linear. However, it can also be used for non-linear regression\n",
    "problems with some modifications. One way to apply Lasso Regression to non-linear regression problems is by \n",
    "including polynomial terms or interactions between the independent variables in the model.\n",
    "\n",
    "For example, if the relationship between the dependent variable and independent variables follows a quadratic or\n",
    "cubic pattern, we can include polynomial terms in the Lasso Regression model to capture these non-linear \n",
    "relationships. Similarly, we can include interaction terms between the independent variables to capture non-linear\n",
    "interactions.\n",
    "\n",
    "However, it is important to note that adding too many polynomial or interaction terms can lead to overfitting and\n",
    "may not be appropriate for all non-linear regression problems. In such cases, other non-linear regression \n",
    "techniques like polynomial regression, spline regression, or kernel regression may be more appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497788b5-b351-4228-9f8f-c6b5646208e7",
   "metadata": {},
   "source": [
    "### Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818b6b9d-bd42-4897-ab28-efdb9c696ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. What is the difference between Ridge Regression and Lasso Regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e5240f-873e-4f49-9103-3c0003853e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans:- Ridge Regression and Lasso Regression are two popular regularization techniques used in regression analysis.\n",
    "Both methods aim to prevent overfitting by adding a penalty term to the cost function, which helps to shrink the\n",
    "coefficients towards zero.\n",
    "\n",
    "The main difference between Ridge and Lasso Regression is the type of penalty term used. Ridge Regression adds the\n",
    "sum of the squared values of the coefficients to the cost function, while Lasso Regression adds the sum of the\n",
    "absolute values of the coefficients.\n",
    "\n",
    "This difference in the penalty term has several implications for the models produced by the two methods. Ridge \n",
    "Regression tends to shrink all of the coefficients towards zero, but does not usually set any of them exactly to \n",
    "zero. This means that Ridge Regression can be useful for situations where there are many correlated variables, as \n",
    "it will tend to give non-zero coefficients to all of them.\n",
    "\n",
    "In contrast, Lasso Regression tends to produce sparse models, where many of the coefficients are exactly zero. \n",
    "This makes Lasso Regression useful for feature selection, as it can be used to identify the most important\n",
    "variables in a dataset.\n",
    "\n",
    "In summary, Ridge Regression is better suited for situations where all the variables in the dataset are potentially\n",
    "useful, while Lasso Regression is better suited for situations where some of the variables are likely to be \n",
    "irrelevant or redundant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716e52bf-97f5-4824-b5f1-99b459a87d04",
   "metadata": {},
   "source": [
    "### Q7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81956aeb-0e16-4c00-a705-d60ea097e4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7. Can Lasso Regression handle multicollinearity in the input features? If yes, how?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2717472d-f85e-4235-87c1-9e0c859b8fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans:- Yes, Lasso Regression can handle multicollinearity in the input features by automatically performing feature \n",
    "selection. When there are highly correlated independent variables, the Lasso Regression penalizes the coefficients\n",
    "of these variables, and some of them are shrunk to zero. This leads to automatic feature selection, as the \n",
    "variables with zero coefficients are effectively removed from the model. This property of Lasso Regression makes\n",
    "it useful in situations where there are many input variables, and some of them are highly correlated. By removing\n",
    "the redundant variables, Lasso Regression can simplify the model and improve its generalization performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a63b56-c14c-4b04-81e5-e11cb5eb42f5",
   "metadata": {},
   "source": [
    "### Q8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bc837d-2c02-4267-ae17-1c96306bf5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q8. How do you choose the optimal value of the regularization parameter (lambda) in Lasso Regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3a1f52-d530-4fe9-8c70-b30fe5a58e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans:- The optimal value of the regularization parameter (lambda) in Lasso Regression can be chosen using techniques\n",
    "such as cross-validation or grid search.\n",
    "\n",
    "In cross-validation, the dataset is divided into several subsets, and the model is trained on each subset while the\n",
    "other subsets are used for validation. This process is repeated for different values of lambda, and the value that\n",
    "gives the best performance on the validation set is chosen.\n",
    "\n",
    "In grid search, a set of lambda values is defined, and the model is trained and evaluated for each value of lambda.\n",
    "The value that gives the best performance is then chosen.\n",
    "\n",
    "Both techniques are useful for choosing the optimal value of lambda in Lasso Regression, but cross-validation is \n",
    "generally preferred as it is more robust and less prone to overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a4e3db-c5d2-4095-9174-ec08caee0630",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
