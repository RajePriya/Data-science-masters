{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6fa73ce-2c54-4eb4-8b25-9a4aedd5d255",
   "metadata": {},
   "source": [
    "## 7APR\n",
    "### Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a911baf4-f0a3-46dd-bcae-5536b31d3df8",
   "metadata": {},
   "source": [
    "### Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c68182b-2b58-4f8c-9bce-7516b7806487",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is the relationship between polynomial functions and kernel functions in machine learning\n",
    "algorithms?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed40993-8c8a-4019-97b4-f87e90ff13dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans:- Polynomial functions and kernel functions are related in machine learning algorithms in that polynomial \n",
    "functions can be used as a type of kernel function.\n",
    "\n",
    "Kernel functions are a fundamental component of many machine learning algorithms, particularly in kernel-based \n",
    "methods such as support vector machines (SVMs). They are used to measure the similarity between pairs of data \n",
    "points in a high-dimensional feature space, without actually computing the coordinates of the points in that space.\n",
    "\n",
    "Polynomial functions are a type of kernel function that can be used in SVMs and other kernel-based algorithms. \n",
    "Specifically, the polynomial kernel function is defined as:\n",
    "\n",
    "K(x, y) = (x^T y + c)^d\n",
    "\n",
    "where x and y are the input data points, c is a constant, and d is the degree of the polynomial. This kernel \n",
    "function computes the inner product between the feature vectors of x and y, raised to the power of d, plus a \n",
    "constant c. The polynomial kernel function allows the SVM to implicitly map the input data points into a \n",
    "high-dimensional feature space, without actually computing the coordinates of the points in that space. This is a\n",
    "useful technique for solving non-linear classification problems.\n",
    "\n",
    "In summary, polynomial functions can be used as kernel functions in machine learning algorithms, specifically as a\n",
    "type of kernel function in SVMs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c8b75a-15b8-42a7-b160-09edd0e184ea",
   "metadata": {},
   "source": [
    "### Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97afce19-7d4a-45c5-9225-b4766599ea81",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. How can we implement an SVM with a polynomial kernel in Python using Scikit-learn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994a6c06-bfa4-432a-8396-489b939018e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans:- To implement an SVM with a polynomial kernel in Python using Scikit-learn, you can follow these steps:\n",
    "\n",
    "Step 1: Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ef2b0a6-286a-4809-9831-3d6e69f36ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d2212d-eb86-496d-b194-204627b52c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Step 2: Load the dataset and split it into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88d82fbc-f3ac-49fa-9127-2a9f46e8005a",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b4a9cc-5414-4fc7-99fd-387ae0b8fff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Step 3: Initialize the SVM with a polynomial kernel and fit the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4d1889f-2f74-4312-b382-d143735a1f2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=5, coef0=1, kernel=&#x27;poly&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=5, coef0=1, kernel=&#x27;poly&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=5, coef0=1, kernel='poly')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_poly = SVC(kernel='poly', degree=3, coef0=1, C=5)\n",
    "svm_poly.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6644bfba-a0b9-4bef-9420-f3e7fab4988f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Here, we have used the SVC class from Scikit-learn, and specified the kernel to be 'poly' to use a polynomial \n",
    "kernel. We have also specified the degree of the polynomial kernel to be 3, and the coefficient of the kernel \n",
    "function to be 1. We have set the regularization parameter C to be 5.\n",
    "\n",
    "Step 4: Predict the labels for the testing set and compute the accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d5c0366-892d-48e5-b886-74e5745cae43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "y_pred = svm_poly.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7bde2f-a7b9-4754-a648-8abd1f7967e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Here, we have used the predict method of the SVM object to predict the labels for the testing set, and computed the \n",
    "accuracy score using the accuracy_score function from Scikit-learn.\n",
    "\n",
    "You can modify the values of the degree and coefficient parameters of the polynomial kernel function, as well as \n",
    "the regularization parameter C, to see how they affect the performance of the SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52b41b2-10a7-4c06-836f-27bc78d4fce6",
   "metadata": {},
   "source": [
    "### Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f412f1d-f50d-4a7b-954d-53cd56698508",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. How does increasing the value of epsilon affect the number of support vectors in SVR?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80d61d9-0c7b-42a4-bccb-278d3cf861e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans:- In Support Vector Regression (SVR), epsilon is a hyperparameter that controls the width of the margin around\n",
    "the regression line. Increasing the value of epsilon allows for more training examples to be within the margin or\n",
    "even on the wrong side of the margin, thus allowing for more training examples to be considered support vectors.\n",
    "\n",
    "As epsilon increases, the number of support vectors typically increases as well. This is because a larger margin \n",
    "allows for more training examples to be within the margin or on the wrong side of the margin, which means that more\n",
    "of these training examples will be classified as support vectors.\n",
    "\n",
    "However, it's important to note that the relationship between epsilon and the number of support vectors is not \n",
    "always straightforward and may depend on the specific dataset and the other hyperparameters of the SVR algorithm.\n",
    "In some cases, increasing epsilon may lead to overfitting, as the SVR algorithm may start to consider too many \n",
    "training examples as support vectors and fail to generalize well to new data.\n",
    "\n",
    "Therefore, it's important to tune the value of epsilon carefully and evaluate the performance of the SVR algorithm \n",
    "on a validation set or using cross-validation to find the optimal value of epsilon that provides good \n",
    "generalization performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a7a9c3-3640-4547-b5ca-4f93bccd4337",
   "metadata": {},
   "source": [
    "### Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d418db-ad6b-4d84-918f-1636374b9045",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. How does the choice of kernel function, C parameter, epsilon parameter, and gamma parameter\n",
    "affect the performance of Support Vector Regression (SVR)? Can you explain how each parameter works\n",
    "and provide examples of when you might want to increase or decrease its value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a50e26-658f-4ec9-8e10-4620f0bac812",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans:- The performance of Support Vector Regression (SVR) is affected by several hyperparameters, including the\n",
    "choice of kernel function, C parameter, epsilon parameter, and gamma parameter. Here's how each parameter works\n",
    "and how it affects the performance of SVR:\n",
    "\n",
    "=> Kernel function: The kernel function determines the shape of the decision boundary used in SVR. The most \n",
    "commonly used kernel functions are linear, polynomial, radial basis function (RBF), and sigmoid. Each kernel \n",
    "function has its own set of hyperparameters, such as the degree of the polynomial kernel or the width of the RBF\n",
    "kernel. Choosing the right kernel function and hyperparameters depends on the specific problem and the data at \n",
    "hand.\n",
    "\n",
    "=> C parameter: The C parameter controls the trade-off between achieving a low training error and a low testing\n",
    "error. A smaller value of C allows more training errors and a larger margin, while a larger value of C allows fewer\n",
    "training errors but a smaller margin. If the training set contains a lot of noise or outliers, it may be beneficial\n",
    "to increase the value of C to allow the SVR algorithm to fit the training data more closely.\n",
    "\n",
    "=> Epsilon parameter: The epsilon parameter controls the width of the margin around the regression line. It \n",
    "determines the size of the tube in which errors are ignored. If the value of epsilon is large, more training \n",
    "examples will be considered as support vectors, which can lead to a more flexible model. However, if epsilon is \n",
    "too large, the model may overfit the training data.\n",
    "\n",
    "=> Gamma parameter: The gamma parameter controls the influence of a single training example. A small value of gamma\n",
    "means that each training example has a large radius of influence, while a large value of gamma means that each \n",
    "training example has a smaller radius of influence. If the value of gamma is too large, the SVR algorithm may \n",
    "overfit the training data and fail to generalize well to new data.\n",
    "\n",
    "In general, the optimal values of these hyperparameters depend on the specific problem and the data at hand, and \n",
    "tuning them requires experimentation and cross-validation. For example, increasing the value of C can be helpful\n",
    "when the training set contains a lot of noise or outliers, while decreasing the value of epsilon can be helpful \n",
    "when the model is overfitting the training data. Similarly, increasing the value of gamma can be helpful when the \n",
    "data is highly non-linear and the decision boundary needs to be more flexible.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a6fff6-84c8-4655-88f8-7bc05614151e",
   "metadata": {},
   "source": [
    "### Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabe40e7-0f7d-44af-a08b-738475f27acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. Assignment:\n",
    "- Import the necessary libraries and load the dataset\n",
    "- Split the dataset into training and testing sets\n",
    "- Preprocess the data using any technique of your choice (e.g. scaling, normalization)\n",
    "- Create an instance of the SVC classifier and train it on the training data\n",
    "- hse the trained classifier to predict the labels of the testing data\n",
    "-  Evaluate the performance of the classifier using any metric of your choice (e.g. accuracy,\n",
    "precision, recall, F1-score)\n",
    "-  Tune the hyperparameters of the SVC classifier using GridSearchCV or RandomizedSearchCV to\n",
    "improve its performance\n",
    "-  Train the tuned classifier on the entire dataset\n",
    "-  Save the trained classifier to a file for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73801b01-e728-4cda-a120-633197aa7a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans:- To implement the steps mentioned in the assignment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf02813-f6c2-488f-aa12-3a8ae3565484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('iris.csv')\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, :-1], data.iloc[:, -1], test_size=0.3, random_state=42)\n",
    "\n",
    "# Preprocess the data using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Create an instance of the SVC classifier and train it on the training data\n",
    "clf = SVC(kernel='rbf', random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Use the trained classifier to predict the labels of the testing data\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the classifier using accuracy score\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", acc)\n",
    "\n",
    "# Tune the hyperparameters of the SVC classifier using GridSearchCV to improve its performance\n",
    "param_grid = {'C': [0.1, 1, 10], 'gamma': [0.1, 1, 10], 'kernel': ['rbf', 'poly', 'sigmoid']}\n",
    "grid = GridSearchCV(SVC(), param_grid, verbose=3)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Train the tuned classifier on the entire dataset\n",
    "clf_tuned = grid.best_estimator_\n",
    "clf_tuned.fit(scaler.transform(data.iloc[:, :-1]), data.iloc[:, -1])\n",
    "\n",
    "# Save the trained classifier to a file for future use\n",
    "joblib.dump(clf_tuned, 'iris_svc.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754bc523-5378-46e2-9eb1-d6bb9f7f87cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
