{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "760598d4",
   "metadata": {},
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39868f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. Install and load the latest versions of TensorFlow and Keras. Print their versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19fd6268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\hp\\anaconda3\\lib\\site-packages (2.13.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.13.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.56.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.23.4)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (21.3)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.3.0)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (63.4.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.13.0->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.26.11)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2022.9.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80086989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\hp\\anaconda3\\lib\\site-packages (2.13.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "085800c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.13.0\n",
      "Keras version: 2.13.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Keras version:\", keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d95045",
   "metadata": {},
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c22c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. Load the Wine Quality dataset and explore its dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a50baa48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples (rows): 178\n",
      "Number of features (columns): 13\n",
      "Number of target labels: 3\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "\n",
    "# Load the Wine dataset\n",
    "wine_data = load_wine()\n",
    "\n",
    "# Explore the dimensions of the dataset\n",
    "data, target = wine_data.data, wine_data.target\n",
    "rows, columns = data.shape\n",
    "\n",
    "print(\"Number of samples (rows):\", rows)\n",
    "print(\"Number of features (columns):\", columns)\n",
    "print(\"Number of target labels:\", len(set(target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcbf8c0",
   "metadata": {},
   "source": [
    "# Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed882ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. Check for null values, identify categorical variables, and encode them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf3f36cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values in the dataset:\n",
      " alcohol                         0\n",
      "malic_acid                      0\n",
      "ash                             0\n",
      "alcalinity_of_ash               0\n",
      "magnesium                       0\n",
      "total_phenols                   0\n",
      "flavanoids                      0\n",
      "nonflavanoid_phenols            0\n",
      "proanthocyanins                 0\n",
      "color_intensity                 0\n",
      "hue                             0\n",
      "od280/od315_of_diluted_wines    0\n",
      "proline                         0\n",
      "target                          0\n",
      "dtype: int64\n",
      "\n",
      "Updated Wine dataset:\n",
      "    alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
      "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
      "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
      "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
      "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
      "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
      "\n",
      "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
      "0        3.06                  0.28             2.29             5.64  1.04   \n",
      "1        2.76                  0.26             1.28             4.38  1.05   \n",
      "2        3.24                  0.30             2.81             5.68  1.03   \n",
      "3        3.49                  0.24             2.18             7.80  0.86   \n",
      "4        2.69                  0.39             1.82             4.32  1.04   \n",
      "\n",
      "   od280/od315_of_diluted_wines  proline  target  \n",
      "0                          3.92   1065.0       0  \n",
      "1                          3.40   1050.0       0  \n",
      "2                          3.17   1185.0       0  \n",
      "3                          3.45   1480.0       0  \n",
      "4                          2.93    735.0       0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the Wine dataset\n",
    "wine_data = load_wine()\n",
    "\n",
    "# Convert the data and target into a pandas DataFrame\n",
    "wine_df = pd.DataFrame(data=wine_data.data, columns=wine_data.feature_names)\n",
    "wine_df['target'] = wine_data.target\n",
    "\n",
    "# Check for null values\n",
    "print(\"Null values in the dataset:\\n\", wine_df.isnull().sum())\n",
    "\n",
    "# Identify categorical variables\n",
    "categorical_vars = ['target']  # The 'target' column is the categorical variable in this dataset\n",
    "\n",
    "# Encode categorical variables using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "for var in categorical_vars:\n",
    "    wine_df[var] = label_encoder.fit_transform(wine_df[var])\n",
    "\n",
    "# Display the updated dataset\n",
    "print(\"\\nUpdated Wine dataset:\\n\", wine_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96437245",
   "metadata": {},
   "source": [
    "# Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6bb8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. Separate the features and target variables from the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6083bd88",
   "metadata": {},
   "source": [
    "Ans:-\n",
    "    \n",
    "    To separate the features and target variables from the Wine dataset, we need to split the dataset into two parts: one containing the input features (independent variables) and another containing the target variable (dependent variable). In the case of the Wine dataset, the input features are the columns representing the wine characteristics, and the target variable is the column representing the wine type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c77d66cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features (Input variables):\n",
      "    alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
      "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
      "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
      "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
      "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
      "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
      "\n",
      "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
      "0        3.06                  0.28             2.29             5.64  1.04   \n",
      "1        2.76                  0.26             1.28             4.38  1.05   \n",
      "2        3.24                  0.30             2.81             5.68  1.03   \n",
      "3        3.49                  0.24             2.18             7.80  0.86   \n",
      "4        2.69                  0.39             1.82             4.32  1.04   \n",
      "\n",
      "   od280/od315_of_diluted_wines  proline  \n",
      "0                          3.92   1065.0  \n",
      "1                          3.40   1050.0  \n",
      "2                          3.17   1185.0  \n",
      "3                          3.45   1480.0  \n",
      "4                          2.93    735.0  \n",
      "\n",
      "Target (Output variable):\n",
      " 0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: wine_type, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "# Load the Wine dataset\n",
    "wine_data = load_wine()\n",
    "\n",
    "# Separate the features (input variables) and target (output variable) from the dataset\n",
    "features = pd.DataFrame(data=wine_data.data, columns=wine_data.feature_names)\n",
    "target = pd.Series(wine_data.target, name='wine_type')\n",
    "\n",
    "# Display the features and target variables\n",
    "print(\"Features (Input variables):\\n\", features.head())\n",
    "print(\"\\nTarget (Output variable):\\n\", target.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7a1f91",
   "metadata": {},
   "source": [
    " we use the \"Wine\" dataset provided by scikit-learn. We load the data and target into pandas DataFrame and Series, respectively. The wine_data.data contains the input features, and the wine_data.target contains the target variable (wine type).\n",
    "\n",
    "The features DataFrame contains the input features, and the target Series contains the wine type, which is the target variable. We display the first few rows of each to visualize the separation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77d48df",
   "metadata": {},
   "source": [
    "# Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6738b522",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. Perform a train-test split, dividing the data into training, validation, and test datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a0b12f",
   "metadata": {},
   "source": [
    "Ans:-\n",
    "    \n",
    "    To perform a train-test split and divide the data into training, validation, and test datasets, we can use the train_test_split function from scikit-learn. This function allows us to split the data into multiple subsets with specified proportions. Typically, the data is split into a training set, a validation set (used for hyperparameter tuning and model selection), and a test set (used for final evaluation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aee30088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data - X_train: (142, 13) y_train: (142,)\n",
      "Validation data - X_val: (18, 13) y_val: (18,)\n",
      "Test data - X_test: (18, 13) y_test: (18,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the Wine dataset\n",
    "wine_data = load_wine()\n",
    "\n",
    "# Separate the features (input variables) and target (output variable) from the dataset\n",
    "features = pd.DataFrame(data=wine_data.data, columns=wine_data.feature_names)\n",
    "target = pd.Series(wine_data.target, name='wine_type')\n",
    "\n",
    "# Perform the train-test split\n",
    "# Split the data into training and temporary data (validation + test)\n",
    "X_train_temp, X_test, y_train_temp, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split the temporary data (validation + test) into validation and test sets\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "# Display the dimensions of the datasets\n",
    "print(\"Training data - X_train:\", X_train_temp.shape, \"y_train:\", y_train_temp.shape)\n",
    "print(\"Validation data - X_val:\", X_val.shape, \"y_val:\", y_val.shape)\n",
    "print(\"Test data - X_test:\", X_test.shape, \"y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de89aef7",
   "metadata": {},
   "source": [
    "we first load the \"Wine\" dataset using scikit-learn and separate the features and target variables.\n",
    "\n",
    "Next, we perform the train-test split in two steps:\n",
    "\n",
    "1. First, we split the original data into training and temporary data, using 80% for training and 20% for the temporary data (validation + test).\n",
    "\n",
    "2. Then, we split the temporary data into validation and test sets, each using 50% of the temporary data.\n",
    "\n",
    "As a result, we obtain three sets: the training set (X_train_temp, y_train_temp), the validation set (X_val, y_val), and the test set (X_test, y_test).\n",
    "\n",
    "The test_size parameter in the train_test_split function specifies the proportion of data to include in the test (or validation) set. The random_state parameter is used to ensure reproducibility of the split, so you may choose any integer value for it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fdf26c",
   "metadata": {},
   "source": [
    "# Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd62f18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. Scale the dataset using an appropriate scaling technique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad3e4ac",
   "metadata": {},
   "source": [
    "Ans:-\n",
    "    \n",
    "    To scale the dataset, we can use an appropriate scaling technique to ensure that all the features are on a similar scale. Scaling is important for many machine learning algorithms, especially those based on distance calculations or gradient-based optimization, as it helps improve convergence and performance. In this example, we will use the Min-Max scaling technique to scale the features to a specific range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfcdc7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled training data:\n",
      " [[0.87105263 0.16089613 0.71657754 ... 0.07317073 0.25274725 0.30102443]\n",
      " [0.39473684 0.94093686 0.68449198 ... 0.27642276 0.15384615 0.18676123]\n",
      " [0.35263158 0.03665988 0.39572193 ... 0.45528455 0.54945055 0.30102443]\n",
      " ...\n",
      " [0.88157895 0.19959267 0.54545455 ... 0.58536585 0.63369963 1.        ]\n",
      " [0.43684211 0.13034623 0.48128342 ... 0.3902439  0.28937729 0.17100079]\n",
      " [0.34473684 0.31771894 0.58823529 ... 0.2601626  0.77289377 0.12608353]]\n",
      "\n",
      "Scaled validation data:\n",
      " [[ 0.65        0.45417515  0.67379679  0.69072165  0.57608696  0.14482759\n",
      "   0.25949367  0.16981132  0.26265823  0.60923623  0.08943089  0.01098901\n",
      "   0.1749409 ]\n",
      " [ 0.83684211  0.64154786  0.57754011  0.42783505  0.44565217  0.64482759\n",
      "   0.48734177  0.32075472  0.26265823  0.31083481  0.31707317  0.75457875\n",
      "   0.6319937 ]\n",
      " [ 0.45789474  0.30549898  0.49197861  0.45876289  0.17391304  0.14137931\n",
      "   0.03586498  0.66037736  0.06962025  0.72468908  0.07317073  0.13186813\n",
      "   0.15130024]\n",
      " [ 0.5         0.3910387   0.71657754  0.53608247  0.2826087   0.19310345\n",
      "   0.03375527  0.75471698  0.10443038  0.25399645  0.23577236  0.38095238\n",
      "   0.2537431 ]\n",
      " [ 0.67105263  0.15682281  0.53475936  0.43814433  0.39130435  0.64827586\n",
      "   0.60126582  0.16981132  0.48417722  0.45825933  0.49593496  0.58974359\n",
      "   0.97478329]\n",
      " [ 0.71052632  0.12423625  0.71657754  0.61340206  0.33695652  0.69655172\n",
      "   0.61392405  0.30188679  0.62025316  0.35168739  0.57723577  0.52747253\n",
      "   0.79353822]\n",
      " [ 0.56052632  0.54582485  0.42245989  0.53608247  0.34782609  0.17931034\n",
      "   0.0443038   0.56603774  0.27848101  0.20071048  0.09756098  0.15018315\n",
      "   0.43498818]\n",
      " [ 0.62368421  0.75560081  0.80213904  0.74226804  0.45652174  0.34482759\n",
      "   0.13080169  0.26415094  0.21835443  0.60035524  0.15447154  0.23809524\n",
      "   0.27738377]\n",
      " [ 0.35263158  0.06517312  0.64171123  0.38659794  0.30434783  0.49655172\n",
      "   0.48734177  0.45283019  0.52531646  0.25399645  0.57723577  0.37728938\n",
      "   0.31520883]\n",
      " [ 0.65        0.18737271  0.6684492   0.48453608  0.2826087   0.53448276\n",
      "   0.47890295  0.28301887  0.39240506  0.15808171  0.5203252   0.93406593\n",
      "   0.44680851]\n",
      " [ 0.34210526  0.04276986  0.49197861  0.27835052  0.33695652  0.36896552\n",
      "   0.15822785  0.94339623 -0.00316456  0.13587922  0.62601626  0.14652015\n",
      "   0.31678487]\n",
      " [ 0.74473684  0.09368635  0.48663102  0.27835052  0.30434783  0.68965517\n",
      "   0.592827    0.16981132  0.45253165  0.48667851  0.43089431  0.83516484\n",
      "   0.60441292]\n",
      " [ 0.72368421  0.3808554   0.5026738   0.58762887  0.2173913   0.12758621\n",
      "   0.07172996  0.52830189  0.19303797  0.69626998  0.17886179  0.15018315\n",
      "   0.26556344]\n",
      " [ 0.25526316  0.51731161  0.34224599  0.43298969  0.18478261  0.35172414\n",
      "   0.2742616   0.45283019  0.45886076 -0.04085258  0.36585366  0.65201465\n",
      "   0.22537431]\n",
      " [ 0.83157895  0.14256619  0.59893048  0.30412371  0.41304348  0.8\n",
      "   0.75738397  0.35849057  0.4556962   0.61811723  0.6097561   0.56776557\n",
      "   1.10480693]\n",
      " [ 0.62368421  0.61507128  0.59893048  0.63917526  0.34782609  0.28275862\n",
      "   0.08649789  0.56603774  0.31329114  0.4937833   0.17886179  0.10622711\n",
      "   0.37194641]\n",
      " [ 0.68421053  0.18737271  0.71657754  0.34020619  0.45652174  0.64482759\n",
      "   0.54219409  0.32075472  0.32911392  0.4937833   0.6504065   0.58974359\n",
      "   0.81323877]\n",
      " [ 0.27631579  0.19144603  0.51336898  0.40721649  0.11956522  0.2137931\n",
      "   0.24472574  0.73584906  0.38607595  0.05861456  0.48780488  0.36630037\n",
      "   0.15918046]]\n",
      "\n",
      "Scaled test data:\n",
      " [[ 0.75        0.20366599  0.65775401  0.22680412  0.33695652  0.78275862\n",
      "   0.67932489  0.0754717   0.40506329  0.3277087   0.32520325  0.83882784\n",
      "   0.64381403]\n",
      " [ 0.45789474  0.51731161  0.3315508   0.27835052  0.10869565  0.22413793\n",
      "   0.19198312  0.56603774  0.12974684  0.14742451  0.17886179  0.31135531\n",
      "   0.07407407]\n",
      " [ 0.36578947  0.14663951  0.44385027  0.61340206  0.41304348  0.35172414\n",
      "   0.36919831  0.39622642  0.37658228  0.02841918  0.47154472  0.61904762\n",
      "   0.05279748]\n",
      " [ 0.78684211  0.16089613  0.45454545  0.27835052  0.2826087   0.57586207\n",
      "   0.41983122  0.24528302  0.49367089  0.26287744  0.45528455  0.84981685\n",
      "   0.5965327 ]\n",
      " [ 0.1        -0.0305499   0.60962567  0.53608247  0.19565217  0.51724138\n",
      "   0.35232068  0.54716981  0.32278481  0.11900533  0.50406504  0.38095238\n",
      "   0.12293144]\n",
      " [ 0.35263158  0.15071283  0.5026738   0.71649485  0.19565217  0.42758621\n",
      "   0.44514768  0.50943396  0.46835443  0.03374778  0.33333333  0.55311355\n",
      "   0.05043341]\n",
      " [ 0.54736842  0.02443992  0.18181818  0.22680412  0.08695652  0.68965517\n",
      "   0.59915612  0.24528302  0.58860759  0.31616341  0.5203252   0.6996337\n",
      "   0.17651694]\n",
      " [ 0.62631579  0.60081466  0.40641711  0.42268041  0.2173913   0.50689655\n",
      "   0.49367089  0.26415094  0.33544304  0.22557726  0.3495935   0.63369963\n",
      "   0.5965327 ]\n",
      " [ 0.15263158  0.09368635  0.71657754  0.48453608  0.26086957  0.60689655\n",
      "   0.5443038   0.30188679  0.65506329  0.08081705  0.3902439   0.72893773\n",
      "   0.31678487]\n",
      " [ 0.27631579  0.04887984  0.61497326  0.69072165  0.08695652  0.35172414\n",
      "   0.26160338  0.50943396  0.31012658  0.04085258  0.67479675  0.53113553\n",
      "   0.27738377]\n",
      " [ 0.61315789  0.3401222   0.52941176  0.48453608  0.20652174  0.14482759\n",
      "   0.03375527  0.45283019  0.06962025  0.34280639  0.17886179  0.43956044\n",
      "   0.39558708]\n",
      " [ 0.71578947  0.17107943  0.56149733  0.27835052  0.20652174  0.55862069\n",
      "   0.51054852  0.30188679  0.43987342  0.34280639  0.54471545  0.5970696\n",
      "   0.82111899]\n",
      " [ 0.68684211  0.45010183  0.64171123  0.2371134   0.5         0.59310345\n",
      "   0.56751055  0.0754717   0.39240506  0.29840142  0.3902439   0.76556777\n",
      "   0.44680851]\n",
      " [ 0.35263158  0.05702648  0.29946524  0.46391753  0.08695652  0.38965517\n",
      "   0.35021097  0.26415094  0.19620253  0.26110124  0.5203252   0.80952381\n",
      "   0.18282112]\n",
      " [ 0.66578947  0.17107943  0.58823529  0.51030928  0.5         0.68275862\n",
      "   0.51476793  0.13207547  0.64240506  0.40053286  0.40650407  0.64468864\n",
      "   0.66351458]\n",
      " [ 0.39210526  0.31364562  0.43315508  0.53608247  0.19565217  0.54137931\n",
      "   0.407173    0.24528302  0.25316456  0.02309059  0.34146341  0.55311355\n",
      "   0.03703704]\n",
      " [ 0.27631579  0.10183299  0.60962567  0.61340206  0.15217391  0.54482759\n",
      "   0.41139241  0.56603774  0.19620253  0.10301954  0.36585366  0.7032967\n",
      "   0.08431836]\n",
      " [ 0.86052632  0.20977597  0.72727273  0.48453608  0.54347826  0.62758621\n",
      "   0.5907173   0.37735849  0.49050633  0.39609236  0.4796748   0.50549451\n",
      "   0.78959811]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load the Wine dataset\n",
    "wine_data = load_wine()\n",
    "\n",
    "# Separate the features (input variables) and target (output variable) from the dataset\n",
    "features = pd.DataFrame(data=wine_data.data, columns=wine_data.feature_names)\n",
    "target = pd.Series(wine_data.target, name='wine_type')\n",
    "\n",
    "# Perform the train-test split (same code as before)\n",
    "X_train_temp, X_test, y_train_temp, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "# Scale the features using Min-Max scaling\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_temp)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Display the scaled features\n",
    "print(\"Scaled training data:\\n\", X_train_scaled)\n",
    "print(\"\\nScaled validation data:\\n\", X_val_scaled)\n",
    "print(\"\\nScaled test data:\\n\", X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78391ab4",
   "metadata": {},
   "source": [
    "we first load the \"Wine\" dataset using scikit-learn and separate the features and target variables as before. Then, we perform the train-test split, which we did in the previous example.\n",
    "\n",
    "Next, we use the MinMaxScaler from scikit-learn to perform Min-Max scaling on the features. The MinMaxScaler scales each feature to a specified range, typically [0, 1], preserving the original data distribution. It calculates the minimum and maximum values of each feature in the training data and uses them to perform the scaling.\n",
    "\n",
    "After scaling, we obtain three sets of scaled features: X_train_scaled, X_val_scaled, and X_test_scaled. These scaled feature sets can now be used in machine learning algorithms for improved performance and better convergence. Remember that scaling should be applied only to the input features, not the target variable (output)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe4f385",
   "metadata": {},
   "source": [
    "# Q7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d2bb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7. Design and implement at least two hidden layers and an output layer for the binary categorical\n",
    "variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b12d4c3",
   "metadata": {},
   "source": [
    "Ans:-\n",
    "     Design and implement a neural network with two hidden layers and an output layer for binary categorical variables using Keras. For this example, we will use the \"Wine\" dataset and perform binary classification to predict whether a wine is of high quality or not. We will consider wines with a quality score of 7 or higher as high-quality wines (positive class) and wines with a quality score lower than 7 as non-high-quality wines (negative class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c81aa784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 16)                224       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 369 (1.44 KB)\n",
      "Trainable params: 369 (1.44 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 2s 105ms/step - loss: 0.7382 - accuracy: 0.4085 - val_loss: 0.7269 - val_accuracy: 0.3889\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.7239 - accuracy: 0.4437 - val_loss: 0.7145 - val_accuracy: 0.4444\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.7110 - accuracy: 0.4789 - val_loss: 0.7038 - val_accuracy: 0.4444\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.6988 - accuracy: 0.4859 - val_loss: 0.6948 - val_accuracy: 0.4444\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.6889 - accuracy: 0.4789 - val_loss: 0.6873 - val_accuracy: 0.3889\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.6796 - accuracy: 0.4859 - val_loss: 0.6801 - val_accuracy: 0.3889\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.6718 - accuracy: 0.4789 - val_loss: 0.6727 - val_accuracy: 0.3889\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.6643 - accuracy: 0.4789 - val_loss: 0.6641 - val_accuracy: 0.3889\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.6571 - accuracy: 0.4859 - val_loss: 0.6539 - val_accuracy: 0.3889\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.6480 - accuracy: 0.4930 - val_loss: 0.6433 - val_accuracy: 0.3889\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.6373 - accuracy: 0.5070 - val_loss: 0.6288 - val_accuracy: 0.3889\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.6220 - accuracy: 0.5070 - val_loss: 0.6052 - val_accuracy: 0.3889\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.6017 - accuracy: 0.5070 - val_loss: 0.5687 - val_accuracy: 0.3889\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.5737 - accuracy: 0.5000 - val_loss: 0.5277 - val_accuracy: 0.3889\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.5396 - accuracy: 0.4859 - val_loss: 0.4859 - val_accuracy: 0.3333\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5041 - accuracy: 0.4648 - val_loss: 0.4465 - val_accuracy: 0.3333\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.4687 - accuracy: 0.4648 - val_loss: 0.4068 - val_accuracy: 0.3333\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.4357 - accuracy: 0.4507 - val_loss: 0.3666 - val_accuracy: 0.3333\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.4017 - accuracy: 0.4507 - val_loss: 0.3240 - val_accuracy: 0.3333\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.3662 - accuracy: 0.4507 - val_loss: 0.2822 - val_accuracy: 0.3333\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.3334 - accuracy: 0.4366 - val_loss: 0.2373 - val_accuracy: 0.3333\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.2930 - accuracy: 0.4366 - val_loss: 0.1908 - val_accuracy: 0.3333\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.2569 - accuracy: 0.4507 - val_loss: 0.1378 - val_accuracy: 0.3333\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.2152 - accuracy: 0.4507 - val_loss: 0.0843 - val_accuracy: 0.3333\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.1742 - accuracy: 0.4507 - val_loss: 0.0294 - val_accuracy: 0.3333\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.1323 - accuracy: 0.4507 - val_loss: -0.0271 - val_accuracy: 0.3333\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0884 - accuracy: 0.4507 - val_loss: -0.0872 - val_accuracy: 0.3333\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0427 - accuracy: 0.4507 - val_loss: -0.1492 - val_accuracy: 0.3333\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: -0.0041 - accuracy: 0.4507 - val_loss: -0.2149 - val_accuracy: 0.3333\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: -0.0543 - accuracy: 0.4507 - val_loss: -0.2839 - val_accuracy: 0.3333\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: -0.1088 - accuracy: 0.4577 - val_loss: -0.3573 - val_accuracy: 0.3333\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: -0.1609 - accuracy: 0.4718 - val_loss: -0.4371 - val_accuracy: 0.3333\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: -0.2243 - accuracy: 0.4859 - val_loss: -0.5170 - val_accuracy: 0.3889\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: -0.2792 - accuracy: 0.4859 - val_loss: -0.6008 - val_accuracy: 0.3889\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: -0.3457 - accuracy: 0.4930 - val_loss: -0.6865 - val_accuracy: 0.3889\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: -0.4080 - accuracy: 0.5000 - val_loss: -0.7760 - val_accuracy: 0.3889\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: -0.4769 - accuracy: 0.5000 - val_loss: -0.8688 - val_accuracy: 0.3889\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: -0.5475 - accuracy: 0.5000 - val_loss: -0.9678 - val_accuracy: 0.3889\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: -0.6149 - accuracy: 0.5000 - val_loss: -1.0714 - val_accuracy: 0.3889\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: -0.6920 - accuracy: 0.5000 - val_loss: -1.1778 - val_accuracy: 0.3889\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: -0.7681 - accuracy: 0.5352 - val_loss: -1.2889 - val_accuracy: 0.3889\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -0.8512 - accuracy: 0.5493 - val_loss: -1.4012 - val_accuracy: 0.3889\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: -0.9287 - accuracy: 0.5352 - val_loss: -1.5225 - val_accuracy: 0.3889\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: -1.0140 - accuracy: 0.5352 - val_loss: -1.6451 - val_accuracy: 0.3889\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: -1.1073 - accuracy: 0.5352 - val_loss: -1.7782 - val_accuracy: 0.3889\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: -1.2052 - accuracy: 0.5282 - val_loss: -1.9142 - val_accuracy: 0.3889\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: -1.2998 - accuracy: 0.5563 - val_loss: -2.0605 - val_accuracy: 0.3889\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: -1.4037 - accuracy: 0.5634 - val_loss: -2.2075 - val_accuracy: 0.3889\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: -1.5024 - accuracy: 0.5704 - val_loss: -2.3591 - val_accuracy: 0.3889\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: -1.6179 - accuracy: 0.5704 - val_loss: -2.5106 - val_accuracy: 0.4444\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Load the Wine dataset\n",
    "wine_data = load_wine()\n",
    "\n",
    "# Separate the features (input variables) and target (output variable) from the dataset\n",
    "features = pd.DataFrame(data=wine_data.data, columns=wine_data.feature_names)\n",
    "target = pd.Series(wine_data.target, name='wine_type')\n",
    "\n",
    "# Perform the train-test split (same code as before)\n",
    "X_train_temp, X_test, y_train_temp, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "# Scale the features using Min-Max scaling (same code as before)\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_temp)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the neural network model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first hidden layer with 16 neurons and 'relu' activation function\n",
    "model.add(Dense(16, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "\n",
    "# Add the second hidden layer with 8 neurons and 'relu' activation function\n",
    "model.add(Dense(8, activation='relu'))\n",
    "\n",
    "# Add the output layer with 1 neuron and 'sigmoid' activation function for binary classification\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "\n",
    "# Train the model on the training data\n",
    "history = model.fit(X_train_scaled, y_train_temp, epochs=50, batch_size=32, validation_data=(X_val_scaled, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff10d429",
   "metadata": {},
   "source": [
    "we first load the \"Wine\" dataset using scikit-learn and separate the features and target variables as before.\n",
    "\n",
    "Next, we create a neural network model using Keras' Sequential API. We add two hidden layers, each with Dense layers. The first hidden layer has 16 neurons, the second hidden layer has 8 neurons, and both use the ReLU activation function.\n",
    "\n",
    "For binary classification, we add an output layer with 1 neuron (as it's a binary classification problem) and use the sigmoid activation function, which squashes the output between 0 and 1, providing a probability-like output.\n",
    "\n",
    "We compile the model with the Adam optimizer, binary cross-entropy loss function (suitable for binary classification), and accuracy as the evaluation metric.\n",
    "\n",
    "After compiling the model, we print the model summary to see the architecture and number of parameters.\n",
    "\n",
    "Finally, we train the model on the training data using the fit method and validate it on the validation data. The history variable stores the training history, which we can use for visualization and analysis.\n",
    "\n",
    "You can experiment with the number of neurons in the hidden layers, the activation functions, the optimizer, or the number of epochs to see how it affects the performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c2ad46",
   "metadata": {},
   "source": [
    "# Q8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f644e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q8. Create a Sequential model in Keras and add the previously designed layers to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e371413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 16)                224       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 369 (1.44 KB)\n",
      "Trainable params: 369 (1.44 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 2s 89ms/step - loss: 0.6348 - accuracy: 0.4507 - val_loss: 0.5849 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.6058 - accuracy: 0.5211 - val_loss: 0.5527 - val_accuracy: 0.3889\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.5757 - accuracy: 0.4577 - val_loss: 0.5252 - val_accuracy: 0.2778\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.5483 - accuracy: 0.4014 - val_loss: 0.4973 - val_accuracy: 0.2222\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.5216 - accuracy: 0.4014 - val_loss: 0.4689 - val_accuracy: 0.2222\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.4946 - accuracy: 0.4014 - val_loss: 0.4395 - val_accuracy: 0.2222\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.4665 - accuracy: 0.4014 - val_loss: 0.4092 - val_accuracy: 0.2222\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.4389 - accuracy: 0.4014 - val_loss: 0.3775 - val_accuracy: 0.2222\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.4082 - accuracy: 0.4014 - val_loss: 0.3451 - val_accuracy: 0.2222\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.3816 - accuracy: 0.4014 - val_loss: 0.3099 - val_accuracy: 0.2222\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.3495 - accuracy: 0.4014 - val_loss: 0.2709 - val_accuracy: 0.2222\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.3154 - accuracy: 0.4014 - val_loss: 0.2256 - val_accuracy: 0.2222\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.2764 - accuracy: 0.4014 - val_loss: 0.1779 - val_accuracy: 0.2222\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.2385 - accuracy: 0.4014 - val_loss: 0.1282 - val_accuracy: 0.2222\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1994 - accuracy: 0.4014 - val_loss: 0.0779 - val_accuracy: 0.2222\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.1639 - accuracy: 0.4014 - val_loss: 0.0285 - val_accuracy: 0.2222\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.1254 - accuracy: 0.4014 - val_loss: -0.0185 - val_accuracy: 0.2222\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0851 - accuracy: 0.4014 - val_loss: -0.0646 - val_accuracy: 0.2222\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.0481 - accuracy: 0.4014 - val_loss: -0.1117 - val_accuracy: 0.2222\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0093 - accuracy: 0.4014 - val_loss: -0.1603 - val_accuracy: 0.2222\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -0.0289 - accuracy: 0.4014 - val_loss: -0.2111 - val_accuracy: 0.2222\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -0.0687 - accuracy: 0.4014 - val_loss: -0.2625 - val_accuracy: 0.2222\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -0.1078 - accuracy: 0.4014 - val_loss: -0.3157 - val_accuracy: 0.2222\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: -0.1494 - accuracy: 0.4014 - val_loss: -0.3695 - val_accuracy: 0.2222\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: -0.1896 - accuracy: 0.4014 - val_loss: -0.4256 - val_accuracy: 0.2222\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: -0.2328 - accuracy: 0.4014 - val_loss: -0.4812 - val_accuracy: 0.2222\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -0.2758 - accuracy: 0.4014 - val_loss: -0.5410 - val_accuracy: 0.2222\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: -0.3184 - accuracy: 0.4014 - val_loss: -0.6042 - val_accuracy: 0.2222\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: -0.3691 - accuracy: 0.4014 - val_loss: -0.6680 - val_accuracy: 0.2222\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -0.4169 - accuracy: 0.4014 - val_loss: -0.7341 - val_accuracy: 0.2222\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: -0.4642 - accuracy: 0.4014 - val_loss: -0.8044 - val_accuracy: 0.2222\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: -0.5192 - accuracy: 0.4014 - val_loss: -0.8766 - val_accuracy: 0.2222\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -0.5716 - accuracy: 0.4014 - val_loss: -0.9537 - val_accuracy: 0.2222\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -0.6282 - accuracy: 0.4014 - val_loss: -1.0341 - val_accuracy: 0.2222\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: -0.6894 - accuracy: 0.4014 - val_loss: -1.1145 - val_accuracy: 0.2222\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: -0.7477 - accuracy: 0.4085 - val_loss: -1.1988 - val_accuracy: 0.2222\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: -0.8103 - accuracy: 0.4085 - val_loss: -1.2871 - val_accuracy: 0.2222\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -0.8727 - accuracy: 0.4085 - val_loss: -1.3791 - val_accuracy: 0.2222\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: -0.9437 - accuracy: 0.4225 - val_loss: -1.4729 - val_accuracy: 0.2222\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: -1.0148 - accuracy: 0.4225 - val_loss: -1.5743 - val_accuracy: 0.2778\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: -1.0910 - accuracy: 0.4296 - val_loss: -1.6879 - val_accuracy: 0.2778\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: -1.1771 - accuracy: 0.4648 - val_loss: -1.8130 - val_accuracy: 0.2778\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: -1.2686 - accuracy: 0.4648 - val_loss: -1.9415 - val_accuracy: 0.2778\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -1.3588 - accuracy: 0.4648 - val_loss: -2.0668 - val_accuracy: 0.2778\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: -1.4525 - accuracy: 0.4648 - val_loss: -2.1987 - val_accuracy: 0.2778\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: -1.5535 - accuracy: 0.4577 - val_loss: -2.3367 - val_accuracy: 0.2778\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -1.6565 - accuracy: 0.4648 - val_loss: -2.4788 - val_accuracy: 0.2778\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: -1.7611 - accuracy: 0.4718 - val_loss: -2.6296 - val_accuracy: 0.2778\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: -1.8729 - accuracy: 0.4718 - val_loss: -2.7875 - val_accuracy: 0.2778\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: -1.9882 - accuracy: 0.4718 - val_loss: -2.9527 - val_accuracy: 0.2778\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Load the Wine dataset\n",
    "wine_data = load_wine()\n",
    "\n",
    "# Separate the features (input variables) and target (output variable) from the dataset\n",
    "features = pd.DataFrame(data=wine_data.data, columns=wine_data.feature_names)\n",
    "target = pd.Series(wine_data.target, name='wine_type')\n",
    "\n",
    "# Perform the train-test split (same code as before)\n",
    "X_train_temp, X_test, y_train_temp, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "# Scale the features using Min-Max scaling (same code as before)\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_temp)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create the Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first hidden layer with 16 neurons and 'relu' activation function\n",
    "model.add(Dense(16, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "\n",
    "# Add the second hidden layer with 8 neurons and 'relu' activation function\n",
    "model.add(Dense(8, activation='relu'))\n",
    "\n",
    "# Add the output layer with 1 neuron and 'sigmoid' activation function for binary classification\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "\n",
    "# Train the model on the training data\n",
    "history = model.fit(X_train_scaled, y_train_temp, epochs=50, batch_size=32, validation_data=(X_val_scaled, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a25921",
   "metadata": {},
   "source": [
    "The code is similar to the one in the previous answer. We create a Sequential model, and then we add the three layers (two hidden layers and one output layer) using the add() method.\n",
    "\n",
    "After adding the layers, we compile the model with the specified optimizer, loss function, and metrics, and then we print the model summary to see the architecture and number of parameters.\n",
    "\n",
    "Finally, we train the model on the training data using the fit method, similar to the previous example. The history variable stores the training history, which can be used for visualization and analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de7dff7",
   "metadata": {},
   "source": [
    "# Q9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb27578",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q9. Print the summary of the model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a2e16eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_8 (Dense)             (None, 16)                224       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 369 (1.44 KB)\n",
      "Trainable params: 369 (1.44 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Load the Wine dataset\n",
    "wine_data = load_wine()\n",
    "\n",
    "# Separate the features (input variables) and target (output variable) from the dataset\n",
    "features = pd.DataFrame(data=wine_data.data, columns=wine_data.feature_names)\n",
    "target = pd.Series(wine_data.target, name='wine_type')\n",
    "\n",
    "# Perform the train-test split (same code as before)\n",
    "X_train_temp, X_test, y_train_temp, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "# Scale the features using Min-Max scaling (same code as before)\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_temp)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create the Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first hidden layer with 16 neurons and 'relu' activation function\n",
    "model.add(Dense(16, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "\n",
    "# Add the second hidden layer with 8 neurons and 'relu' activation function\n",
    "model.add(Dense(8, activation='relu'))\n",
    "\n",
    "# Add the output layer with 1 neuron and 'sigmoid' activation function for binary classification\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b643cb97",
   "metadata": {},
   "source": [
    "This summary provides valuable information about the model's architecture, including the number of trainable parameters in each layer and the total number of trainable parameters in the entire model. It helps you understand the complexity of the model and can be useful for debugging and optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a264301",
   "metadata": {},
   "source": [
    "# Q10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8276fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q10. Set the loss function(binary_crossentropy), optimizer, and include the accuracy metric in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f29451da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_11 (Dense)            (None, 16)                224       \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 369 (1.44 KB)\n",
      "Trainable params: 369 (1.44 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 2s 100ms/step - loss: 0.7198 - accuracy: 0.4296 - val_loss: 0.7163 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.6912 - accuracy: 0.5352 - val_loss: 0.6818 - val_accuracy: 0.5000\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.6674 - accuracy: 0.5704 - val_loss: 0.6535 - val_accuracy: 0.5000\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.6467 - accuracy: 0.5282 - val_loss: 0.6314 - val_accuracy: 0.5000\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.6245 - accuracy: 0.4366 - val_loss: 0.6146 - val_accuracy: 0.4444\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.6027 - accuracy: 0.4296 - val_loss: 0.5935 - val_accuracy: 0.3333\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.5771 - accuracy: 0.4014 - val_loss: 0.5709 - val_accuracy: 0.2778\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.5488 - accuracy: 0.3944 - val_loss: 0.5443 - val_accuracy: 0.2222\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.5191 - accuracy: 0.4014 - val_loss: 0.5113 - val_accuracy: 0.2222\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.4895 - accuracy: 0.4014 - val_loss: 0.4756 - val_accuracy: 0.2222\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.4594 - accuracy: 0.4014 - val_loss: 0.4402 - val_accuracy: 0.2222\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.4308 - accuracy: 0.4014 - val_loss: 0.4042 - val_accuracy: 0.2222\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.3998 - accuracy: 0.4014 - val_loss: 0.3683 - val_accuracy: 0.2222\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.3682 - accuracy: 0.4014 - val_loss: 0.3332 - val_accuracy: 0.2222\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.3396 - accuracy: 0.4014 - val_loss: 0.2969 - val_accuracy: 0.2222\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.3130 - accuracy: 0.4014 - val_loss: 0.2599 - val_accuracy: 0.2222\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2836 - accuracy: 0.4014 - val_loss: 0.2242 - val_accuracy: 0.2222\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.2591 - accuracy: 0.4014 - val_loss: 0.1869 - val_accuracy: 0.2222\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2301 - accuracy: 0.4014 - val_loss: 0.1501 - val_accuracy: 0.2222\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2047 - accuracy: 0.4014 - val_loss: 0.1118 - val_accuracy: 0.2222\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1747 - accuracy: 0.4014 - val_loss: 0.0740 - val_accuracy: 0.2222\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1461 - accuracy: 0.4014 - val_loss: 0.0353 - val_accuracy: 0.2222\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1171 - accuracy: 0.4014 - val_loss: -0.0063 - val_accuracy: 0.2222\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0883 - accuracy: 0.4014 - val_loss: -0.0500 - val_accuracy: 0.2222\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0558 - accuracy: 0.4014 - val_loss: -0.0960 - val_accuracy: 0.2222\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0240 - accuracy: 0.4014 - val_loss: -0.1440 - val_accuracy: 0.2222\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: -0.0099 - accuracy: 0.4014 - val_loss: -0.1927 - val_accuracy: 0.2222\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: -0.0444 - accuracy: 0.4014 - val_loss: -0.2429 - val_accuracy: 0.2222\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -0.0821 - accuracy: 0.4014 - val_loss: -0.2941 - val_accuracy: 0.2222\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: -0.1206 - accuracy: 0.4014 - val_loss: -0.3494 - val_accuracy: 0.2222\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: -0.1604 - accuracy: 0.4014 - val_loss: -0.4070 - val_accuracy: 0.2222\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -0.2019 - accuracy: 0.4014 - val_loss: -0.4668 - val_accuracy: 0.2222\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: -0.2459 - accuracy: 0.4014 - val_loss: -0.5303 - val_accuracy: 0.2222\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -0.2907 - accuracy: 0.4014 - val_loss: -0.5958 - val_accuracy: 0.2222\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: -0.3394 - accuracy: 0.4014 - val_loss: -0.6620 - val_accuracy: 0.2222\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: -0.3858 - accuracy: 0.4014 - val_loss: -0.7311 - val_accuracy: 0.2222\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: -0.4389 - accuracy: 0.4014 - val_loss: -0.8012 - val_accuracy: 0.2778\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: -0.4870 - accuracy: 0.4085 - val_loss: -0.8749 - val_accuracy: 0.2778\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: -0.5414 - accuracy: 0.4225 - val_loss: -0.9490 - val_accuracy: 0.2778\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: -0.5947 - accuracy: 0.4296 - val_loss: -1.0276 - val_accuracy: 0.2778\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: -0.6508 - accuracy: 0.4366 - val_loss: -1.1102 - val_accuracy: 0.2778\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: -0.7107 - accuracy: 0.4296 - val_loss: -1.1928 - val_accuracy: 0.2778\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: -0.7702 - accuracy: 0.4225 - val_loss: -1.2811 - val_accuracy: 0.3333\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -0.8344 - accuracy: 0.4437 - val_loss: -1.3720 - val_accuracy: 0.3333\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: -0.9025 - accuracy: 0.4507 - val_loss: -1.4624 - val_accuracy: 0.3889\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -0.9662 - accuracy: 0.4507 - val_loss: -1.5584 - val_accuracy: 0.3889\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -1.0385 - accuracy: 0.4718 - val_loss: -1.6565 - val_accuracy: 0.4444\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: -1.1058 - accuracy: 0.4718 - val_loss: -1.7619 - val_accuracy: 0.4444\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: -1.1849 - accuracy: 0.4718 - val_loss: -1.8684 - val_accuracy: 0.4444\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -1.2600 - accuracy: 0.4859 - val_loss: -1.9810 - val_accuracy: 0.4444\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Load the Wine dataset\n",
    "wine_data = load_wine()\n",
    "\n",
    "# Separate the features (input variables) and target (output variable) from the dataset\n",
    "features = pd.DataFrame(data=wine_data.data, columns=wine_data.feature_names)\n",
    "target = pd.Series(wine_data.target, name='wine_type')\n",
    "\n",
    "# Perform the train-test split (same code as before)\n",
    "X_train_temp, X_test, y_train_temp, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "# Scale the features using Min-Max scaling (same code as before)\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_temp)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create the Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first hidden layer with 16 neurons and 'relu' activation function\n",
    "model.add(Dense(16, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "\n",
    "# Add the second hidden layer with 8 neurons and 'relu' activation function\n",
    "model.add(Dense(8, activation='relu'))\n",
    "\n",
    "# Add the output layer with 1 neuron and 'sigmoid' activation function for binary classification\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "\n",
    "# Train the model on the training data\n",
    "history = model.fit(X_train_scaled, y_train_temp, epochs=50, batch_size=32, validation_data=(X_val_scaled, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf911bb",
   "metadata": {},
   "source": [
    "In the compile method, we set the loss parameter to 'binary_crossentropy', as this is the appropriate loss function for binary classification tasks. For multiclass classification, you would typically use 'categorical_crossentropy'.\n",
    "\n",
    "We use the 'adam' optimizer, which is a popular choice for many neural network models due to its adaptive learning rate and momentum.\n",
    "\n",
    "Lastly, we include the metrics=['accuracy'] parameter to calculate and display the accuracy metric during training and evaluation.\n",
    "\n",
    "By setting these parameters in the compile method, you have defined the model's training configuration, and the model is now ready to be trained on your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2225abc2",
   "metadata": {},
   "source": [
    "# Q11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2479efcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q11. Compile the model with the specified loss function, optimizer, and metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3bfe6c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_14 (Dense)            (None, 16)                224       \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 369 (1.44 KB)\n",
      "Trainable params: 369 (1.44 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 2s 84ms/step - loss: 0.5677 - accuracy: 0.4014 - val_loss: 0.5370 - val_accuracy: 0.2222\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.5433 - accuracy: 0.4014 - val_loss: 0.5054 - val_accuracy: 0.2222\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5155 - accuracy: 0.4014 - val_loss: 0.4703 - val_accuracy: 0.2222\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.4870 - accuracy: 0.4014 - val_loss: 0.4302 - val_accuracy: 0.2222\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.4526 - accuracy: 0.4014 - val_loss: 0.3896 - val_accuracy: 0.2222\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.4179 - accuracy: 0.4014 - val_loss: 0.3463 - val_accuracy: 0.2222\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.3826 - accuracy: 0.4014 - val_loss: 0.3004 - val_accuracy: 0.2222\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.3454 - accuracy: 0.4014 - val_loss: 0.2533 - val_accuracy: 0.2222\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.3060 - accuracy: 0.4014 - val_loss: 0.2064 - val_accuracy: 0.2222\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.2670 - accuracy: 0.4014 - val_loss: 0.1580 - val_accuracy: 0.2222\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.2262 - accuracy: 0.4014 - val_loss: 0.1085 - val_accuracy: 0.2222\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1830 - accuracy: 0.4014 - val_loss: 0.0597 - val_accuracy: 0.2222\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1397 - accuracy: 0.4014 - val_loss: 0.0072 - val_accuracy: 0.2222\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0952 - accuracy: 0.4014 - val_loss: -0.0483 - val_accuracy: 0.2222\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0538 - accuracy: 0.4014 - val_loss: -0.1065 - val_accuracy: 0.2222\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0055 - accuracy: 0.4085 - val_loss: -0.1680 - val_accuracy: 0.2222\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: -0.0419 - accuracy: 0.4085 - val_loss: -0.2313 - val_accuracy: 0.2222\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -0.0888 - accuracy: 0.4085 - val_loss: -0.2971 - val_accuracy: 0.2222\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -0.1402 - accuracy: 0.4155 - val_loss: -0.3636 - val_accuracy: 0.2222\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: -0.1873 - accuracy: 0.4155 - val_loss: -0.4352 - val_accuracy: 0.2222\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -0.2446 - accuracy: 0.4225 - val_loss: -0.5060 - val_accuracy: 0.2222\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: -0.3005 - accuracy: 0.4225 - val_loss: -0.5815 - val_accuracy: 0.2222\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -0.3587 - accuracy: 0.4225 - val_loss: -0.6608 - val_accuracy: 0.2222\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -0.4168 - accuracy: 0.4366 - val_loss: -0.7445 - val_accuracy: 0.2222\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: -0.4821 - accuracy: 0.4437 - val_loss: -0.8313 - val_accuracy: 0.2778\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -0.5464 - accuracy: 0.4718 - val_loss: -0.9181 - val_accuracy: 0.2778\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -0.6142 - accuracy: 0.4718 - val_loss: -1.0088 - val_accuracy: 0.2778\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -0.6798 - accuracy: 0.4789 - val_loss: -1.1064 - val_accuracy: 0.2778\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: -0.7543 - accuracy: 0.5000 - val_loss: -1.2083 - val_accuracy: 0.2778\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: -0.8304 - accuracy: 0.5000 - val_loss: -1.3152 - val_accuracy: 0.3889\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: -0.9129 - accuracy: 0.5141 - val_loss: -1.4228 - val_accuracy: 0.3889\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: -0.9904 - accuracy: 0.5141 - val_loss: -1.5376 - val_accuracy: 0.3889\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: -1.0798 - accuracy: 0.5141 - val_loss: -1.6586 - val_accuracy: 0.3889\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: -1.1676 - accuracy: 0.5141 - val_loss: -1.7919 - val_accuracy: 0.3889\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -1.2623 - accuracy: 0.5141 - val_loss: -1.9447 - val_accuracy: 0.3889\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: -1.3821 - accuracy: 0.5211 - val_loss: -2.1106 - val_accuracy: 0.3889\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: -1.5016 - accuracy: 0.5211 - val_loss: -2.2895 - val_accuracy: 0.3889\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: -1.6403 - accuracy: 0.5282 - val_loss: -2.4713 - val_accuracy: 0.3889\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: -1.7720 - accuracy: 0.5282 - val_loss: -2.6688 - val_accuracy: 0.3889\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: -1.9146 - accuracy: 0.5070 - val_loss: -2.8732 - val_accuracy: 0.4444\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -2.0708 - accuracy: 0.5211 - val_loss: -3.0752 - val_accuracy: 0.4444\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -2.2192 - accuracy: 0.5211 - val_loss: -3.2881 - val_accuracy: 0.4444\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: -2.3665 - accuracy: 0.5211 - val_loss: -3.5224 - val_accuracy: 0.4444\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -2.5431 - accuracy: 0.5211 - val_loss: -3.7604 - val_accuracy: 0.4444\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -2.7213 - accuracy: 0.5282 - val_loss: -4.0080 - val_accuracy: 0.4444\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: -2.8842 - accuracy: 0.5211 - val_loss: -4.2672 - val_accuracy: 0.4444\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 64ms/step - loss: -3.0900 - accuracy: 0.5070 - val_loss: -4.5360 - val_accuracy: 0.4444\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: -3.2875 - accuracy: 0.5070 - val_loss: -4.8266 - val_accuracy: 0.4444\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: -3.5103 - accuracy: 0.5070 - val_loss: -5.1196 - val_accuracy: 0.4444\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: -3.7249 - accuracy: 0.5070 - val_loss: -5.4294 - val_accuracy: 0.4444\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Load the Wine dataset\n",
    "wine_data = load_wine()\n",
    "\n",
    "# Separate the features (input variables) and target (output variable) from the dataset\n",
    "features = pd.DataFrame(data=wine_data.data, columns=wine_data.feature_names)\n",
    "target = pd.Series(wine_data.target, name='wine_type')\n",
    "\n",
    "# Perform the train-test split (same code as before)\n",
    "X_train_temp, X_test, y_train_temp, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "# Scale the features using Min-Max scaling (same code as before)\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_temp)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create the Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first hidden layer with 16 neurons and 'relu' activation function\n",
    "model.add(Dense(16, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "\n",
    "# Add the second hidden layer with 8 neurons and 'relu' activation function\n",
    "model.add(Dense(8, activation='relu'))\n",
    "\n",
    "# Add the output layer with 1 neuron and 'sigmoid' activation function for binary classification\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model with the specified loss function, optimizer, and metrics\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "\n",
    "# Train the model on the training data\n",
    "history = model.fit(X_train_scaled, y_train_temp, epochs=50, batch_size=32, validation_data=(X_val_scaled, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe96f79",
   "metadata": {},
   "source": [
    "the model is compiled using the compile method, and the specified loss function is 'binary_crossentropy' (for binary classification). The optimizer used is 'adam', and the metric used for evaluation is 'accuracy'. With these settings, the model is ready for training on the provided Wine dataset for binary classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf0e317",
   "metadata": {},
   "source": [
    "# Q12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b80c45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q12. Fit the model to the training data using appropriate batch size and number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d34f2873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_17 (Dense)            (None, 16)                224       \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 369 (1.44 KB)\n",
      "Trainable params: 369 (1.44 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 2s 79ms/step - loss: 0.6102 - accuracy: 0.4014 - val_loss: 0.6303 - val_accuracy: 0.2222\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.5839 - accuracy: 0.4014 - val_loss: 0.6023 - val_accuracy: 0.2222\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.5547 - accuracy: 0.4014 - val_loss: 0.5679 - val_accuracy: 0.2222\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.5270 - accuracy: 0.4014 - val_loss: 0.5330 - val_accuracy: 0.2222\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.5003 - accuracy: 0.4014 - val_loss: 0.4988 - val_accuracy: 0.2222\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.4728 - accuracy: 0.4014 - val_loss: 0.4667 - val_accuracy: 0.2222\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.4481 - accuracy: 0.4014 - val_loss: 0.4359 - val_accuracy: 0.2222\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.4238 - accuracy: 0.4014 - val_loss: 0.4066 - val_accuracy: 0.2222\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.4009 - accuracy: 0.4014 - val_loss: 0.3794 - val_accuracy: 0.2222\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.3792 - accuracy: 0.4014 - val_loss: 0.3521 - val_accuracy: 0.2222\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.3579 - accuracy: 0.4014 - val_loss: 0.3246 - val_accuracy: 0.2222\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.3345 - accuracy: 0.4014 - val_loss: 0.2977 - val_accuracy: 0.2222\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.3136 - accuracy: 0.4014 - val_loss: 0.2695 - val_accuracy: 0.2222\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.2920 - accuracy: 0.4014 - val_loss: 0.2418 - val_accuracy: 0.2222\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.2693 - accuracy: 0.4014 - val_loss: 0.2148 - val_accuracy: 0.2222\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.2464 - accuracy: 0.4014 - val_loss: 0.1860 - val_accuracy: 0.2222\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.2230 - accuracy: 0.4014 - val_loss: 0.1573 - val_accuracy: 0.2222\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.2024 - accuracy: 0.4014 - val_loss: 0.1265 - val_accuracy: 0.2222\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1797 - accuracy: 0.4014 - val_loss: 0.0959 - val_accuracy: 0.2222\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.1552 - accuracy: 0.4014 - val_loss: 0.0644 - val_accuracy: 0.2222\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1327 - accuracy: 0.4014 - val_loss: 0.0305 - val_accuracy: 0.2222\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1050 - accuracy: 0.4014 - val_loss: -0.0043 - val_accuracy: 0.2222\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0774 - accuracy: 0.4014 - val_loss: -0.0417 - val_accuracy: 0.2222\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0501 - accuracy: 0.4014 - val_loss: -0.0830 - val_accuracy: 0.2222\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0205 - accuracy: 0.4014 - val_loss: -0.1268 - val_accuracy: 0.2222\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -0.0138 - accuracy: 0.4014 - val_loss: -0.1705 - val_accuracy: 0.2222\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -0.0468 - accuracy: 0.4014 - val_loss: -0.2182 - val_accuracy: 0.2222\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -0.0823 - accuracy: 0.4014 - val_loss: -0.2682 - val_accuracy: 0.2222\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -0.1187 - accuracy: 0.4014 - val_loss: -0.3235 - val_accuracy: 0.2222\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -0.1617 - accuracy: 0.4014 - val_loss: -0.3805 - val_accuracy: 0.2222\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -0.2000 - accuracy: 0.4014 - val_loss: -0.4427 - val_accuracy: 0.2222\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: -0.2477 - accuracy: 0.4014 - val_loss: -0.5068 - val_accuracy: 0.2222\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: -0.2936 - accuracy: 0.4014 - val_loss: -0.5760 - val_accuracy: 0.2222\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 50ms/step - loss: -0.3467 - accuracy: 0.4085 - val_loss: -0.6460 - val_accuracy: 0.2778\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: -0.3991 - accuracy: 0.4366 - val_loss: -0.7221 - val_accuracy: 0.3333\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: -0.4540 - accuracy: 0.4648 - val_loss: -0.8051 - val_accuracy: 0.3333\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: -0.5172 - accuracy: 0.4648 - val_loss: -0.8893 - val_accuracy: 0.3333\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: -0.5787 - accuracy: 0.4718 - val_loss: -0.9771 - val_accuracy: 0.3333\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: -0.6452 - accuracy: 0.4930 - val_loss: -1.0661 - val_accuracy: 0.3889\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -0.7120 - accuracy: 0.5070 - val_loss: -1.1585 - val_accuracy: 0.3889\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: -0.7804 - accuracy: 0.5493 - val_loss: -1.2598 - val_accuracy: 0.3889\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: -0.8579 - accuracy: 0.5493 - val_loss: -1.3649 - val_accuracy: 0.3889\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: -0.9294 - accuracy: 0.5493 - val_loss: -1.4780 - val_accuracy: 0.3889\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: -1.0135 - accuracy: 0.5493 - val_loss: -1.5912 - val_accuracy: 0.3889\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: -1.0937 - accuracy: 0.5563 - val_loss: -1.7069 - val_accuracy: 0.3889\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: -1.1783 - accuracy: 0.5704 - val_loss: -1.8253 - val_accuracy: 0.3889\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: -1.2639 - accuracy: 0.5775 - val_loss: -1.9513 - val_accuracy: 0.3889\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: -1.3558 - accuracy: 0.5775 - val_loss: -2.0805 - val_accuracy: 0.3889\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: -1.4558 - accuracy: 0.5775 - val_loss: -2.2131 - val_accuracy: 0.3889\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: -1.5512 - accuracy: 0.5775 - val_loss: -2.3588 - val_accuracy: 0.3889\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Load the Wine dataset\n",
    "wine_data = load_wine()\n",
    "\n",
    "# Separate the features (input variables) and target (output variable) from the dataset\n",
    "features = pd.DataFrame(data=wine_data.data, columns=wine_data.feature_names)\n",
    "target = pd.Series(wine_data.target, name='wine_type')\n",
    "\n",
    "# Perform the train-test split (same code as before)\n",
    "X_train_temp, X_test, y_train_temp, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "# Scale the features using Min-Max scaling (same code as before)\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_temp)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create the Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first hidden layer with 16 neurons and 'relu' activation function\n",
    "model.add(Dense(16, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "\n",
    "# Add the second hidden layer with 8 neurons and 'relu' activation function\n",
    "model.add(Dense(8, activation='relu'))\n",
    "\n",
    "# Add the output layer with 1 neuron and 'sigmoid' activation function for binary classification\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model with the specified loss function, optimizer, and metrics\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "\n",
    "# Fit the model to the training data with batch size of 32 and 50 epochs\n",
    "history = model.fit(X_train_scaled, y_train_temp, epochs=50, batch_size=32, validation_data=(X_val_scaled, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24376c7",
   "metadata": {},
   "source": [
    "the model is compiled using the compile method with the specified loss function, optimizer, and metric. Then, the fit method is used to train the model on the training data (X_train_scaled and y_train_temp) for 50 epochs with a batch size of 32. During training, the model's performance on the validation data (X_val_scaled and y_val) is also evaluated. The training history is stored in the history variable, which can be used for further analysis and visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e1f717",
   "metadata": {},
   "source": [
    "# Q13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5dcec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q13. Obtain the model's parameters (weights and biases)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19396f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_20 (Dense)            (None, 16)                224       \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 369 (1.44 KB)\n",
      "Trainable params: 369 (1.44 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 2s 85ms/step - loss: 0.6719 - accuracy: 0.3944 - val_loss: 0.6672 - val_accuracy: 0.2222\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.6331 - accuracy: 0.4014 - val_loss: 0.6302 - val_accuracy: 0.2222\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5914 - accuracy: 0.4014 - val_loss: 0.5985 - val_accuracy: 0.2222\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5558 - accuracy: 0.4014 - val_loss: 0.5632 - val_accuracy: 0.2222\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.5164 - accuracy: 0.4014 - val_loss: 0.5255 - val_accuracy: 0.2222\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.4802 - accuracy: 0.4014 - val_loss: 0.4855 - val_accuracy: 0.2222\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.4452 - accuracy: 0.4014 - val_loss: 0.4436 - val_accuracy: 0.2222\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.4061 - accuracy: 0.4014 - val_loss: 0.4033 - val_accuracy: 0.2222\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.3743 - accuracy: 0.4014 - val_loss: 0.3622 - val_accuracy: 0.2222\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.3347 - accuracy: 0.4014 - val_loss: 0.3217 - val_accuracy: 0.2222\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.3037 - accuracy: 0.4014 - val_loss: 0.2805 - val_accuracy: 0.2222\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.2688 - accuracy: 0.4014 - val_loss: 0.2383 - val_accuracy: 0.2222\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.2365 - accuracy: 0.4014 - val_loss: 0.1931 - val_accuracy: 0.2222\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.1999 - accuracy: 0.4014 - val_loss: 0.1476 - val_accuracy: 0.2222\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.1630 - accuracy: 0.4014 - val_loss: 0.0996 - val_accuracy: 0.2222\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1270 - accuracy: 0.4014 - val_loss: 0.0483 - val_accuracy: 0.2222\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0880 - accuracy: 0.4014 - val_loss: -0.0045 - val_accuracy: 0.2222\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0450 - accuracy: 0.4014 - val_loss: -0.0607 - val_accuracy: 0.2222\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0019 - accuracy: 0.4014 - val_loss: -0.1232 - val_accuracy: 0.2222\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -0.0482 - accuracy: 0.4014 - val_loss: -0.1887 - val_accuracy: 0.2222\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -0.0981 - accuracy: 0.4014 - val_loss: -0.2584 - val_accuracy: 0.2222\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: -0.1507 - accuracy: 0.4014 - val_loss: -0.3308 - val_accuracy: 0.2222\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -0.2047 - accuracy: 0.4014 - val_loss: -0.4054 - val_accuracy: 0.2222\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: -0.2644 - accuracy: 0.4014 - val_loss: -0.4821 - val_accuracy: 0.2222\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: -0.3235 - accuracy: 0.4014 - val_loss: -0.5653 - val_accuracy: 0.2222\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -0.3884 - accuracy: 0.4014 - val_loss: -0.6523 - val_accuracy: 0.2222\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -0.4523 - accuracy: 0.4014 - val_loss: -0.7470 - val_accuracy: 0.2222\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: -0.5241 - accuracy: 0.4014 - val_loss: -0.8456 - val_accuracy: 0.2222\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -0.5986 - accuracy: 0.4014 - val_loss: -0.9509 - val_accuracy: 0.2222\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -0.6707 - accuracy: 0.4014 - val_loss: -1.0650 - val_accuracy: 0.2222\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: -0.7664 - accuracy: 0.4014 - val_loss: -1.1817 - val_accuracy: 0.2222\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: -0.8543 - accuracy: 0.4014 - val_loss: -1.3061 - val_accuracy: 0.2222\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -0.9443 - accuracy: 0.4014 - val_loss: -1.4389 - val_accuracy: 0.2222\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -1.0458 - accuracy: 0.4014 - val_loss: -1.5818 - val_accuracy: 0.2222\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -1.1583 - accuracy: 0.4014 - val_loss: -1.7289 - val_accuracy: 0.2222\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: -1.2601 - accuracy: 0.4085 - val_loss: -1.8868 - val_accuracy: 0.2222\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: -1.3851 - accuracy: 0.4225 - val_loss: -2.0494 - val_accuracy: 0.2222\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: -1.5037 - accuracy: 0.4296 - val_loss: -2.2249 - val_accuracy: 0.2222\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -1.6309 - accuracy: 0.4296 - val_loss: -2.4075 - val_accuracy: 0.2222\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: -1.7697 - accuracy: 0.4366 - val_loss: -2.5983 - val_accuracy: 0.2222\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: -1.9078 - accuracy: 0.4437 - val_loss: -2.8004 - val_accuracy: 0.3889\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: -2.0540 - accuracy: 0.4648 - val_loss: -3.0065 - val_accuracy: 0.3889\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: -2.2055 - accuracy: 0.4789 - val_loss: -3.2202 - val_accuracy: 0.3889\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: -2.3595 - accuracy: 0.4859 - val_loss: -3.4489 - val_accuracy: 0.3889\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: -2.5387 - accuracy: 0.5070 - val_loss: -3.6799 - val_accuracy: 0.3889\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -2.7076 - accuracy: 0.5141 - val_loss: -3.9284 - val_accuracy: 0.3889\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -2.8975 - accuracy: 0.5141 - val_loss: -4.1838 - val_accuracy: 0.3889\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -3.0842 - accuracy: 0.5141 - val_loss: -4.4615 - val_accuracy: 0.3889\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -3.2891 - accuracy: 0.5141 - val_loss: -4.7551 - val_accuracy: 0.3889\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: -3.5021 - accuracy: 0.5141 - val_loss: -5.0638 - val_accuracy: 0.3889\n",
      "Layer 1 - Weights:\n",
      " [[ 0.24060193 -0.1461649  -0.24839792  0.47202983 -0.04627684 -0.0905847\n",
      "   0.02007404  0.292119   -0.41918954  0.00169576 -0.16295974 -0.12824555\n",
      "  -0.41056836 -0.13759243 -0.27859664  0.2942172 ]\n",
      " [ 0.5557132  -0.33766857  0.2287206   0.43316764 -0.30649644  0.54169905\n",
      "  -0.05681678  0.422046   -0.05912912  0.16717719  0.14465563  0.13591777\n",
      "   0.24216962  0.36167005  0.09935306  0.6208846 ]\n",
      " [ 0.37587318  0.47155792  0.4863247   0.22661087 -0.02445453 -0.01279562\n",
      "   0.24014065  0.51126266  0.06976902  0.35566342  0.3248329   0.2967699\n",
      "   0.46916056  0.07128173  0.2206485   0.35752675]\n",
      " [ 0.38669103 -0.43848798  0.03792622  0.1299202   0.17283905  0.11991733\n",
      "  -0.3965641  -0.08623841  0.05743116  0.24940956  0.11847902 -0.14211562\n",
      "   0.1233777   0.26667494  0.37137395  0.23940095]\n",
      " [ 0.3726038   0.09927221 -0.13654563  0.44327152 -0.34758943  0.12312553\n",
      "   0.01041042 -0.1097798   0.0597629  -0.24506937  0.03059513 -0.1198457\n",
      "  -0.01729418 -0.16982016  0.01237597  0.4810936 ]\n",
      " [ 0.30865505  0.5896702   0.2828211  -0.44940937 -0.05767462 -0.09367117\n",
      "   0.6374027   0.07882282  0.2453808   0.23399071 -0.24502318  0.10930443\n",
      "  -0.2718295   0.24305253  0.4022566  -0.32015032]\n",
      " [-0.5834038   0.4002597  -0.53262866  0.05599448 -0.13021228 -0.2351002\n",
      "   0.05571693  0.13102216  0.08920643 -0.51999086 -0.6151718  -0.41141653\n",
      "   0.06489165 -0.23471045  0.21015306 -0.41596457]\n",
      " [ 0.42481223 -0.04536477  0.4124131   0.24366273 -0.30457446  0.45900047\n",
      "  -0.06804188  0.4771725   0.211322    0.15417564  0.6683366   0.03092359\n",
      "   0.6865279   0.35088885 -0.41929567  0.40569246]\n",
      " [ 0.31806746 -0.20594846 -0.2991308  -0.48194134 -0.296144    0.42744163\n",
      "   0.5366255   0.36901566 -0.34280196 -0.06382123  0.2513955  -0.1308358\n",
      "   0.10709024 -0.20629896  0.02069318 -0.10212556]\n",
      " [ 0.12818086  0.36642307  0.31366357  0.65622884  0.28855717  0.5571492\n",
      "  -0.4778253   0.35674667 -0.24290507  0.60059285  0.23369393 -0.18945393\n",
      "  -0.11796004  0.54947895 -0.36893925 -0.16032632]\n",
      " [ 0.20334607 -0.17005962  0.17676292 -0.4654961  -0.3632816  -0.14295976\n",
      "   0.69899213 -0.04050733  0.13456273 -0.5156048   0.20075816  0.1265345\n",
      "  -0.42895526 -0.37657318 -0.36813143 -0.22700265]\n",
      " [ 0.17999302  0.43715712 -0.39315113 -0.2752526   0.15749836  0.13502105\n",
      "   0.11305927 -0.13336015 -0.08190334 -0.08368609 -0.38951042  0.12960224\n",
      "   0.18504818 -0.38500485 -0.34147358 -0.63106906]\n",
      " [-0.44981354  0.35310832  0.00184227 -0.4781388  -0.12411574  0.11108456\n",
      "   0.5927125  -0.24802981 -0.39687815 -0.32369456  0.03726789  0.06521542\n",
      "  -0.16443525  0.08377672 -0.05040289  0.11743783]]\n",
      "Layer 1 - Biases:\n",
      " [ 0.25804886  0.05844006  0.19850326  0.19503094  0.          0.24215432\n",
      "  0.04276182  0.24256104 -0.07607139  0.23401988  0.27434707 -0.02301331\n",
      "  0.19065018  0.21676122  0.13983852  0.19729657]\n",
      "Layer 2 - Weights:\n",
      " [[ 0.20311989  0.38504523 -0.47695982  0.5923008   0.36728022  0.6479205\n",
      "   0.6357866   0.06419803]\n",
      " [-0.28361544  0.17032523  0.13088655 -0.34342635  0.6569716  -0.00465161\n",
      "  -0.09958014 -0.2144825 ]\n",
      " [-0.2981328  -0.34645995  0.21642804 -0.04523069 -0.4070772   0.0405977\n",
      "   0.23572673  0.71088713]\n",
      " [-0.01036528 -0.52650404 -0.02114296 -0.04277696  0.1665476   0.46088612\n",
      "   0.7813509   0.17802888]\n",
      " [ 0.39083314  0.28914893  0.43616188  0.284348    0.37458837 -0.4333011\n",
      "  -0.09331942  0.11423349]\n",
      " [ 0.00709409  0.31405172  0.31198466 -0.14222535 -0.05883814  0.634917\n",
      "   0.7209883   0.15619192]\n",
      " [-0.49204186  0.6929345  -0.10210228 -0.33833075  0.5848837  -0.03514022\n",
      "  -0.1469928  -0.44916168]\n",
      " [-0.20230311  0.41051325 -0.4380424   0.37390783  0.18245174  0.23440939\n",
      "  -0.17447546  0.66095155]\n",
      " [-0.15523735  0.26451144  0.45213473 -0.38534448 -0.4880181  -0.35351107\n",
      "  -0.07076243 -0.31794432]\n",
      " [-0.13675146 -0.5528826  -0.37685108  0.1491976  -0.4817003   0.5066765\n",
      "   0.81499803  0.1374711 ]\n",
      " [-0.36452392 -0.05240563 -0.31960523  0.0319221  -0.34711903  0.33357224\n",
      "   0.14983475  0.7372759 ]\n",
      " [-0.26716727 -0.40681946 -0.47931647 -0.04812272  0.0862709   0.37880963\n",
      "  -0.4011289  -0.26978055]\n",
      " [ 0.42429394 -0.4078714   0.14082313  0.3074196  -0.02742418  0.70041937\n",
      "   0.44842333  0.70131516]\n",
      " [-0.4003519  -0.38484105 -0.36866665  0.6074657   0.01394772  0.6721184\n",
      "   0.7293295   0.7363701 ]\n",
      " [ 0.20024632 -0.7080443  -0.27596855  0.19439314 -0.24632524  0.29610905\n",
      "   0.35347724  0.5725542 ]\n",
      " [ 0.30776212 -0.0670968  -0.34391356  0.43828914 -0.4126561   0.1802838\n",
      "   0.23813552  0.54652876]]\n",
      "Layer 2 - Biases:\n",
      " [-0.05420289  0.04104357  0.          0.1766724   0.03109452  0.15202847\n",
      "  0.19833645  0.17219304]\n",
      "Layer 3 - Weights:\n",
      " [[-0.5831009 ]\n",
      " [-0.98207885]\n",
      " [ 0.58216465]\n",
      " [ 1.016814  ]\n",
      " [-0.6235851 ]\n",
      " [ 1.0774492 ]\n",
      " [ 0.46277785]\n",
      " [ 1.1456832 ]]\n",
      "Layer 3 - Biases:\n",
      " [0.14202979]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Load the Wine dataset\n",
    "wine_data = load_wine()\n",
    "\n",
    "# Separate the features (input variables) and target (output variable) from the dataset\n",
    "features = pd.DataFrame(data=wine_data.data, columns=wine_data.feature_names)\n",
    "target = pd.Series(wine_data.target, name='wine_type')\n",
    "\n",
    "# Perform the train-test split (same code as before)\n",
    "X_train_temp, X_test, y_train_temp, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "# Scale the features using Min-Max scaling (same code as before)\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_temp)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create the Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first hidden layer with 16 neurons and 'relu' activation function\n",
    "model.add(Dense(16, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "\n",
    "# Add the second hidden layer with 8 neurons and 'relu' activation function\n",
    "model.add(Dense(8, activation='relu'))\n",
    "\n",
    "# Add the output layer with 1 neuron and 'sigmoid' activation function for binary classification\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model with the specified loss function, optimizer, and metrics\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "\n",
    "# Fit the model to the training data with batch size of 32 and 50 epochs\n",
    "history = model.fit(X_train_scaled, y_train_temp, epochs=50, batch_size=32, validation_data=(X_val_scaled, y_val))\n",
    "\n",
    "# Obtain the model's parameters (weights and biases)\n",
    "model_params = []\n",
    "for layer in model.layers:\n",
    "    layer_params = layer.get_weights()\n",
    "    model_params.append(layer_params)\n",
    "\n",
    "# Print the model's parameters (weights and biases)\n",
    "for i, layer_params in enumerate(model_params):\n",
    "    print(f\"Layer {i+1} - Weights:\\n\", layer_params[0])\n",
    "    print(f\"Layer {i+1} - Biases:\\n\", layer_params[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94b2577",
   "metadata": {},
   "source": [
    "After training the model, we use a for loop to access each layer in the model (model.layers) and then use the get_weights() method of each layer to obtain its parameters (weights and biases). The parameters are stored in a list model_params, and we print them for each layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78adc7f9",
   "metadata": {},
   "source": [
    "# Q14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764a8222",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q14. Store the model's training history as a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32474a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_23 (Dense)            (None, 16)                224       \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 369 (1.44 KB)\n",
      "Trainable params: 369 (1.44 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 2s 81ms/step - loss: 0.6907 - accuracy: 0.3944 - val_loss: 0.7001 - val_accuracy: 0.2222\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.6417 - accuracy: 0.4014 - val_loss: 0.6516 - val_accuracy: 0.2222\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.5966 - accuracy: 0.4014 - val_loss: 0.6074 - val_accuracy: 0.2222\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.5569 - accuracy: 0.4014 - val_loss: 0.5680 - val_accuracy: 0.2222\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.5245 - accuracy: 0.4014 - val_loss: 0.5372 - val_accuracy: 0.2222\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.4964 - accuracy: 0.4014 - val_loss: 0.5094 - val_accuracy: 0.2222\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.4746 - accuracy: 0.4014 - val_loss: 0.4824 - val_accuracy: 0.2222\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.4517 - accuracy: 0.4014 - val_loss: 0.4564 - val_accuracy: 0.2222\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.4307 - accuracy: 0.4014 - val_loss: 0.4309 - val_accuracy: 0.2222\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.4064 - accuracy: 0.4014 - val_loss: 0.4053 - val_accuracy: 0.2222\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.3844 - accuracy: 0.4014 - val_loss: 0.3774 - val_accuracy: 0.2222\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.3622 - accuracy: 0.4014 - val_loss: 0.3487 - val_accuracy: 0.2222\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.3392 - accuracy: 0.4014 - val_loss: 0.3195 - val_accuracy: 0.2222\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.3148 - accuracy: 0.4014 - val_loss: 0.2895 - val_accuracy: 0.2222\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.2879 - accuracy: 0.4014 - val_loss: 0.2599 - val_accuracy: 0.2222\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.2674 - accuracy: 0.4014 - val_loss: 0.2276 - val_accuracy: 0.2222\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.2390 - accuracy: 0.4014 - val_loss: 0.1951 - val_accuracy: 0.2222\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.2111 - accuracy: 0.4014 - val_loss: 0.1595 - val_accuracy: 0.2222\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1825 - accuracy: 0.4014 - val_loss: 0.1197 - val_accuracy: 0.2222\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1496 - accuracy: 0.4014 - val_loss: 0.0766 - val_accuracy: 0.2222\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1159 - accuracy: 0.4014 - val_loss: 0.0280 - val_accuracy: 0.2222\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0774 - accuracy: 0.4014 - val_loss: -0.0208 - val_accuracy: 0.2222\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0408 - accuracy: 0.4014 - val_loss: -0.0685 - val_accuracy: 0.2222\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: -5.6580e-04 - accuracy: 0.4014 - val_loss: -0.1179 - val_accuracy: 0.2222\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -0.0378 - accuracy: 0.4014 - val_loss: -0.1725 - val_accuracy: 0.2222\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: -0.0836 - accuracy: 0.4014 - val_loss: -0.2292 - val_accuracy: 0.2222\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: -0.1273 - accuracy: 0.4014 - val_loss: -0.2900 - val_accuracy: 0.2222\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: -0.1775 - accuracy: 0.4014 - val_loss: -0.3530 - val_accuracy: 0.2222\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: -0.2247 - accuracy: 0.4014 - val_loss: -0.4207 - val_accuracy: 0.2222\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: -0.2748 - accuracy: 0.4014 - val_loss: -0.4911 - val_accuracy: 0.2222\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -0.3300 - accuracy: 0.4014 - val_loss: -0.5626 - val_accuracy: 0.2222\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -0.3885 - accuracy: 0.4014 - val_loss: -0.6360 - val_accuracy: 0.2222\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: -0.4471 - accuracy: 0.4014 - val_loss: -0.7147 - val_accuracy: 0.2222\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: -0.5049 - accuracy: 0.4014 - val_loss: -0.7992 - val_accuracy: 0.2222\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -0.5695 - accuracy: 0.4014 - val_loss: -0.8863 - val_accuracy: 0.2222\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: -0.6372 - accuracy: 0.4014 - val_loss: -0.9767 - val_accuracy: 0.2222\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -0.7051 - accuracy: 0.4014 - val_loss: -1.0728 - val_accuracy: 0.2222\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: -0.7816 - accuracy: 0.4014 - val_loss: -1.1684 - val_accuracy: 0.2222\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -0.8551 - accuracy: 0.4014 - val_loss: -1.2730 - val_accuracy: 0.2222\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: -0.9342 - accuracy: 0.4014 - val_loss: -1.3835 - val_accuracy: 0.2222\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: -1.0223 - accuracy: 0.4014 - val_loss: -1.4975 - val_accuracy: 0.2222\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: -1.1005 - accuracy: 0.4014 - val_loss: -1.6208 - val_accuracy: 0.2222\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: -1.1971 - accuracy: 0.4014 - val_loss: -1.7442 - val_accuracy: 0.2222\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: -1.2855 - accuracy: 0.4014 - val_loss: -1.8744 - val_accuracy: 0.2222\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: -1.3861 - accuracy: 0.4014 - val_loss: -2.0031 - val_accuracy: 0.2222\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: -1.4840 - accuracy: 0.4014 - val_loss: -2.1374 - val_accuracy: 0.2222\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -1.5804 - accuracy: 0.4014 - val_loss: -2.2809 - val_accuracy: 0.2222\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: -1.6950 - accuracy: 0.4014 - val_loss: -2.4247 - val_accuracy: 0.2222\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: -1.7996 - accuracy: 0.4014 - val_loss: -2.5829 - val_accuracy: 0.2222\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: -1.9287 - accuracy: 0.4014 - val_loss: -2.7418 - val_accuracy: 0.2222\n",
      "           loss  accuracy  val_loss  val_accuracy\n",
      "epoch                                            \n",
      "1      0.690718  0.394366  0.700066      0.222222\n",
      "2      0.641676  0.401408  0.651560      0.222222\n",
      "3      0.596581  0.401408  0.607450      0.222222\n",
      "4      0.556911  0.401408  0.568036      0.222222\n",
      "5      0.524516  0.401408  0.537172      0.222222\n",
      "6      0.496383  0.401408  0.509431      0.222222\n",
      "7      0.474629  0.401408  0.482401      0.222222\n",
      "8      0.451667  0.401408  0.456368      0.222222\n",
      "9      0.430664  0.401408  0.430932      0.222222\n",
      "10     0.406426  0.401408  0.405312      0.222222\n",
      "11     0.384401  0.401408  0.377399      0.222222\n",
      "12     0.362168  0.401408  0.348655      0.222222\n",
      "13     0.339163  0.401408  0.319466      0.222222\n",
      "14     0.314775  0.401408  0.289544      0.222222\n",
      "15     0.287928  0.401408  0.259857      0.222222\n",
      "16     0.267356  0.401408  0.227554      0.222222\n",
      "17     0.238975  0.401408  0.195101      0.222222\n",
      "18     0.211077  0.401408  0.159518      0.222222\n",
      "19     0.182470  0.401408  0.119679      0.222222\n",
      "20     0.149563  0.401408  0.076623      0.222222\n",
      "21     0.115927  0.401408  0.028034      0.222222\n",
      "22     0.077433  0.401408 -0.020807      0.222222\n",
      "23     0.040796  0.401408 -0.068502      0.222222\n",
      "24    -0.000566  0.401408 -0.117885      0.222222\n",
      "25    -0.037835  0.401408 -0.172505      0.222222\n",
      "26    -0.083555  0.401408 -0.229179      0.222222\n",
      "27    -0.127281  0.401408 -0.290008      0.222222\n",
      "28    -0.177492  0.401408 -0.353020      0.222222\n",
      "29    -0.224706  0.401408 -0.420690      0.222222\n",
      "30    -0.274791  0.401408 -0.491101      0.222222\n",
      "31    -0.330010  0.401408 -0.562565      0.222222\n",
      "32    -0.388524  0.401408 -0.636000      0.222222\n",
      "33    -0.447102  0.401408 -0.714701      0.222222\n",
      "34    -0.504870  0.401408 -0.799242      0.222222\n",
      "35    -0.569471  0.401408 -0.886271      0.222222\n",
      "36    -0.637236  0.401408 -0.976668      0.222222\n",
      "37    -0.705090  0.401408 -1.072785      0.222222\n",
      "38    -0.781594  0.401408 -1.168395      0.222222\n",
      "39    -0.855073  0.401408 -1.272959      0.222222\n",
      "40    -0.934158  0.401408 -1.383481      0.222222\n",
      "41    -1.022263  0.401408 -1.497502      0.222222\n",
      "42    -1.100495  0.401408 -1.620813      0.222222\n",
      "43    -1.197069  0.401408 -1.744204      0.222222\n",
      "44    -1.285481  0.401408 -1.874423      0.222222\n",
      "45    -1.386131  0.401408 -2.003087      0.222222\n",
      "46    -1.484046  0.401408 -2.137398      0.222222\n",
      "47    -1.580432  0.401408 -2.280923      0.222222\n",
      "48    -1.694984  0.401408 -2.424692      0.222222\n",
      "49    -1.799581  0.401408 -2.582877      0.222222\n",
      "50    -1.928682  0.401408 -2.741817      0.222222\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Load the Wine dataset\n",
    "wine_data = load_wine()\n",
    "\n",
    "# Separate the features (input variables) and target (output variable) from the dataset\n",
    "features = pd.DataFrame(data=wine_data.data, columns=wine_data.feature_names)\n",
    "target = pd.Series(wine_data.target, name='wine_type')\n",
    "\n",
    "# Perform the train-test split (same code as before)\n",
    "X_train_temp, X_test, y_train_temp, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "# Scale the features using Min-Max scaling (same code as before)\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_temp)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create the Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first hidden layer with 16 neurons and 'relu' activation function\n",
    "model.add(Dense(16, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "\n",
    "# Add the second hidden layer with 8 neurons and 'relu' activation function\n",
    "model.add(Dense(8, activation='relu'))\n",
    "\n",
    "# Add the output layer with 1 neuron and 'sigmoid' activation function for binary classification\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model with the specified loss function, optimizer, and metrics\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "\n",
    "# Fit the model to the training data with batch size of 32 and 50 epochs\n",
    "history = model.fit(X_train_scaled, y_train_temp, epochs=50, batch_size=32, validation_data=(X_val_scaled, y_val))\n",
    "\n",
    "# Store the model's training history as a Pandas DataFrame\n",
    "history_df = pd.DataFrame(history.history)\n",
    "\n",
    "# Add the epoch column to the DataFrame\n",
    "history_df['epoch'] = np.arange(1, len(history_df) + 1)\n",
    "\n",
    "# Set the epoch column as the index\n",
    "history_df.set_index('epoch', inplace=True)\n",
    "\n",
    "# Display the training history\n",
    "print(history_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ebfac8",
   "metadata": {},
   "source": [
    " after training the model, the history object contains the training history with loss and accuracy values for each epoch. We convert this history object to a Pandas DataFrame using pd.DataFrame(history.history). Then, we add the epoch column to the DataFrame to represent the number of epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b0022c",
   "metadata": {},
   "source": [
    "# Q15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de55abe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q15. Plot the training history (e.g., accuracy and loss) using suitable visualization techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99a8f671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_26 (Dense)            (None, 16)                224       \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 369 (1.44 KB)\n",
      "Trainable params: 369 (1.44 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 2s 98ms/step - loss: 0.4307 - accuracy: 0.4014 - val_loss: 0.4035 - val_accuracy: 0.2222\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.3959 - accuracy: 0.4014 - val_loss: 0.3554 - val_accuracy: 0.2222\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.3564 - accuracy: 0.4014 - val_loss: 0.3066 - val_accuracy: 0.2222\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.3165 - accuracy: 0.4014 - val_loss: 0.2569 - val_accuracy: 0.2222\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.2778 - accuracy: 0.4014 - val_loss: 0.2083 - val_accuracy: 0.2222\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.2399 - accuracy: 0.4014 - val_loss: 0.1589 - val_accuracy: 0.2222\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.2003 - accuracy: 0.4014 - val_loss: 0.1105 - val_accuracy: 0.2222\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.1630 - accuracy: 0.4014 - val_loss: 0.0622 - val_accuracy: 0.2222\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1260 - accuracy: 0.4014 - val_loss: 0.0129 - val_accuracy: 0.2222\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0867 - accuracy: 0.4014 - val_loss: -0.0378 - val_accuracy: 0.2222\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0480 - accuracy: 0.4014 - val_loss: -0.0902 - val_accuracy: 0.2222\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0089 - accuracy: 0.4014 - val_loss: -0.1442 - val_accuracy: 0.2222\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: -0.0304 - accuracy: 0.4014 - val_loss: -0.2013 - val_accuracy: 0.2222\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: -0.0754 - accuracy: 0.4014 - val_loss: -0.2603 - val_accuracy: 0.2222\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -0.1196 - accuracy: 0.4014 - val_loss: -0.3218 - val_accuracy: 0.2222\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -0.1656 - accuracy: 0.4014 - val_loss: -0.3857 - val_accuracy: 0.2222\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -0.2102 - accuracy: 0.4014 - val_loss: -0.4514 - val_accuracy: 0.2222\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -0.2621 - accuracy: 0.4014 - val_loss: -0.5204 - val_accuracy: 0.2222\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: -0.3135 - accuracy: 0.4014 - val_loss: -0.5925 - val_accuracy: 0.2222\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: -0.3650 - accuracy: 0.4014 - val_loss: -0.6663 - val_accuracy: 0.2222\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: -0.4217 - accuracy: 0.4014 - val_loss: -0.7435 - val_accuracy: 0.2222\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -0.4785 - accuracy: 0.4085 - val_loss: -0.8232 - val_accuracy: 0.2222\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: -0.5357 - accuracy: 0.4296 - val_loss: -0.9085 - val_accuracy: 0.2222\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -0.5988 - accuracy: 0.4437 - val_loss: -0.9957 - val_accuracy: 0.2222\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -0.6646 - accuracy: 0.4648 - val_loss: -1.0842 - val_accuracy: 0.2222\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: -0.7321 - accuracy: 0.4648 - val_loss: -1.1771 - val_accuracy: 0.2778\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -0.8018 - accuracy: 0.4577 - val_loss: -1.2748 - val_accuracy: 0.2778\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: -0.8751 - accuracy: 0.4577 - val_loss: -1.3792 - val_accuracy: 0.2778\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -0.9540 - accuracy: 0.4577 - val_loss: -1.4870 - val_accuracy: 0.2778\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: -1.0338 - accuracy: 0.4648 - val_loss: -1.6013 - val_accuracy: 0.2778\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: -1.1160 - accuracy: 0.4718 - val_loss: -1.7170 - val_accuracy: 0.3333\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: -1.2051 - accuracy: 0.4789 - val_loss: -1.8365 - val_accuracy: 0.3333\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: -1.2918 - accuracy: 0.4930 - val_loss: -1.9627 - val_accuracy: 0.3333\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -1.3888 - accuracy: 0.4930 - val_loss: -2.0939 - val_accuracy: 0.3333\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: -1.4880 - accuracy: 0.5000 - val_loss: -2.2329 - val_accuracy: 0.3333\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: -1.5852 - accuracy: 0.5000 - val_loss: -2.3809 - val_accuracy: 0.3333\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: -1.7037 - accuracy: 0.5000 - val_loss: -2.5345 - val_accuracy: 0.3889\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: -1.8231 - accuracy: 0.4930 - val_loss: -2.6955 - val_accuracy: 0.3889\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: -1.9378 - accuracy: 0.5070 - val_loss: -2.8713 - val_accuracy: 0.3889\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: -2.0640 - accuracy: 0.5070 - val_loss: -3.0527 - val_accuracy: 0.3889\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: -2.1903 - accuracy: 0.5141 - val_loss: -3.2363 - val_accuracy: 0.3889\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: -2.3277 - accuracy: 0.5282 - val_loss: -3.4241 - val_accuracy: 0.3889\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: -2.4645 - accuracy: 0.5282 - val_loss: -3.6182 - val_accuracy: 0.3889\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: -2.6079 - accuracy: 0.5282 - val_loss: -3.8217 - val_accuracy: 0.3889\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: -2.7586 - accuracy: 0.5282 - val_loss: -4.0348 - val_accuracy: 0.3889\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -2.9229 - accuracy: 0.5282 - val_loss: -4.2582 - val_accuracy: 0.3889\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: -3.0824 - accuracy: 0.5282 - val_loss: -4.4907 - val_accuracy: 0.3889\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -3.2642 - accuracy: 0.5282 - val_loss: -4.7354 - val_accuracy: 0.3889\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -3.4306 - accuracy: 0.5211 - val_loss: -4.9951 - val_accuracy: 0.3889\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: -3.6198 - accuracy: 0.5282 - val_loss: -5.2512 - val_accuracy: 0.3889\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Load the Wine dataset\n",
    "wine_data = load_wine()\n",
    "\n",
    "# Separate the features (input variables) and target (output variable) from the dataset\n",
    "features = pd.DataFrame(data=wine_data.data, columns=wine_data.feature_names)\n",
    "target = pd.Series(wine_data.target, name='wine_type')\n",
    "\n",
    "# Perform the train-test split (same code as before)\n",
    "X_train_temp, X_test, y_train_temp, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "# Scale the features using Min-Max scaling (same code as before)\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_temp)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create the Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first hidden layer with 16 neurons and 'relu' activation function\n",
    "model.add(Dense(16, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "\n",
    "# Add the second hidden layer with 8 neurons and 'relu' activation function\n",
    "model.add(Dense(8, activation='relu'))\n",
    "\n",
    "# Add the output layer with 1 neuron and 'sigmoid' activation function for binary classification\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model with the specified loss function, optimizer, and metrics\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "\n",
    "# Fit the model to the training data with batch size of 32 and 50 epochs\n",
    "history = model.fit(X_train_scaled, y_train_temp, epochs=50, batch_size=32, validation_data=(X_val_scaled, y_val))\n",
    "\n",
    "# Store the model's training history as a Pandas DataFrame\n",
    "history_df = pd.DataFrame(history.history)\n",
    "\n",
    "# Add the epoch column to the DataFrame\n",
    "history_df['epoch'] = np.arange(1, len(history_df) + 1)\n",
    "\n",
    "# Set the epoch column as the index\n",
    "history_df.set_index('epoch', inplace=True)\n",
    "\n",
    "# Plot the training history (accuracy and loss)\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_df['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history_df['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_df['loss'], label='Training Loss')\n",
    "plt.plot(history_df['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fead043",
   "metadata": {},
   "source": [
    "we plot the training and validation accuracy on the left subplot and the training and validation loss on the right subplot. The x-axis represents the number of epochs, and the y-axis represents the accuracy and loss values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba47f13",
   "metadata": {},
   "source": [
    "# Q16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd2bbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q16. Evaluate the model's performance using the test dataset and report relevant metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b66ef886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_29 (Dense)            (None, 16)                224       \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 369 (1.44 KB)\n",
      "Trainable params: 369 (1.44 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 2s 107ms/step - loss: 0.7333 - accuracy: 0.3521 - val_loss: 0.7357 - val_accuracy: 0.1111\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.7056 - accuracy: 0.3239 - val_loss: 0.7051 - val_accuracy: 0.1111\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.6796 - accuracy: 0.3521 - val_loss: 0.6783 - val_accuracy: 0.1667\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.6542 - accuracy: 0.3873 - val_loss: 0.6540 - val_accuracy: 0.2222\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.6303 - accuracy: 0.3944 - val_loss: 0.6303 - val_accuracy: 0.2222\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.6105 - accuracy: 0.4014 - val_loss: 0.6065 - val_accuracy: 0.2222\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.5878 - accuracy: 0.4014 - val_loss: 0.5821 - val_accuracy: 0.2222\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.5661 - accuracy: 0.4014 - val_loss: 0.5562 - val_accuracy: 0.2222\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.5426 - accuracy: 0.4014 - val_loss: 0.5282 - val_accuracy: 0.2222\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.5186 - accuracy: 0.4014 - val_loss: 0.4974 - val_accuracy: 0.2222\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.4929 - accuracy: 0.4014 - val_loss: 0.4638 - val_accuracy: 0.2222\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.4659 - accuracy: 0.4014 - val_loss: 0.4270 - val_accuracy: 0.2222\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.4340 - accuracy: 0.4014 - val_loss: 0.3861 - val_accuracy: 0.2222\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.4025 - accuracy: 0.4014 - val_loss: 0.3400 - val_accuracy: 0.2222\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.3653 - accuracy: 0.4014 - val_loss: 0.2912 - val_accuracy: 0.2222\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.3260 - accuracy: 0.4014 - val_loss: 0.2382 - val_accuracy: 0.2222\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.2848 - accuracy: 0.4014 - val_loss: 0.1838 - val_accuracy: 0.2222\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.2377 - accuracy: 0.4014 - val_loss: 0.1298 - val_accuracy: 0.2222\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1965 - accuracy: 0.4014 - val_loss: 0.0744 - val_accuracy: 0.2222\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1519 - accuracy: 0.4014 - val_loss: 0.0206 - val_accuracy: 0.2222\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1117 - accuracy: 0.4014 - val_loss: -0.0308 - val_accuracy: 0.2222\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0687 - accuracy: 0.4014 - val_loss: -0.0823 - val_accuracy: 0.2222\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0301 - accuracy: 0.4014 - val_loss: -0.1376 - val_accuracy: 0.2222\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -0.0137 - accuracy: 0.4014 - val_loss: -0.1923 - val_accuracy: 0.2222\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: -0.0565 - accuracy: 0.4014 - val_loss: -0.2481 - val_accuracy: 0.2222\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -0.0995 - accuracy: 0.4014 - val_loss: -0.3060 - val_accuracy: 0.2222\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -0.1432 - accuracy: 0.4014 - val_loss: -0.3682 - val_accuracy: 0.2222\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: -0.1908 - accuracy: 0.4014 - val_loss: -0.4328 - val_accuracy: 0.2222\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: -0.2391 - accuracy: 0.4014 - val_loss: -0.5002 - val_accuracy: 0.2222\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: -0.2917 - accuracy: 0.4014 - val_loss: -0.5683 - val_accuracy: 0.2222\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: -0.3433 - accuracy: 0.4014 - val_loss: -0.6406 - val_accuracy: 0.2222\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: -0.4003 - accuracy: 0.4014 - val_loss: -0.7160 - val_accuracy: 0.2222\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: -0.4570 - accuracy: 0.4014 - val_loss: -0.7949 - val_accuracy: 0.2222\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: -0.5167 - accuracy: 0.4014 - val_loss: -0.8768 - val_accuracy: 0.2222\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -0.5775 - accuracy: 0.4014 - val_loss: -0.9640 - val_accuracy: 0.2222\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -0.6459 - accuracy: 0.4014 - val_loss: -1.0487 - val_accuracy: 0.2222\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: -0.7034 - accuracy: 0.4014 - val_loss: -1.1420 - val_accuracy: 0.2222\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: -0.7782 - accuracy: 0.4014 - val_loss: -1.2366 - val_accuracy: 0.2222\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: -0.8472 - accuracy: 0.4014 - val_loss: -1.3376 - val_accuracy: 0.2222\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -0.9262 - accuracy: 0.4014 - val_loss: -1.4367 - val_accuracy: 0.2222\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: -1.0003 - accuracy: 0.4014 - val_loss: -1.5428 - val_accuracy: 0.2222\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: -1.0814 - accuracy: 0.4014 - val_loss: -1.6530 - val_accuracy: 0.2222\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -1.1582 - accuracy: 0.4014 - val_loss: -1.7826 - val_accuracy: 0.2222\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: -1.2549 - accuracy: 0.4014 - val_loss: -1.9100 - val_accuracy: 0.2222\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: -1.3479 - accuracy: 0.4014 - val_loss: -2.0458 - val_accuracy: 0.2222\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -1.4454 - accuracy: 0.4014 - val_loss: -2.1894 - val_accuracy: 0.2222\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -1.5513 - accuracy: 0.4014 - val_loss: -2.3392 - val_accuracy: 0.2222\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -1.6594 - accuracy: 0.4014 - val_loss: -2.5031 - val_accuracy: 0.2222\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -1.7749 - accuracy: 0.4014 - val_loss: -2.6750 - val_accuracy: 0.2222\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: -1.9015 - accuracy: 0.4085 - val_loss: -2.8579 - val_accuracy: 0.2222\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2737 - accuracy: 0.5556\n",
      "Test Loss: 0.2737\n",
      "Test Accuracy: 0.5556\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Load the Wine dataset\n",
    "wine_data = load_wine()\n",
    "\n",
    "# Separate the features (input variables) and target (output variable) from the dataset\n",
    "features = pd.DataFrame(data=wine_data.data, columns=wine_data.feature_names)\n",
    "target = pd.Series(wine_data.target, name='wine_type')\n",
    "\n",
    "# Perform the train-test split (same code as before)\n",
    "X_train_temp, X_test, y_train_temp, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "# Scale the features using Min-Max scaling (same code as before)\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_temp)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create the Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first hidden layer with 16 neurons and 'relu' activation function\n",
    "model.add(Dense(16, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "\n",
    "# Add the second hidden layer with 8 neurons and 'relu' activation function\n",
    "model.add(Dense(8, activation='relu'))\n",
    "\n",
    "# Add the output layer with 1 neuron and 'sigmoid' activation function for binary classification\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model with the specified loss function, optimizer, and metrics\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "\n",
    "# Fit the model to the training data with batch size of 32 and 50 epochs\n",
    "history = model.fit(X_train_scaled, y_train_temp, epochs=50, batch_size=32, validation_data=(X_val_scaled, y_val))\n",
    "\n",
    "# Evaluate the model's performance on the test dataset\n",
    "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b11d57",
   "metadata": {},
   "source": [
    "after training the model on the training and validation data, we use the evaluate method to evaluate the model's performance on the test dataset (X_test_scaled and y_test). The evaluate method returns the test loss and accuracy, which we print out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b0b85b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
