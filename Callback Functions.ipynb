{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71aa7456",
   "metadata": {},
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e19bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. Install and load the latest versions of TensorFlow and Keras. Print their versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13bfacf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\hp\\anaconda3\\lib\\site-packages (2.13.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.13.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (63.4.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.23.4)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.3.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.56.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (21.3)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.13.0->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.26.11)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2022.9.14)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac9f15bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\hp\\anaconda3\\lib\\site-packages (2.13.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84769126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.13.0\n",
      "Keras version: 2.13.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Keras version:\", keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e90c59e",
   "metadata": {},
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfccdfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. Load the Wine Quality dataset and explore its dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48e147b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\hp\\anaconda3\\lib\\site-packages (1.4.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b366c4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 1599\n",
      "Number of columns: 12\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Wine Quality dataset (assuming the CSV file is in the current working directory)\n",
    "wine_data = pd.read_csv('wine.csv')\n",
    "\n",
    "# Explore the dimensions of the dataset\n",
    "print(\"Number of rows:\", wine_data.shape[0])\n",
    "print(\"Number of columns:\", wine_data.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533cc8ae",
   "metadata": {},
   "source": [
    "This code will load the Wine Quality dataset from the CSV file (change the filename if needed) and print the number of rows and columns in the dataset. Each row represents a wine sample, and each column corresponds to a specific feature or property of the wine, including various physicochemical measurements and the quality rating."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1a3706",
   "metadata": {},
   "source": [
    "# Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9219bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. Check for null values, identify categorical variables, and encode them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2e5c5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\hp\\anaconda3\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from scikit-learn) (1.9.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75da3aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null Values:\n",
      " fixed acidity           0\n",
      "volatile acidity        0\n",
      "citric acid             0\n",
      "residual sugar          0\n",
      "chlorides               0\n",
      "free sulfur dioxide     0\n",
      "total sulfur dioxide    0\n",
      "density                 0\n",
      "pH                      0\n",
      "sulphates               0\n",
      "alcohol                 0\n",
      "quality                 0\n",
      "dtype: int64\n",
      "Categorical Columns:\n",
      " Index(['quality'], dtype='object')\n",
      "First few rows after encoding:\n",
      "    fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0            7.4              0.70         0.00             1.9      0.076   \n",
      "1            7.8              0.88         0.00             2.6      0.098   \n",
      "2            7.8              0.76         0.04             2.3      0.092   \n",
      "3           11.2              0.28         0.56             1.9      0.075   \n",
      "4            7.4              0.70         0.00             1.9      0.076   \n",
      "\n",
      "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
      "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
      "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
      "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "\n",
      "   alcohol  quality  \n",
      "0      9.4        0  \n",
      "1      9.8        0  \n",
      "2      9.8        0  \n",
      "3      9.8        1  \n",
      "4      9.4        0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the Wine dataset from the CSV file\n",
    "wine_data = pd.read_csv('wine.csv')\n",
    "\n",
    "# Check for null values\n",
    "null_values = wine_data.isnull().sum()\n",
    "print(\"Null Values:\\n\", null_values)\n",
    "\n",
    "# Identify categorical variables\n",
    "categorical_columns = wine_data.select_dtypes(include='object').columns\n",
    "print(\"Categorical Columns:\\n\", categorical_columns)\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "for col in categorical_columns:\n",
    "    wine_data[col] = label_encoder.fit_transform(wine_data[col])\n",
    "\n",
    "# Print the first few rows after encoding\n",
    "print(\"First few rows after encoding:\\n\", wine_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54e8b27",
   "metadata": {},
   "source": [
    "# Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce5c79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. Separate the features and target variables from the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b239147",
   "metadata": {},
   "source": [
    "Ans:-\n",
    "    To separate the features and target variables from the DataFrame, we need to identify which columns represent the features (input variables) and which column represents the target variable (output variable). In this case, assuming the 'wine.csv' dataset has the features and target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fce0a19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Wine dataset from the CSV file\n",
    "wine_data = pd.read_csv('wine.csv')\n",
    "\n",
    "# Column names for features (input variables) and the target variable\n",
    "feature_columns = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol']\n",
    "target_column = 'quality'\n",
    "\n",
    "# Separate features and target variable\n",
    "X = wine_data[feature_columns]\n",
    "y = wine_data[target_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0fc2780a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'quality' is the target variable\n",
    "X = wine_data.drop(columns=['quality'])\n",
    "y = wine_data['quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6175078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0            7.4              0.70         0.00             1.9      0.076   \n",
      "1            7.8              0.88         0.00             2.6      0.098   \n",
      "2            7.8              0.76         0.04             2.3      0.092   \n",
      "3           11.2              0.28         0.56             1.9      0.075   \n",
      "4            7.4              0.70         0.00             1.9      0.076   \n",
      "\n",
      "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
      "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
      "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
      "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "\n",
      "   alcohol  \n",
      "0      9.4  \n",
      "1      9.8  \n",
      "2      9.8  \n",
      "3      9.8  \n",
      "4      9.4  \n",
      "0     bad\n",
      "1     bad\n",
      "2     bad\n",
      "3    good\n",
      "4     bad\n",
      "Name: quality, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X.head())\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f17b97",
   "metadata": {},
   "source": [
    "# Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9914ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. Perform a train-test split and divide the data into training, validation, and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36e4f181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 1023\n",
      "Validation set size: 256\n",
      "Test set size: 320\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the Wine dataset from the CSV file\n",
    "wine_data = pd.read_csv('wine.csv')\n",
    "\n",
    "# Column names for features (input variables) and the target variable\n",
    "feature_columns = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol']\n",
    "target_column = 'quality'\n",
    "\n",
    "# Separate features and target variable\n",
    "X = wine_data[feature_columns]\n",
    "y = wine_data[target_column]\n",
    "\n",
    "# Perform a train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Further split the training set into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the sizes of the datasets\n",
    "print(\"Training set size:\", X_train.shape[0])\n",
    "print(\"Validation set size:\", X_val.shape[0])\n",
    "print(\"Test set size:\", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e14b686",
   "metadata": {},
   "source": [
    "we first load the 'wine.csv' dataset and separate the features (X) and target variable (y). We then use train_test_split twice to split the data into training, validation, and test sets. The first train_test_split splits the data into a training set (80%) and a test set (20%). The second train_test_split splits the training set from the previous step into a new training set (64% of the original data) and a validation set (16% of the original data).\n",
    "\n",
    "The random_state parameter is used to ensure reproducibility of the splits. Setting it to a specific value (e.g., random_state=42) ensures that the same split will be generated every time you run the code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ef295d",
   "metadata": {},
   "source": [
    "# Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b04b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. Perform scaling on the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a398653d",
   "metadata": {},
   "source": [
    "Ans:-\n",
    "    \n",
    "    To perform scaling on the dataset, we can use scikit-learn's StandardScaler or MinMaxScaler. These scalers transform the data such that each feature has a mean of 0 and a standard deviation of 1 (for StandardScaler) or scales the data to a specified range, typically [0, 1] (for MinMaxScaler). Scaling is important in many machine learning algorithms to ensure that features are on similar scales and have equal importance during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "074fcf40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled Training Data:\n",
      " [[-0.36458197  0.27028307 -0.88452628 -0.52477545  0.28181672  1.18643738\n",
      "   1.88446744 -0.58557889 -1.50331912 -0.96231644 -0.61284241]\n",
      " [ 2.08646306 -0.82422292  1.09972703  0.13151463  0.20024397 -0.36725548\n",
      "  -0.12357452  1.94514874 -0.98778743 -0.29662295 -0.13057021]\n",
      " [ 0.86094055 -0.16751933  1.09972703  0.05859351  3.30000862 -1.0469961\n",
      "  -0.78293158  1.19925007 -0.02116552  0.70191728  0.25524755]\n",
      " [-0.18950732 -1.20730002  0.89621387 -0.30601209  2.60664021 -1.0469961\n",
      "  -0.90281468 -1.68844335 -1.05222889  0.81286619  1.99142746]\n",
      " [ 1.26944805 -0.11279403  1.86290138 -0.08724873  0.38378266 -0.9498903\n",
      "  -0.93278545  0.29351597 -1.43887765 -0.01925067  1.31624638]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the Wine dataset from the CSV file\n",
    "wine_data = pd.read_csv('wine.csv')\n",
    "\n",
    "# Column names for features (input variables) and the target variable\n",
    "feature_columns = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol']\n",
    "target_column = 'quality'\n",
    "\n",
    "# Separate features and target variable\n",
    "X = wine_data[feature_columns]\n",
    "y = wine_data[target_column]\n",
    "\n",
    "# Perform a train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Further split the training set into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform both training and validation data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Print the first few rows of the scaled training data\n",
    "print(\"Scaled Training Data:\\n\", X_train_scaled[:5, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d2a11e",
   "metadata": {},
   "source": [
    "we first load the 'wine.csv' dataset and separate the features (X) and target variable (y). Then, we perform a train-test split as shown in the previous example.\n",
    "\n",
    "Next, we initialize the StandardScaler and fit it on the training data using fit_transform. This step computes the mean and standard deviation of each feature in the training set and applies the scaling transformation. We then use the learned scaling parameters to transform both the training and validation data using transform.\n",
    "\n",
    "After scaling, you can observe that the values in the X_train_scaled are centered around 0 with a standard deviation of 1. Scaling ensures that all features have a similar impact on the model, making the training process more stable and efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49ff281",
   "metadata": {},
   "source": [
    "# Q7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1037cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7. Create at least 2 hidden layers and an output layer for the binary categorical variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f00d150",
   "metadata": {},
   "source": [
    "Ans:- \n",
    "    a neural network with at least 2 hidden layers and an output layer for binary categorical variables, we'll use TensorFlow/Keras. For binary classification, the output layer will typically have one neuron with a sigmoid activation function, and the loss function will be binary cross-entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be95ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the Wine dataset from the CSV file\n",
    "wine_data = pd.read_csv('wine.csv')\n",
    "\n",
    "# Column names for features (input variables) and the target variable\n",
    "feature_columns = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol']\n",
    "target_column = 'quality'\n",
    "\n",
    "# Separate features and target variable\n",
    "X = wine_data[feature_columns]\n",
    "y = wine_data[target_column]\n",
    "\n",
    "# Define binary classes: 'good' and 'not good'\n",
    "y = (y >= 7).astype(int)\n",
    "\n",
    "# Perform a train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Further split the training set into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform both training and validation data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create the neural network model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(X_train_scaled.shape[1],)),  # Input layer\n",
    "    tf.keras.layers.Dense(64, activation='relu'),  # Hidden layer 1 with 64 neurons and ReLU activation\n",
    "    tf.keras.layers.Dense(32, activation='relu'),  # Hidden layer 2 with 32 neurons and ReLU activation\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  # Output layer with 1 neuron and sigmoid activation for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_scaled, y_train, epochs=10, batch_size=32, validation_data=(X_val_scaled, y_val))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db0f564",
   "metadata": {},
   "source": [
    "# Q8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749b3eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q8. Create a Sequential model and add all the layers to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "847f7b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "32/32 [==============================] - 1s 13ms/step - loss: 0.3575 - accuracy: 0.9316 - val_loss: 0.1255 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0654 - accuracy: 1.0000 - val_loss: 0.0309 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 9.4546e-04 - val_accuracy: 1.0000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8.8006e-04 - accuracy: 1.0000\n",
      "Test Loss: 0.0008800593204796314\n",
      "Test Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the Wine dataset from the CSV file\n",
    "wine_data = pd.read_csv('wine.csv')\n",
    "\n",
    "# Column names for features (input variables) and the target variable\n",
    "feature_columns = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol']\n",
    "target_column = 'quality'\n",
    "\n",
    "# Separate features and target variable\n",
    "X = wine_data[feature_columns]\n",
    "y = wine_data[target_column]\n",
    "\n",
    "# Convert 'quality' column to numerical values\n",
    "y = pd.to_numeric(y, errors='coerce')  # Coerce non-numeric values to NaN\n",
    "y = y.fillna(0)  # Fill NaN values with 0 (for example purposes, you may use other strategies)\n",
    "\n",
    "# Define binary classes: 'good' and 'not good'\n",
    "y = (y >= 7).astype(int)\n",
    "\n",
    "# Perform a train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Further split the training set into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform both training and validation data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create the Sequential model and add the layers\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Input(shape=(X_train_scaled.shape[1],)))  # Input layer\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))  # Hidden layer 1 with 64 neurons and ReLU activation\n",
    "model.add(tf.keras.layers.Dense(32, activation='relu'))  # Hidden layer 2 with 32 neurons and ReLU activation\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # Output layer with 1 neuron and sigmoid activation for binary classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_scaled, y_train, epochs=10, batch_size=32, validation_data=(X_val_scaled, y_val))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef306d5",
   "metadata": {},
   "source": [
    "This code will create a Sequential model and add each layer to it using the Sequential class of the model. The layers are added in the order of their definition, starting with the input layer, followed by the hidden layers, and ending with the output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed5479f",
   "metadata": {},
   "source": [
    "# Q9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd2c80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q9. Implement a TensorBoard callback to visualize and monitor the model's training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7a289eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "32/32 [==============================] - 2s 39ms/step - loss: 0.3512 - accuracy: 0.9032 - val_loss: 0.1259 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0639 - accuracy: 1.0000 - val_loss: 0.0276 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Test Loss: 0.001088961260393262\n",
      "Test Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Load the Wine dataset from the CSV file\n",
    "wine_data = pd.read_csv('wine.csv')\n",
    "\n",
    "# Column names for features (input variables) and the target variable\n",
    "feature_columns = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol']\n",
    "target_column = 'quality'\n",
    "\n",
    "# Separate features and target variable\n",
    "X = wine_data[feature_columns]\n",
    "y = wine_data[target_column]\n",
    "\n",
    "# Convert 'quality' column to numerical values\n",
    "y = pd.to_numeric(y, errors='coerce')  # Coerce non-numeric values to NaN\n",
    "y = y.fillna(0)  # Fill NaN values with 0 (for example purposes, you may use other strategies)\n",
    "\n",
    "# Define binary classes: 'good' and 'not good'\n",
    "y = (y >= 7).astype(int)\n",
    "\n",
    "# Perform a train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Further split the training set into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform both training and validation data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create the Sequential model and add the layers\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(X_train_scaled.shape[1],)),  # Input layer\n",
    "    tf.keras.layers.Dense(64, activation='relu'),  # Hidden layer 1 with 64 neurons and ReLU activation\n",
    "    tf.keras.layers.Dense(32, activation='relu'),  # Hidden layer 2 with 32 neurons and ReLU activation\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  # Output layer with 1 neuron and sigmoid activation for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Create a directory for TensorBoard logs\n",
    "log_dir = \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# Create a TensorBoard callback\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Train the model with the TensorBoard callback\n",
    "history = model.fit(X_train_scaled, y_train, epochs=10, batch_size=32, validation_data=(X_val_scaled, y_val), callbacks=[tensorboard_callback])\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac52a337",
   "metadata": {},
   "source": [
    "we create a TensorBoard callback using tf.keras.callbacks.TensorBoard. The log_dir specifies the directory where the TensorBoard logs will be saved. It includes a timestamp to create a unique directory for each run.\n",
    "\n",
    "We then add the TensorBoard callback to the model.fit method using the callbacks parameter. During training, TensorBoard will write the logs to the specified directory. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa189cca",
   "metadata": {},
   "source": [
    "# Q10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39aafbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q10. Use Early Stopping to prevent overfitting by monitoring a chosen metric and stopping the training if\n",
    "no improvement is observed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91fc435",
   "metadata": {},
   "source": [
    "Ans:-\n",
    "    \n",
    "    Early stopping is a technique used to prevent overfitting by monitoring a chosen metric (e.g., validation loss or accuracy) during the training process. If the metric does not improve for a certain number of epochs, training is stopped early to avoid overfitting on the training data. We can use the tf.keras.callbacks.EarlyStopping callback to implement this in TensorFlow/Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "91bdde69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "32/32 [==============================] - 2s 20ms/step - loss: 0.2803 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0574 - accuracy: 1.0000 - val_loss: 0.0219 - val_accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 9.7368e-04 - accuracy: 1.0000 - val_loss: 8.1991e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.8174e-04 - accuracy: 1.0000 - val_loss: 6.6663e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.4291e-04 - accuracy: 1.0000 - val_loss: 5.5012e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.3649e-04 - accuracy: 1.0000 - val_loss: 4.6411e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 4.5626e-04 - accuracy: 1.0000 - val_loss: 3.9484e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 3.9120e-04 - accuracy: 1.0000 - val_loss: 3.4237e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.4065e-04 - accuracy: 1.0000 - val_loss: 2.9839e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.9878e-04 - accuracy: 1.0000 - val_loss: 2.6237e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.6411e-04 - accuracy: 1.0000 - val_loss: 2.3289e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.3526e-04 - accuracy: 1.0000 - val_loss: 2.0784e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.1073e-04 - accuracy: 1.0000 - val_loss: 1.8725e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.9009e-04 - accuracy: 1.0000 - val_loss: 1.6904e-04 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.7252e-04 - accuracy: 1.0000 - val_loss: 1.5238e-04 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.5654e-04 - accuracy: 1.0000 - val_loss: 1.3895e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.4295e-04 - accuracy: 1.0000 - val_loss: 1.2739e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.3140e-04 - accuracy: 1.0000 - val_loss: 1.1636e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.2069e-04 - accuracy: 1.0000 - val_loss: 1.0719e-04 - val_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.1131e-04 - accuracy: 1.0000 - val_loss: 9.9348e-05 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0320e-04 - accuracy: 1.0000 - val_loss: 9.1774e-05 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 9.5619e-05 - accuracy: 1.0000 - val_loss: 8.5450e-05 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 8.9132e-05 - accuracy: 1.0000 - val_loss: 7.9251e-05 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 8.3077e-05 - accuracy: 1.0000 - val_loss: 7.3834e-05 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 7.7508e-05 - accuracy: 1.0000 - val_loss: 6.9255e-05 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 7.2640e-05 - accuracy: 1.0000 - val_loss: 6.4862e-05 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 6.8180e-05 - accuracy: 1.0000 - val_loss: 6.0720e-05 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 6.4035e-05 - accuracy: 1.0000 - val_loss: 5.7083e-05 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.0244e-05 - accuracy: 1.0000 - val_loss: 5.3827e-05 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.6918e-05 - accuracy: 1.0000 - val_loss: 5.0514e-05 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.3615e-05 - accuracy: 1.0000 - val_loss: 4.7804e-05 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.0709e-05 - accuracy: 1.0000 - val_loss: 4.5232e-05 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.8064e-05 - accuracy: 1.0000 - val_loss: 4.2692e-05 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.5487e-05 - accuracy: 1.0000 - val_loss: 4.0555e-05 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.3213e-05 - accuracy: 1.0000 - val_loss: 3.8431e-05 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.1046e-05 - accuracy: 1.0000 - val_loss: 3.6486e-05 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.9017e-05 - accuracy: 1.0000 - val_loss: 3.4728e-05 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.7161e-05 - accuracy: 1.0000 - val_loss: 3.3044e-05 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.5408e-05 - accuracy: 1.0000 - val_loss: 3.1469e-05 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.3767e-05 - accuracy: 1.0000 - val_loss: 3.0010e-05 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 3.2247e-05 - accuracy: 1.0000 - val_loss: 2.8597e-05 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.0791e-05 - accuracy: 1.0000 - val_loss: 2.7355e-05 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 2.9453e-05 - accuracy: 1.0000 - val_loss: 2.6134e-05 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.8201e-05 - accuracy: 1.0000 - val_loss: 2.4949e-05 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.6964e-05 - accuracy: 1.0000 - val_loss: 2.3935e-05 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.5853e-05 - accuracy: 1.0000 - val_loss: 2.2937e-05 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.4793e-05 - accuracy: 1.0000 - val_loss: 2.1991e-05 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.3797e-05 - accuracy: 1.0000 - val_loss: 2.1073e-05 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 2.2838e-05 - accuracy: 1.0000 - val_loss: 2.0237e-05 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 7ms/step - loss: 2.1947e-05 - accuracy: 1.0000 - val_loss: 1.9419e-05 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.1099e-05 - accuracy: 1.0000 - val_loss: 1.8644e-05 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.0281e-05 - accuracy: 1.0000 - val_loss: 1.7939e-05 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.9516e-05 - accuracy: 1.0000 - val_loss: 1.7275e-05 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.8796e-05 - accuracy: 1.0000 - val_loss: 1.6626e-05 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.8104e-05 - accuracy: 1.0000 - val_loss: 1.5998e-05 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.7448e-05 - accuracy: 1.0000 - val_loss: 1.5403e-05 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.6812e-05 - accuracy: 1.0000 - val_loss: 1.4884e-05 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.6229e-05 - accuracy: 1.0000 - val_loss: 1.4331e-05 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.5663e-05 - accuracy: 1.0000 - val_loss: 1.3798e-05 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.5103e-05 - accuracy: 1.0000 - val_loss: 1.3345e-05 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.4595e-05 - accuracy: 1.0000 - val_loss: 1.2881e-05 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.4101e-05 - accuracy: 1.0000 - val_loss: 1.2437e-05 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.3624e-05 - accuracy: 1.0000 - val_loss: 1.2023e-05 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.3188e-05 - accuracy: 1.0000 - val_loss: 1.1588e-05 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.2746e-05 - accuracy: 1.0000 - val_loss: 1.1204e-05 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.2324e-05 - accuracy: 1.0000 - val_loss: 1.0844e-05 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.1932e-05 - accuracy: 1.0000 - val_loss: 1.0497e-05 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.1555e-05 - accuracy: 1.0000 - val_loss: 1.0153e-05 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.1188e-05 - accuracy: 1.0000 - val_loss: 9.8296e-06 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0835e-05 - accuracy: 1.0000 - val_loss: 9.5279e-06 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0502e-05 - accuracy: 1.0000 - val_loss: 9.2321e-06 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0185e-05 - accuracy: 1.0000 - val_loss: 8.9317e-06 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 9.8671e-06 - accuracy: 1.0000 - val_loss: 8.6684e-06 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 9.5790e-06 - accuracy: 1.0000 - val_loss: 8.3866e-06 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 9.2810e-06 - accuracy: 1.0000 - val_loss: 8.1472e-06 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 9.0138e-06 - accuracy: 1.0000 - val_loss: 7.9008e-06 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.7475e-06 - accuracy: 1.0000 - val_loss: 7.6598e-06 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.4869e-06 - accuracy: 1.0000 - val_loss: 7.4455e-06 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.2448e-06 - accuracy: 1.0000 - val_loss: 7.2256e-06 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.0101e-06 - accuracy: 1.0000 - val_loss: 7.0086e-06 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.7770e-06 - accuracy: 1.0000 - val_loss: 6.8182e-06 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.5649e-06 - accuracy: 1.0000 - val_loss: 6.6037e-06 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.3459e-06 - accuracy: 1.0000 - val_loss: 6.4188e-06 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.1390e-06 - accuracy: 1.0000 - val_loss: 6.2490e-06 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.9473e-06 - accuracy: 1.0000 - val_loss: 6.0603e-06 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.7535e-06 - accuracy: 1.0000 - val_loss: 5.8873e-06 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.5683e-06 - accuracy: 1.0000 - val_loss: 5.7220e-06 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.3859e-06 - accuracy: 1.0000 - val_loss: 5.5726e-06 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.2154e-06 - accuracy: 1.0000 - val_loss: 5.4261e-06 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.0507e-06 - accuracy: 1.0000 - val_loss: 5.2720e-06 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.8868e-06 - accuracy: 1.0000 - val_loss: 5.1335e-06 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.7321e-06 - accuracy: 1.0000 - val_loss: 4.9961e-06 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.5824e-06 - accuracy: 1.0000 - val_loss: 4.8577e-06 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 5.4351e-06 - accuracy: 1.0000 - val_loss: 4.7299e-06 - val_accuracy: 1.0000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.1732e-06 - accuracy: 1.0000\n",
      "Test Loss: 6.173201199999312e-06\n",
      "Test Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Load the Wine dataset from the CSV file\n",
    "wine_data = pd.read_csv('wine.csv')\n",
    "\n",
    "# Column names for features (input variables) and the target variable\n",
    "feature_columns = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol']\n",
    "target_column = 'quality'\n",
    "\n",
    "# Separate features and target variable\n",
    "X = wine_data[feature_columns]\n",
    "y = wine_data[target_column]\n",
    "\n",
    "# Convert 'quality' column to numerical values\n",
    "y = pd.to_numeric(y, errors='coerce')  # Coerce non-numeric values to NaN\n",
    "y = y.fillna(0)  # Fill NaN values with 0 (for example purposes, you may use other strategies)\n",
    "\n",
    "# Define binary classes: 'good' and 'not good'\n",
    "y = (y >= 7).astype(int)\n",
    "\n",
    "# Perform a train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Further split the training set into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform both training and validation data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create the Sequential model and add the layers\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(X_train_scaled.shape[1],)),  # Input layer\n",
    "    tf.keras.layers.Dense(64, activation='relu'),  # Hidden layer 1 with 64 neurons and ReLU activation\n",
    "    tf.keras.layers.Dense(32, activation='relu'),  # Hidden layer 2 with 32 neurons and ReLU activation\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  # Output layer with 1 neuron and sigmoid activation for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Create a directory for TensorBoard logs\n",
    "log_dir = \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# Create a TensorBoard callback\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Create an Early Stopping callback to monitor validation loss and stop training if no improvement is observed for 5 epochs\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train the model with both the TensorBoard and Early Stopping callbacks\n",
    "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_data=(X_val_scaled, y_val), callbacks=[tensorboard_callback, early_stopping_callback])\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a08dc08",
   "metadata": {},
   "source": [
    "In this updated code, we added an EarlyStopping callback with the following parameters:\n",
    "\n",
    "- monitor='val_loss': The metric to monitor during training (validation loss in this case).\n",
    "- patience=5: The number of epochs with no improvement after which training will be stopped.\n",
    "- restore_best_weights=True: Restores the best model weights when training is stopped, based on the monitored metric.\n",
    "\n",
    "\n",
    "With these updates, the code should use Early Stopping to prevent overfitting and stop training early if no improvement is observed in the validation loss for 5 consecutive epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86761f36",
   "metadata": {},
   "source": [
    "# Q11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96799d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q11. Implement a ModelCheckpoint callback to save the best model based on a chosen metric during\n",
    "training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15aec80",
   "metadata": {},
   "source": [
    "Ans:-\n",
    "    \n",
    "    The ModelCheckpoint callback in TensorFlow/Keras allows you to save the model's weights during training based on a chosen metric (e.g., validation loss or accuracy). It helps you keep track of the best-performing model and enables you to restore it later for inference or further training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cf551867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "32/32 [==============================] - 2s 18ms/step - loss: 0.4674 - accuracy: 0.8573 - val_loss: 0.2140 - val_accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "11/32 [=========>....................] - ETA: 0s - loss: 0.1756 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1171 - accuracy: 1.0000 - val_loss: 0.0497 - val_accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0297 - accuracy: 1.0000 - val_loss: 0.0159 - val_accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 9.5334e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 9.4349e-04 - accuracy: 1.0000 - val_loss: 7.9741e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.9833e-04 - accuracy: 1.0000 - val_loss: 6.7981e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.8624e-04 - accuracy: 1.0000 - val_loss: 5.8359e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.9563e-04 - accuracy: 1.0000 - val_loss: 5.0644e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 5.2109e-04 - accuracy: 1.0000 - val_loss: 4.4556e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 4.6078e-04 - accuracy: 1.0000 - val_loss: 3.9380e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.1012e-04 - accuracy: 1.0000 - val_loss: 3.5028e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 3.6710e-04 - accuracy: 1.0000 - val_loss: 3.1386e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.3025e-04 - accuracy: 1.0000 - val_loss: 2.8405e-04 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.9966e-04 - accuracy: 1.0000 - val_loss: 2.5627e-04 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.7237e-04 - accuracy: 1.0000 - val_loss: 2.3251e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.4834e-04 - accuracy: 1.0000 - val_loss: 2.1295e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 2.2802e-04 - accuracy: 1.0000 - val_loss: 1.9474e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 2.0960e-04 - accuracy: 1.0000 - val_loss: 1.7910e-04 - val_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.9348e-04 - accuracy: 1.0000 - val_loss: 1.6502e-04 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.7901e-04 - accuracy: 1.0000 - val_loss: 1.5273e-04 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.6628e-04 - accuracy: 1.0000 - val_loss: 1.4135e-04 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.5446e-04 - accuracy: 1.0000 - val_loss: 1.3175e-04 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.4420e-04 - accuracy: 1.0000 - val_loss: 1.2261e-04 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.3474e-04 - accuracy: 1.0000 - val_loss: 1.1441e-04 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.2604e-04 - accuracy: 1.0000 - val_loss: 1.0746e-04 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.1847e-04 - accuracy: 1.0000 - val_loss: 1.0032e-04 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 1.1124e-04 - accuracy: 1.0000 - val_loss: 9.4117e-05 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.0466e-04 - accuracy: 1.0000 - val_loss: 8.8610e-05 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 9.8722e-05 - accuracy: 1.0000 - val_loss: 8.3422e-05 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 9.3102e-05 - accuracy: 1.0000 - val_loss: 7.8924e-05 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 8.8133e-05 - accuracy: 1.0000 - val_loss: 7.4499e-05 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 8.3464e-05 - accuracy: 1.0000 - val_loss: 7.0304e-05 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.9031e-05 - accuracy: 1.0000 - val_loss: 6.6671e-05 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 7.5034e-05 - accuracy: 1.0000 - val_loss: 6.3179e-05 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.1278e-05 - accuracy: 1.0000 - val_loss: 5.9975e-05 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 6.7783e-05 - accuracy: 1.0000 - val_loss: 5.6998e-05 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 6.4552e-05 - accuracy: 1.0000 - val_loss: 5.4200e-05 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 6.1494e-05 - accuracy: 1.0000 - val_loss: 5.1614e-05 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 5.8639e-05 - accuracy: 1.0000 - val_loss: 4.9258e-05 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 5.6015e-05 - accuracy: 1.0000 - val_loss: 4.6929e-05 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 5.3502e-05 - accuracy: 1.0000 - val_loss: 4.4799e-05 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.1165e-05 - accuracy: 1.0000 - val_loss: 4.2786e-05 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.8949e-05 - accuracy: 1.0000 - val_loss: 4.0918e-05 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.6900e-05 - accuracy: 1.0000 - val_loss: 3.9097e-05 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 4.4900e-05 - accuracy: 1.0000 - val_loss: 3.7501e-05 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.3092e-05 - accuracy: 1.0000 - val_loss: 3.5905e-05 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.1325e-05 - accuracy: 1.0000 - val_loss: 3.4450e-05 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 3.9702e-05 - accuracy: 1.0000 - val_loss: 3.3010e-05 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 3.8117e-05 - accuracy: 1.0000 - val_loss: 3.1739e-05 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 8ms/step - loss: 3.6710e-05 - accuracy: 1.0000 - val_loss: 3.0392e-05 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 3.5229e-05 - accuracy: 1.0000 - val_loss: 2.9279e-05 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 3.3933e-05 - accuracy: 1.0000 - val_loss: 2.8139e-05 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 3.2656e-05 - accuracy: 1.0000 - val_loss: 2.7092e-05 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 3.1470e-05 - accuracy: 1.0000 - val_loss: 2.6058e-05 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.0322e-05 - accuracy: 1.0000 - val_loss: 2.5094e-05 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 2.9223e-05 - accuracy: 1.0000 - val_loss: 2.4214e-05 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 2.8207e-05 - accuracy: 1.0000 - val_loss: 2.3315e-05 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 2.7216e-05 - accuracy: 1.0000 - val_loss: 2.2461e-05 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.6260e-05 - accuracy: 1.0000 - val_loss: 2.1696e-05 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.5383e-05 - accuracy: 1.0000 - val_loss: 2.0907e-05 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.4495e-05 - accuracy: 1.0000 - val_loss: 2.0217e-05 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.3683e-05 - accuracy: 1.0000 - val_loss: 1.9536e-05 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.2909e-05 - accuracy: 1.0000 - val_loss: 1.8860e-05 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.2134e-05 - accuracy: 1.0000 - val_loss: 1.8279e-05 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.1448e-05 - accuracy: 1.0000 - val_loss: 1.7619e-05 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 2.0737e-05 - accuracy: 1.0000 - val_loss: 1.7041e-05 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.0072e-05 - accuracy: 1.0000 - val_loss: 1.6496e-05 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.9442e-05 - accuracy: 1.0000 - val_loss: 1.5964e-05 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.8833e-05 - accuracy: 1.0000 - val_loss: 1.5459e-05 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.8256e-05 - accuracy: 1.0000 - val_loss: 1.4960e-05 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.7697e-05 - accuracy: 1.0000 - val_loss: 1.4473e-05 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.7141e-05 - accuracy: 1.0000 - val_loss: 1.4050e-05 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.6634e-05 - accuracy: 1.0000 - val_loss: 1.3615e-05 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.6141e-05 - accuracy: 1.0000 - val_loss: 1.3188e-05 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.5651e-05 - accuracy: 1.0000 - val_loss: 1.2808e-05 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.5195e-05 - accuracy: 1.0000 - val_loss: 1.2422e-05 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.4751e-05 - accuracy: 1.0000 - val_loss: 1.2050e-05 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.4325e-05 - accuracy: 1.0000 - val_loss: 1.1693e-05 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.3909e-05 - accuracy: 1.0000 - val_loss: 1.1354e-05 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.3510e-05 - accuracy: 1.0000 - val_loss: 1.1033e-05 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.3134e-05 - accuracy: 1.0000 - val_loss: 1.0699e-05 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.2755e-05 - accuracy: 1.0000 - val_loss: 1.0403e-05 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.2406e-05 - accuracy: 1.0000 - val_loss: 1.0096e-05 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.2058e-05 - accuracy: 1.0000 - val_loss: 9.8074e-06 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1724e-05 - accuracy: 1.0000 - val_loss: 9.5343e-06 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.1409e-05 - accuracy: 1.0000 - val_loss: 9.2592e-06 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.1093e-05 - accuracy: 1.0000 - val_loss: 9.0103e-06 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.0800e-05 - accuracy: 1.0000 - val_loss: 8.7522e-06 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 1.0502e-05 - accuracy: 1.0000 - val_loss: 8.5200e-06 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.0221e-05 - accuracy: 1.0000 - val_loss: 8.3029e-06 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 9.9626e-06 - accuracy: 1.0000 - val_loss: 8.0607e-06 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 9.6872e-06 - accuracy: 1.0000 - val_loss: 7.8568e-06 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 9.4396e-06 - accuracy: 1.0000 - val_loss: 7.6431e-06 - val_accuracy: 1.0000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.0163e-05 - accuracy: 1.0000\n",
      "Test Loss: 1.0163332262891345e-05\n",
      "Test Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Load the Wine dataset from the CSV file\n",
    "wine_data = pd.read_csv('wine.csv')\n",
    "\n",
    "# Column names for features (input variables) and the target variable\n",
    "feature_columns = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol']\n",
    "target_column = 'quality'\n",
    "\n",
    "# Separate features and target variable\n",
    "X = wine_data[feature_columns]\n",
    "y = wine_data[target_column]\n",
    "\n",
    "# Convert 'quality' column to numerical values\n",
    "y = pd.to_numeric(y, errors='coerce')  # Coerce non-numeric values to NaN\n",
    "y = y.fillna(0)  # Fill NaN values with 0 (for example purposes, you may use other strategies)\n",
    "\n",
    "# Define binary classes: 'good' and 'not good'\n",
    "y = (y >= 7).astype(int)\n",
    "\n",
    "# Perform a train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Further split the training set into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform both training and validation data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create the Sequential model and add the layers\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(X_train_scaled.shape[1],)),  # Input layer\n",
    "    tf.keras.layers.Dense(64, activation='relu'),  # Hidden layer 1 with 64 neurons and ReLU activation\n",
    "    tf.keras.layers.Dense(32, activation='relu'),  # Hidden layer 2 with 32 neurons and ReLU activation\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  # Output layer with 1 neuron and sigmoid activation for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Create a directory for TensorBoard logs\n",
    "log_dir = \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# Create a TensorBoard callback\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Create an Early Stopping callback to monitor validation loss and stop training if no improvement is observed for 5 epochs\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Create a ModelCheckpoint callback to save the best model based on validation accuracy\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath='best_model.h5', monitor='val_accuracy', save_best_only=True, mode='max')\n",
    "\n",
    "# Train the model with both the TensorBoard, Early Stopping, and ModelCheckpoint callbacks\n",
    "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_data=(X_val_scaled, y_val), callbacks=[tensorboard_callback, early_stopping_callback, checkpoint_callback])\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5b6cba",
   "metadata": {},
   "source": [
    "In this updated code, we added a ModelCheckpoint callback with the following parameters:\n",
    "\n",
    "filepath='best_model.h5': The path to save the best model's weights.\n",
    "monitor='val_accuracy': The metric to monitor during training (validation accuracy in this case).\n",
    "save_best_only=True: Only saves the model when the monitored metric improves.\n",
    "mode='max': Monitors the metric to maximize its value (i.e., higher validation accuracy).\n",
    "With these updates, the code should use both the Early Stopping and ModelCheckpoint callbacks during training. The best model's weights will be saved in 'best_model.h5', and training will stop early if no improvement is observed in the validation loss for 5 consecutive epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2981c5",
   "metadata": {},
   "source": [
    "# Q12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deeb7be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q12. Print the model summary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63a33c6",
   "metadata": {},
   "source": [
    "Ans:-\n",
    "\n",
    "To print the summary of the model, you can use the summary() method of the Keras model. This will provide you with a summary of the model architecture, including the number of parameters in each layer, the output shape of each layer, and the total number of trainable parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "580afe17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_15 (Dense)            (None, 64)                768       \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2881 (11.25 KB)\n",
      "Trainable params: 2881 (11.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "32/32 [==============================] - 2s 21ms/step - loss: 0.4572 - accuracy: 0.8446 - val_loss: 0.2119 - val_accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "30/32 [===========================>..] - ETA: 0s - loss: 0.1186 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1155 - accuracy: 1.0000 - val_loss: 0.0557 - val_accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0335 - accuracy: 1.0000 - val_loss: 0.0200 - val_accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.0102 - val_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 8.8112e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 9.2137e-04 - accuracy: 1.0000 - val_loss: 7.5845e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 8.0295e-04 - accuracy: 1.0000 - val_loss: 6.5652e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 7.0325e-04 - accuracy: 1.0000 - val_loss: 5.7803e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 6.2345e-04 - accuracy: 1.0000 - val_loss: 5.1107e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.5541e-04 - accuracy: 1.0000 - val_loss: 4.5554e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.9855e-04 - accuracy: 1.0000 - val_loss: 4.0806e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.4968e-04 - accuracy: 1.0000 - val_loss: 3.6724e-04 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.0747e-04 - accuracy: 1.0000 - val_loss: 3.3253e-04 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 3.7105e-04 - accuracy: 1.0000 - val_loss: 3.0256e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 3.3927e-04 - accuracy: 1.0000 - val_loss: 2.7615e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 3.1152e-04 - accuracy: 1.0000 - val_loss: 2.5246e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.8647e-04 - accuracy: 1.0000 - val_loss: 2.3262e-04 - val_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.6487e-04 - accuracy: 1.0000 - val_loss: 2.1424e-04 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.4509e-04 - accuracy: 1.0000 - val_loss: 1.9846e-04 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.2768e-04 - accuracy: 1.0000 - val_loss: 1.8416e-04 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.1207e-04 - accuracy: 1.0000 - val_loss: 1.7102e-04 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.9789e-04 - accuracy: 1.0000 - val_loss: 1.5898e-04 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.8497e-04 - accuracy: 1.0000 - val_loss: 1.4841e-04 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.7319e-04 - accuracy: 1.0000 - val_loss: 1.3897e-04 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.6261e-04 - accuracy: 1.0000 - val_loss: 1.3026e-04 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.5285e-04 - accuracy: 1.0000 - val_loss: 1.2245e-04 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.4411e-04 - accuracy: 1.0000 - val_loss: 1.1481e-04 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.3578e-04 - accuracy: 1.0000 - val_loss: 1.0824e-04 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.2833e-04 - accuracy: 1.0000 - val_loss: 1.0198e-04 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.2128e-04 - accuracy: 1.0000 - val_loss: 9.6526e-05 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.1493e-04 - accuracy: 1.0000 - val_loss: 9.1295e-05 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.0903e-04 - accuracy: 1.0000 - val_loss: 8.6395e-05 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0349e-04 - accuracy: 1.0000 - val_loss: 8.1808e-05 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 9.8354e-05 - accuracy: 1.0000 - val_loss: 7.7577e-05 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 9.3472e-05 - accuracy: 1.0000 - val_loss: 7.3927e-05 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 8.9127e-05 - accuracy: 1.0000 - val_loss: 7.0277e-05 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.4902e-05 - accuracy: 1.0000 - val_loss: 6.6939e-05 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.1023e-05 - accuracy: 1.0000 - val_loss: 6.3771e-05 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 7.7430e-05 - accuracy: 1.0000 - val_loss: 6.0627e-05 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 7.3902e-05 - accuracy: 1.0000 - val_loss: 5.7939e-05 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.0738e-05 - accuracy: 1.0000 - val_loss: 5.5282e-05 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.7649e-05 - accuracy: 1.0000 - val_loss: 5.2984e-05 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 6.4848e-05 - accuracy: 1.0000 - val_loss: 5.0634e-05 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.2158e-05 - accuracy: 1.0000 - val_loss: 4.8455e-05 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.9639e-05 - accuracy: 1.0000 - val_loss: 4.6321e-05 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.7198e-05 - accuracy: 1.0000 - val_loss: 4.4427e-05 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.4919e-05 - accuracy: 1.0000 - val_loss: 4.2678e-05 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.2801e-05 - accuracy: 1.0000 - val_loss: 4.0943e-05 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 9ms/step - loss: 5.0749e-05 - accuracy: 1.0000 - val_loss: 3.9370e-05 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 4.8832e-05 - accuracy: 1.0000 - val_loss: 3.7799e-05 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 4.7012e-05 - accuracy: 1.0000 - val_loss: 3.6295e-05 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.5231e-05 - accuracy: 1.0000 - val_loss: 3.4980e-05 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.3630e-05 - accuracy: 1.0000 - val_loss: 3.3589e-05 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.1998e-05 - accuracy: 1.0000 - val_loss: 3.2426e-05 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.0536e-05 - accuracy: 1.0000 - val_loss: 3.1190e-05 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 3.9116e-05 - accuracy: 1.0000 - val_loss: 3.0014e-05 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 3.7744e-05 - accuracy: 1.0000 - val_loss: 2.8929e-05 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.6451e-05 - accuracy: 1.0000 - val_loss: 2.7880e-05 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 3.5171e-05 - accuracy: 1.0000 - val_loss: 2.6971e-05 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.4025e-05 - accuracy: 1.0000 - val_loss: 2.6013e-05 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.2873e-05 - accuracy: 1.0000 - val_loss: 2.5130e-05 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 3.1809e-05 - accuracy: 1.0000 - val_loss: 2.4259e-05 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 3.0747e-05 - accuracy: 1.0000 - val_loss: 2.3466e-05 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.9775e-05 - accuracy: 1.0000 - val_loss: 2.2659e-05 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.8804e-05 - accuracy: 1.0000 - val_loss: 2.1934e-05 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.7900e-05 - accuracy: 1.0000 - val_loss: 2.1220e-05 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.7027e-05 - accuracy: 1.0000 - val_loss: 2.0523e-05 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.6181e-05 - accuracy: 1.0000 - val_loss: 1.9876e-05 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.5376e-05 - accuracy: 1.0000 - val_loss: 1.9244e-05 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.4600e-05 - accuracy: 1.0000 - val_loss: 1.8649e-05 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.3865e-05 - accuracy: 1.0000 - val_loss: 1.8044e-05 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.3137e-05 - accuracy: 1.0000 - val_loss: 1.7488e-05 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.2450e-05 - accuracy: 1.0000 - val_loss: 1.6952e-05 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 2.1789e-05 - accuracy: 1.0000 - val_loss: 1.6432e-05 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.1156e-05 - accuracy: 1.0000 - val_loss: 1.5919e-05 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.0531e-05 - accuracy: 1.0000 - val_loss: 1.5453e-05 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.9941e-05 - accuracy: 1.0000 - val_loss: 1.5006e-05 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.9384e-05 - accuracy: 1.0000 - val_loss: 1.4541e-05 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.8815e-05 - accuracy: 1.0000 - val_loss: 1.4132e-05 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.8294e-05 - accuracy: 1.0000 - val_loss: 1.3728e-05 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.7786e-05 - accuracy: 1.0000 - val_loss: 1.3315e-05 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.7282e-05 - accuracy: 1.0000 - val_loss: 1.2937e-05 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.6808e-05 - accuracy: 1.0000 - val_loss: 1.2565e-05 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.6338e-05 - accuracy: 1.0000 - val_loss: 1.2225e-05 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.5897e-05 - accuracy: 1.0000 - val_loss: 1.1892e-05 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.5475e-05 - accuracy: 1.0000 - val_loss: 1.1547e-05 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.5052e-05 - accuracy: 1.0000 - val_loss: 1.1222e-05 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.4651e-05 - accuracy: 1.0000 - val_loss: 1.0906e-05 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.4257e-05 - accuracy: 1.0000 - val_loss: 1.0614e-05 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.3878e-05 - accuracy: 1.0000 - val_loss: 1.0333e-05 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.3519e-05 - accuracy: 1.0000 - val_loss: 1.0045e-05 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.3160e-05 - accuracy: 1.0000 - val_loss: 9.7768e-06 - val_accuracy: 1.0000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.5068e-05 - accuracy: 1.0000\n",
      "Test Loss: 1.5067978893057443e-05\n",
      "Test Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Load the Wine dataset from the CSV file\n",
    "wine_data = pd.read_csv('wine.csv')\n",
    "\n",
    "# Column names for features (input variables) and the target variable\n",
    "feature_columns = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol']\n",
    "target_column = 'quality'\n",
    "\n",
    "# Separate features and target variable\n",
    "X = wine_data[feature_columns]\n",
    "y = wine_data[target_column]\n",
    "\n",
    "# Convert 'quality' column to numerical values\n",
    "y = pd.to_numeric(y, errors='coerce')  # Coerce non-numeric values to NaN\n",
    "y = y.fillna(0)  # Fill NaN values with 0 (for example purposes, you may use other strategies)\n",
    "\n",
    "# Define binary classes: 'good' and 'not good'\n",
    "y = (y >= 7).astype(int)\n",
    "\n",
    "# Perform a train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Further split the training set into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform both training and validation data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create the Sequential model and add the layers\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(X_train_scaled.shape[1],)),  # Input layer\n",
    "    tf.keras.layers.Dense(64, activation='relu'),  # Hidden layer 1 with 64 neurons and ReLU activation\n",
    "    tf.keras.layers.Dense(32, activation='relu'),  # Hidden layer 2 with 32 neurons and ReLU activation\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  # Output layer with 1 neuron and sigmoid activation for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "\n",
    "# Create a directory for TensorBoard logs\n",
    "log_dir = \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# Create a TensorBoard callback\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Create an Early Stopping callback to monitor validation loss and stop training if no improvement is observed for 5 epochs\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Create a ModelCheckpoint callback to save the best model based on validation accuracy\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath='best_model.h5', monitor='val_accuracy', save_best_only=True, mode='max')\n",
    "\n",
    "# Train the model with both the TensorBoard, Early Stopping, and ModelCheckpoint callbacks\n",
    "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_data=(X_val_scaled, y_val), callbacks=[tensorboard_callback, early_stopping_callback, checkpoint_callback])\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519b875f",
   "metadata": {},
   "source": [
    "The model.summary() line added to the code will print the model summary in the console or output. It will display the details of each layer in the model, including the layer type, output shape, and the number of trainable parameters. This summary is helpful to understand the model architecture and the flow of information through the network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267e92a5",
   "metadata": {},
   "source": [
    "# Q13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6012938b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q13. Use binary cross-entropy as the loss function, Adam optimizer, and include the metric ['accuracy']."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4f153a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Sequential model and add the layers\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(X_train_scaled.shape[1],)),  # Input layer\n",
    "    tf.keras.layers.Dense(64, activation='relu'),  # Hidden layer 1 with 64 neurons and ReLU activation\n",
    "    tf.keras.layers.Dense(32, activation='relu'),  # Hidden layer 2 with 32 neurons and ReLU activation\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  # Output layer with 1 neuron and sigmoid activation for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# ... Rest of the code ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb56dfb",
   "metadata": {},
   "source": [
    "In this part of the code, the model is compiled using the Adam optimizer and binary cross-entropy as the loss function for binary classification. The 'accuracy' metric is included to monitor the model's performance during training. The model.compile() function specifies these settings, and the optimizer, loss function, and metrics will be used during training and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2517b42",
   "metadata": {},
   "source": [
    "# Q14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bcdfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q14. Compile the model with the specified loss function, optimizer, and metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2e9421bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Load the Wine dataset from the CSV file\n",
    "wine_data = pd.read_csv('wine.csv')\n",
    "\n",
    "# Column names for features (input variables) and the target variable\n",
    "feature_columns = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol']\n",
    "target_column = 'quality'\n",
    "\n",
    "# Separate features and target variable\n",
    "X = wine_data[feature_columns]\n",
    "y = wine_data[target_column]\n",
    "\n",
    "# Convert 'quality' column to numerical values\n",
    "y = pd.to_numeric(y, errors='coerce')  # Coerce non-numeric values to NaN\n",
    "y = y.fillna(0)  # Fill NaN values with 0 (for example purposes, you may use other strategies)\n",
    "\n",
    "# Define binary classes: 'good' and 'not good'\n",
    "y = (y >= 7).astype(int)\n",
    "\n",
    "# Perform a train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Further split the training set into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform both training and validation data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create the Sequential model and add the layers\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(X_train_scaled.shape[1],)),  # Input layer\n",
    "    tf.keras.layers.Dense(64, activation='relu'),  # Hidden layer 1 with 64 neurons and ReLU activation\n",
    "    tf.keras.layers.Dense(32, activation='relu'),  # Hidden layer 2 with 32 neurons and ReLU activation\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  # Output layer with 1 neuron and sigmoid activation for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model with specified loss function, optimizer, and metrics\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# ... Rest of the code ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "06f1e1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Sequential model and add the layers\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(X_train_scaled.shape[1],)),  # Input layer\n",
    "    tf.keras.layers.Dense(64, activation='relu'),  # Hidden layer 1 with 64 neurons and ReLU activation\n",
    "    tf.keras.layers.Dense(32, activation='relu'),  # Hidden layer 2 with 32 neurons and ReLU activation\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  # Output layer with 1 neuron and sigmoid activation for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model with specified loss function, optimizer, and metrics\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9253e9b2",
   "metadata": {},
   "source": [
    "In this code, we create a Sequential model with three layers (input, two hidden, and output). Then, we use the compile() method to compile the model with the following settings:\n",
    "\n",
    "optimizer='adam': Adam optimizer, a popular optimizer for gradient-based optimization.\n",
    "loss='binary_crossentropy': Binary cross-entropy loss function, appropriate for binary classification problems.\n",
    "metrics=['accuracy']: The accuracy metric is used to monitor the model's performance during training and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cacece",
   "metadata": {},
   "source": [
    "# Q15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143f0c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q15. Fit the model to the data, incorporating the TensorBoard, Early Stopping, and ModelCheckpoint\n",
    "callbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af1f7622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_27 (Dense)            (None, 64)                768       \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2881 (11.25 KB)\n",
      "Trainable params: 2881 (11.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "32/32 [==============================] - 1s 15ms/step - loss: 0.3569 - accuracy: 0.9648 - val_loss: 0.1471 - val_accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "13/32 [===========>..................] - ETA: 0s - loss: 0.1082 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0740 - accuracy: 1.0000 - val_loss: 0.0344 - val_accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 9.1432e-04 - accuracy: 1.0000 - val_loss: 8.4820e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.2398e-04 - accuracy: 1.0000 - val_loss: 6.9220e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.9173e-04 - accuracy: 1.0000 - val_loss: 5.6859e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.8912e-04 - accuracy: 1.0000 - val_loss: 4.8000e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.1322e-04 - accuracy: 1.0000 - val_loss: 4.0647e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 3.5221e-04 - accuracy: 1.0000 - val_loss: 3.4988e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 3.0366e-04 - accuracy: 1.0000 - val_loss: 3.0491e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.6484e-04 - accuracy: 1.0000 - val_loss: 2.6751e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.3236e-04 - accuracy: 1.0000 - val_loss: 2.3777e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.0601e-04 - accuracy: 1.0000 - val_loss: 2.1181e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.8359e-04 - accuracy: 1.0000 - val_loss: 1.8971e-04 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 1.6447e-04 - accuracy: 1.0000 - val_loss: 1.7124e-04 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.4833e-04 - accuracy: 1.0000 - val_loss: 1.5498e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.3432e-04 - accuracy: 1.0000 - val_loss: 1.4098e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.2205e-04 - accuracy: 1.0000 - val_loss: 1.2903e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.1162e-04 - accuracy: 1.0000 - val_loss: 1.1811e-04 - val_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.0213e-04 - accuracy: 1.0000 - val_loss: 1.0894e-04 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 9.4002e-05 - accuracy: 1.0000 - val_loss: 1.0048e-04 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 8.6663e-05 - accuracy: 1.0000 - val_loss: 9.3106e-05 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 8.0229e-05 - accuracy: 1.0000 - val_loss: 8.6235e-05 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.4404e-05 - accuracy: 1.0000 - val_loss: 8.0148e-05 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 6.9050e-05 - accuracy: 1.0000 - val_loss: 7.5084e-05 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 6.4530e-05 - accuracy: 1.0000 - val_loss: 6.9898e-05 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 6.0140e-05 - accuracy: 1.0000 - val_loss: 6.5527e-05 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.6246e-05 - accuracy: 1.0000 - val_loss: 6.1659e-05 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 5.2773e-05 - accuracy: 1.0000 - val_loss: 5.7931e-05 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.9527e-05 - accuracy: 1.0000 - val_loss: 5.4676e-05 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.6620e-05 - accuracy: 1.0000 - val_loss: 5.1448e-05 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.3957e-05 - accuracy: 1.0000 - val_loss: 4.8387e-05 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.1398e-05 - accuracy: 1.0000 - val_loss: 4.5820e-05 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.9109e-05 - accuracy: 1.0000 - val_loss: 4.3476e-05 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 3.7008e-05 - accuracy: 1.0000 - val_loss: 4.1232e-05 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 3.5062e-05 - accuracy: 1.0000 - val_loss: 3.9108e-05 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.3228e-05 - accuracy: 1.0000 - val_loss: 3.7197e-05 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 3.1545e-05 - accuracy: 1.0000 - val_loss: 3.5392e-05 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 2.9991e-05 - accuracy: 1.0000 - val_loss: 3.3667e-05 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 2.8525e-05 - accuracy: 1.0000 - val_loss: 3.2066e-05 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 2.7175e-05 - accuracy: 1.0000 - val_loss: 3.0566e-05 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.5888e-05 - accuracy: 1.0000 - val_loss: 2.9178e-05 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 2.4691e-05 - accuracy: 1.0000 - val_loss: 2.7906e-05 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.3574e-05 - accuracy: 1.0000 - val_loss: 2.6699e-05 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 2.2519e-05 - accuracy: 1.0000 - val_loss: 2.5586e-05 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.1552e-05 - accuracy: 1.0000 - val_loss: 2.4475e-05 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 2.0604e-05 - accuracy: 1.0000 - val_loss: 2.3497e-05 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.9750e-05 - accuracy: 1.0000 - val_loss: 2.2505e-05 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.8913e-05 - accuracy: 1.0000 - val_loss: 2.1638e-05 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 1.8149e-05 - accuracy: 1.0000 - val_loss: 2.0751e-05 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 9ms/step - loss: 1.7412e-05 - accuracy: 1.0000 - val_loss: 1.9923e-05 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.6699e-05 - accuracy: 1.0000 - val_loss: 1.9211e-05 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.6072e-05 - accuracy: 1.0000 - val_loss: 1.8436e-05 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.5428e-05 - accuracy: 1.0000 - val_loss: 1.7769e-05 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.4839e-05 - accuracy: 1.0000 - val_loss: 1.7120e-05 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.4285e-05 - accuracy: 1.0000 - val_loss: 1.6478e-05 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.3757e-05 - accuracy: 1.0000 - val_loss: 1.5858e-05 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.3237e-05 - accuracy: 1.0000 - val_loss: 1.5307e-05 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.2754e-05 - accuracy: 1.0000 - val_loss: 1.4789e-05 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.2302e-05 - accuracy: 1.0000 - val_loss: 1.4287e-05 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.1868e-05 - accuracy: 1.0000 - val_loss: 1.3782e-05 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.1455e-05 - accuracy: 1.0000 - val_loss: 1.3296e-05 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.1050e-05 - accuracy: 1.0000 - val_loss: 1.2860e-05 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0670e-05 - accuracy: 1.0000 - val_loss: 1.2435e-05 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0312e-05 - accuracy: 1.0000 - val_loss: 1.2022e-05 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 9.9625e-06 - accuracy: 1.0000 - val_loss: 1.1636e-05 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 9.6338e-06 - accuracy: 1.0000 - val_loss: 1.1257e-05 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 9.3137e-06 - accuracy: 1.0000 - val_loss: 1.0907e-05 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 9.0126e-06 - accuracy: 1.0000 - val_loss: 1.0555e-05 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 8.7251e-06 - accuracy: 1.0000 - val_loss: 1.0219e-05 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 8.4463e-06 - accuracy: 1.0000 - val_loss: 9.8877e-06 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 8.1687e-06 - accuracy: 1.0000 - val_loss: 9.6090e-06 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.9239e-06 - accuracy: 1.0000 - val_loss: 9.3041e-06 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.6730e-06 - accuracy: 1.0000 - val_loss: 9.0254e-06 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 7.4362e-06 - accuracy: 1.0000 - val_loss: 8.7677e-06 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.2177e-06 - accuracy: 1.0000 - val_loss: 8.4859e-06 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.9878e-06 - accuracy: 1.0000 - val_loss: 8.2625e-06 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.7857e-06 - accuracy: 1.0000 - val_loss: 8.0085e-06 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.5851e-06 - accuracy: 1.0000 - val_loss: 7.7653e-06 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.3819e-06 - accuracy: 1.0000 - val_loss: 7.5619e-06 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.1999e-06 - accuracy: 1.0000 - val_loss: 7.3418e-06 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.0186e-06 - accuracy: 1.0000 - val_loss: 7.1353e-06 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.8467e-06 - accuracy: 1.0000 - val_loss: 6.9256e-06 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.6752e-06 - accuracy: 1.0000 - val_loss: 6.7374e-06 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.5139e-06 - accuracy: 1.0000 - val_loss: 6.5575e-06 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.3616e-06 - accuracy: 1.0000 - val_loss: 6.3728e-06 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 5.2107e-06 - accuracy: 1.0000 - val_loss: 6.1914e-06 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.0645e-06 - accuracy: 1.0000 - val_loss: 6.0216e-06 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.9208e-06 - accuracy: 1.0000 - val_loss: 5.8800e-06 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.7895e-06 - accuracy: 1.0000 - val_loss: 5.7152e-06 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.6598e-06 - accuracy: 1.0000 - val_loss: 5.5551e-06 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 4.5325e-06 - accuracy: 1.0000 - val_loss: 5.4040e-06 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 4.4085e-06 - accuracy: 1.0000 - val_loss: 5.2647e-06 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.2885e-06 - accuracy: 1.0000 - val_loss: 5.1428e-06 - val_accuracy: 1.0000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 4.9250e-06 - accuracy: 1.0000\n",
      "Test Loss: 4.924958375340793e-06\n",
      "Test Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Load the Wine dataset from the CSV file\n",
    "wine_data = pd.read_csv('wine.csv')\n",
    "\n",
    "# Column names for features (input variables) and the target variable\n",
    "feature_columns = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol']\n",
    "target_column = 'quality'\n",
    "\n",
    "# Separate features and target variable\n",
    "X = wine_data[feature_columns]\n",
    "y = wine_data[target_column]\n",
    "\n",
    "# Convert 'quality' column to numerical values\n",
    "y = pd.to_numeric(y, errors='coerce')  # Coerce non-numeric values to NaN\n",
    "y = y.fillna(0)  # Fill NaN values with 0 (for example purposes, you may use other strategies)\n",
    "\n",
    "# Define binary classes: 'good' and 'not good'\n",
    "y = (y >= 7).astype(int)\n",
    "\n",
    "# Perform a train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Further split the training set into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform both training and validation data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create the Sequential model and add the layers\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(X_train_scaled.shape[1],)),  # Input layer\n",
    "    tf.keras.layers.Dense(64, activation='relu'),  # Hidden layer 1 with 64 neurons and ReLU activation\n",
    "    tf.keras.layers.Dense(32, activation='relu'),  # Hidden layer 2 with 32 neurons and ReLU activation\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  # Output layer with 1 neuron and sigmoid activation for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model with specified loss function, optimizer, and metrics\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "\n",
    "# Create a directory for TensorBoard logs\n",
    "log_dir = \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# Create a TensorBoard callback\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Create an Early Stopping callback to monitor validation loss and stop training if no improvement is observed for 5 epochs\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Create a ModelCheckpoint callback to save the best model based on validation accuracy\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath='best_model.h5', monitor='val_accuracy', save_best_only=True, mode='max')\n",
    "\n",
    "# Train the model with both the TensorBoard, Early Stopping, and ModelCheckpoint callbacks\n",
    "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_data=(X_val_scaled, y_val), callbacks=[tensorboard_callback, early_stopping_callback, checkpoint_callback])\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf59ce3e",
   "metadata": {},
   "source": [
    "This code will train the model using the training data, validate it using the validation data, and monitor the training process using TensorBoard, Early Stopping, and ModelCheckpoint callbacks. The trained model will be saved in 'best_model.h5', and the test loss and accuracy will be printed at the end of training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233ce46a",
   "metadata": {},
   "source": [
    "# Q16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9165a73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q16. Get the model's parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "413fa1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 - Weights shape: (11, 64)\n",
      "Layer 2 - Weights shape: (64,)\n",
      "Layer 3 - Weights shape: (64, 32)\n",
      "Layer 4 - Weights shape: (32,)\n",
      "Layer 5 - Weights shape: (32, 1)\n",
      "Layer 6 - Weights shape: (1,)\n"
     ]
    }
   ],
   "source": [
    "# ... (previous code for model creation, compilation, and training) ...\n",
    "\n",
    "# Get the model's parameters\n",
    "model_parameters = model.get_weights()\n",
    "\n",
    "# Print the model's parameters\n",
    "for layer_num, layer_weights in enumerate(model_parameters):\n",
    "    print(f\"Layer {layer_num + 1} - Weights shape: {layer_weights.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8ac4f5",
   "metadata": {},
   "source": [
    "The model.get_weights() call will return a list of arrays, where each array contains the weights and biases of a layer. The shape of each array corresponds to the shape of the layer's weights and biases.\n",
    "\n",
    "In the loop, we iterate through the list of model parameters and print the shape of each array, which represents the shape of the weights and biases for each layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d085c7",
   "metadata": {},
   "source": [
    "# Q17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a2fd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q17. Store the model's training history as a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54ad9e6",
   "metadata": {},
   "source": [
    "Ans:-\n",
    "    \n",
    "    To store the model's training history as a Pandas DataFrame, you can use the history object returned by the fit() method. The history object contains information about the training metrics (e.g., loss, accuracy) at each epoch. You can convert this information to a DataFrame for further analysis and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4f0ba5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 4.1784e-06 - accuracy: 1.0000 - val_loss: 5.0006e-06 - val_accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.0682e-06 - accuracy: 1.0000 - val_loss: 4.8628e-06 - val_accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 3.9589e-06 - accuracy: 1.0000 - val_loss: 4.7426e-06 - val_accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 3.8550e-06 - accuracy: 1.0000 - val_loss: 4.6238e-06 - val_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 3.7607e-06 - accuracy: 1.0000 - val_loss: 4.4941e-06 - val_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 3.6572e-06 - accuracy: 1.0000 - val_loss: 4.3901e-06 - val_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 3.5667e-06 - accuracy: 1.0000 - val_loss: 4.2747e-06 - val_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 3.4738e-06 - accuracy: 1.0000 - val_loss: 4.1676e-06 - val_accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 3.3847e-06 - accuracy: 1.0000 - val_loss: 4.0696e-06 - val_accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 3.3000e-06 - accuracy: 1.0000 - val_loss: 3.9723e-06 - val_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 3.2194e-06 - accuracy: 1.0000 - val_loss: 3.8649e-06 - val_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.1351e-06 - accuracy: 1.0000 - val_loss: 3.7779e-06 - val_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.0577e-06 - accuracy: 1.0000 - val_loss: 3.6903e-06 - val_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.9867e-06 - accuracy: 1.0000 - val_loss: 3.5874e-06 - val_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.9083e-06 - accuracy: 1.0000 - val_loss: 3.5037e-06 - val_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.8366e-06 - accuracy: 1.0000 - val_loss: 3.4217e-06 - val_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.7680e-06 - accuracy: 1.0000 - val_loss: 3.3410e-06 - val_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 2.7013e-06 - accuracy: 1.0000 - val_loss: 3.2585e-06 - val_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 2.6351e-06 - accuracy: 1.0000 - val_loss: 3.1822e-06 - val_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.5719e-06 - accuracy: 1.0000 - val_loss: 3.1061e-06 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.5095e-06 - accuracy: 1.0000 - val_loss: 3.0355e-06 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 2.4494e-06 - accuracy: 1.0000 - val_loss: 2.9680e-06 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.3927e-06 - accuracy: 1.0000 - val_loss: 2.8941e-06 - val_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.3347e-06 - accuracy: 1.0000 - val_loss: 2.8273e-06 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 2.2804e-06 - accuracy: 1.0000 - val_loss: 2.7603e-06 - val_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.2252e-06 - accuracy: 1.0000 - val_loss: 2.7032e-06 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 2.1740e-06 - accuracy: 1.0000 - val_loss: 2.6423e-06 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.1250e-06 - accuracy: 1.0000 - val_loss: 2.5745e-06 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 2.0743e-06 - accuracy: 1.0000 - val_loss: 2.5145e-06 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.0251e-06 - accuracy: 1.0000 - val_loss: 2.4604e-06 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.9793e-06 - accuracy: 1.0000 - val_loss: 2.4022e-06 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.9332e-06 - accuracy: 1.0000 - val_loss: 2.3494e-06 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.8886e-06 - accuracy: 1.0000 - val_loss: 2.2999e-06 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.8469e-06 - accuracy: 1.0000 - val_loss: 2.2461e-06 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.8035e-06 - accuracy: 1.0000 - val_loss: 2.1971e-06 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.7647e-06 - accuracy: 1.0000 - val_loss: 2.1437e-06 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.7230e-06 - accuracy: 1.0000 - val_loss: 2.0975e-06 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.6848e-06 - accuracy: 1.0000 - val_loss: 2.0499e-06 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.6467e-06 - accuracy: 1.0000 - val_loss: 2.0051e-06 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.6099e-06 - accuracy: 1.0000 - val_loss: 1.9612e-06 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.5736e-06 - accuracy: 1.0000 - val_loss: 1.9200e-06 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.5385e-06 - accuracy: 1.0000 - val_loss: 1.8806e-06 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.5047e-06 - accuracy: 1.0000 - val_loss: 1.8407e-06 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.4720e-06 - accuracy: 1.0000 - val_loss: 1.7989e-06 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.4400e-06 - accuracy: 1.0000 - val_loss: 1.7571e-06 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.4075e-06 - accuracy: 1.0000 - val_loss: 1.7190e-06 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.3761e-06 - accuracy: 1.0000 - val_loss: 1.6839e-06 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.3475e-06 - accuracy: 1.0000 - val_loss: 1.6453e-06 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.3168e-06 - accuracy: 1.0000 - val_loss: 1.6113e-06 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.2880e-06 - accuracy: 1.0000 - val_loss: 1.5794e-06 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.2614e-06 - accuracy: 1.0000 - val_loss: 1.5443e-06 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.2340e-06 - accuracy: 1.0000 - val_loss: 1.5091e-06 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.2066e-06 - accuracy: 1.0000 - val_loss: 1.4772e-06 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.1803e-06 - accuracy: 1.0000 - val_loss: 1.4479e-06 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 6ms/step - loss: 1.1552e-06 - accuracy: 1.0000 - val_loss: 1.4183e-06 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.1313e-06 - accuracy: 1.0000 - val_loss: 1.3859e-06 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.1058e-06 - accuracy: 1.0000 - val_loss: 1.3616e-06 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.0834e-06 - accuracy: 1.0000 - val_loss: 1.3303e-06 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.0599e-06 - accuracy: 1.0000 - val_loss: 1.3020e-06 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.0375e-06 - accuracy: 1.0000 - val_loss: 1.2742e-06 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0155e-06 - accuracy: 1.0000 - val_loss: 1.2474e-06 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 9.9370e-07 - accuracy: 1.0000 - val_loss: 1.2228e-06 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 9.7346e-07 - accuracy: 1.0000 - val_loss: 1.1961e-06 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 9.5262e-07 - accuracy: 1.0000 - val_loss: 1.1723e-06 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 9.3279e-07 - accuracy: 1.0000 - val_loss: 1.1473e-06 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 9.1346e-07 - accuracy: 1.0000 - val_loss: 1.1230e-06 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 8.9400e-07 - accuracy: 1.0000 - val_loss: 1.1006e-06 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.7559e-07 - accuracy: 1.0000 - val_loss: 1.0776e-06 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.5752e-07 - accuracy: 1.0000 - val_loss: 1.0552e-06 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 8.3990e-07 - accuracy: 1.0000 - val_loss: 1.0329e-06 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.2196e-07 - accuracy: 1.0000 - val_loss: 1.0126e-06 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 8.0506e-07 - accuracy: 1.0000 - val_loss: 9.9266e-07 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.8882e-07 - accuracy: 1.0000 - val_loss: 9.7301e-07 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.7247e-07 - accuracy: 1.0000 - val_loss: 9.5348e-07 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 7.5689e-07 - accuracy: 1.0000 - val_loss: 9.3320e-07 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.4118e-07 - accuracy: 1.0000 - val_loss: 9.1468e-07 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 7.2593e-07 - accuracy: 1.0000 - val_loss: 8.9659e-07 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.1103e-07 - accuracy: 1.0000 - val_loss: 8.7936e-07 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.9704e-07 - accuracy: 1.0000 - val_loss: 8.6088e-07 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.8254e-07 - accuracy: 1.0000 - val_loss: 8.4380e-07 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.6935e-07 - accuracy: 1.0000 - val_loss: 8.2557e-07 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 6.5512e-07 - accuracy: 1.0000 - val_loss: 8.0955e-07 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 6.4177e-07 - accuracy: 1.0000 - val_loss: 7.9441e-07 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.2886e-07 - accuracy: 1.0000 - val_loss: 7.7941e-07 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 6.1661e-07 - accuracy: 1.0000 - val_loss: 7.6281e-07 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.0403e-07 - accuracy: 1.0000 - val_loss: 7.4744e-07 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.9219e-07 - accuracy: 1.0000 - val_loss: 7.3169e-07 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.7977e-07 - accuracy: 1.0000 - val_loss: 7.1877e-07 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.6842e-07 - accuracy: 1.0000 - val_loss: 7.0486e-07 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.5740e-07 - accuracy: 1.0000 - val_loss: 6.8964e-07 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.4590e-07 - accuracy: 1.0000 - val_loss: 6.7634e-07 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.3505e-07 - accuracy: 1.0000 - val_loss: 6.6386e-07 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.2472e-07 - accuracy: 1.0000 - val_loss: 6.4993e-07 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.1395e-07 - accuracy: 1.0000 - val_loss: 6.3779e-07 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 5.0402e-07 - accuracy: 1.0000 - val_loss: 6.2482e-07 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.9405e-07 - accuracy: 1.0000 - val_loss: 6.1231e-07 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.8403e-07 - accuracy: 1.0000 - val_loss: 6.0101e-07 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.7458e-07 - accuracy: 1.0000 - val_loss: 5.9034e-07 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.6532e-07 - accuracy: 1.0000 - val_loss: 5.7882e-07 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.5645e-07 - accuracy: 1.0000 - val_loss: 5.6626e-07 - val_accuracy: 1.0000\n",
      "       loss  accuracy  val_loss  val_accuracy\n",
      "0  0.000004       1.0  0.000005           1.0\n",
      "1  0.000004       1.0  0.000005           1.0\n",
      "2  0.000004       1.0  0.000005           1.0\n",
      "3  0.000004       1.0  0.000005           1.0\n",
      "4  0.000004       1.0  0.000004           1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# ... (previous code for data loading, preprocessing, model creation, and compilation) ...\n",
    "\n",
    "# Train the model and get the history\n",
    "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_data=(X_val_scaled, y_val), callbacks=[tensorboard_callback, early_stopping_callback, checkpoint_callback])\n",
    "\n",
    "# Convert the history to a Pandas DataFrame\n",
    "history_df = pd.DataFrame(history.history)\n",
    "\n",
    "# Print the history DataFrame\n",
    "print(history_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0688a7f",
   "metadata": {},
   "source": [
    "The history.history attribute contains a dictionary with the training and validation metrics at each epoch. We convert this dictionary to a Pandas DataFrame using pd.DataFrame(history.history), where each column of the DataFrame represents a metric (e.g., 'loss', 'accuracy', 'val_loss', 'val_accuracy'), and each row corresponds to a training epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c62931",
   "metadata": {},
   "source": [
    "# Q18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13cb809",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q18. Plot the model's training history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ed294a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 4.4717e-07 - accuracy: 1.0000 - val_loss: 5.5529e-07 - val_accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.3816e-07 - accuracy: 1.0000 - val_loss: 5.4550e-07 - val_accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.3012e-07 - accuracy: 1.0000 - val_loss: 5.3373e-07 - val_accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.2135e-07 - accuracy: 1.0000 - val_loss: 5.2372e-07 - val_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 4.1324e-07 - accuracy: 1.0000 - val_loss: 5.1331e-07 - val_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 4.0498e-07 - accuracy: 1.0000 - val_loss: 5.0455e-07 - val_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 3.9749e-07 - accuracy: 1.0000 - val_loss: 4.9368e-07 - val_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 3.8946e-07 - accuracy: 1.0000 - val_loss: 4.8476e-07 - val_accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 3.8211e-07 - accuracy: 1.0000 - val_loss: 4.7489e-07 - val_accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.7439e-07 - accuracy: 1.0000 - val_loss: 4.6639e-07 - val_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 3.6728e-07 - accuracy: 1.0000 - val_loss: 4.5743e-07 - val_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.6024e-07 - accuracy: 1.0000 - val_loss: 4.4884e-07 - val_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.5336e-07 - accuracy: 1.0000 - val_loss: 4.3958e-07 - val_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.4649e-07 - accuracy: 1.0000 - val_loss: 4.3105e-07 - val_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.3959e-07 - accuracy: 1.0000 - val_loss: 4.2335e-07 - val_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 3.3313e-07 - accuracy: 1.0000 - val_loss: 4.1555e-07 - val_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 3.2685e-07 - accuracy: 1.0000 - val_loss: 4.0731e-07 - val_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.2056e-07 - accuracy: 1.0000 - val_loss: 3.9940e-07 - val_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.1427e-07 - accuracy: 1.0000 - val_loss: 3.9237e-07 - val_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.0852e-07 - accuracy: 1.0000 - val_loss: 3.8409e-07 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.0231e-07 - accuracy: 1.0000 - val_loss: 3.7721e-07 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.9660e-07 - accuracy: 1.0000 - val_loss: 3.7021e-07 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 2.9099e-07 - accuracy: 1.0000 - val_loss: 3.6305e-07 - val_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 2.8550e-07 - accuracy: 1.0000 - val_loss: 3.5597e-07 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.7997e-07 - accuracy: 1.0000 - val_loss: 3.4930e-07 - val_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 2.7455e-07 - accuracy: 1.0000 - val_loss: 3.4312e-07 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.6941e-07 - accuracy: 1.0000 - val_loss: 3.3676e-07 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.6424e-07 - accuracy: 1.0000 - val_loss: 3.3063e-07 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.5931e-07 - accuracy: 1.0000 - val_loss: 3.2394e-07 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.5429e-07 - accuracy: 1.0000 - val_loss: 3.1785e-07 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 2.4945e-07 - accuracy: 1.0000 - val_loss: 3.1189e-07 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.4468e-07 - accuracy: 1.0000 - val_loss: 3.0671e-07 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.4031e-07 - accuracy: 1.0000 - val_loss: 2.9999e-07 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.3555e-07 - accuracy: 1.0000 - val_loss: 2.9439e-07 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.3114e-07 - accuracy: 1.0000 - val_loss: 2.8877e-07 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.2673e-07 - accuracy: 1.0000 - val_loss: 2.8360e-07 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 2.2246e-07 - accuracy: 1.0000 - val_loss: 2.7850e-07 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.1835e-07 - accuracy: 1.0000 - val_loss: 2.7299e-07 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.1424e-07 - accuracy: 1.0000 - val_loss: 2.6781e-07 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.1018e-07 - accuracy: 1.0000 - val_loss: 2.6290e-07 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.0622e-07 - accuracy: 1.0000 - val_loss: 2.5808e-07 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 2.0240e-07 - accuracy: 1.0000 - val_loss: 2.5305e-07 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.9857e-07 - accuracy: 1.0000 - val_loss: 2.4837e-07 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.9476e-07 - accuracy: 1.0000 - val_loss: 2.4411e-07 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.9147e-07 - accuracy: 1.0000 - val_loss: 2.3917e-07 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.8751e-07 - accuracy: 1.0000 - val_loss: 2.3529e-07 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.8427e-07 - accuracy: 1.0000 - val_loss: 2.3049e-07 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.8059e-07 - accuracy: 1.0000 - val_loss: 2.2691e-07 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.7745e-07 - accuracy: 1.0000 - val_loss: 2.2215e-07 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.7403e-07 - accuracy: 1.0000 - val_loss: 2.1803e-07 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.7080e-07 - accuracy: 1.0000 - val_loss: 2.1394e-07 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.6756e-07 - accuracy: 1.0000 - val_loss: 2.1017e-07 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.6446e-07 - accuracy: 1.0000 - val_loss: 2.0647e-07 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.6141e-07 - accuracy: 1.0000 - val_loss: 2.0282e-07 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 13ms/step - loss: 1.5844e-07 - accuracy: 1.0000 - val_loss: 1.9919e-07 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.5554e-07 - accuracy: 1.0000 - val_loss: 1.9510e-07 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.5269e-07 - accuracy: 1.0000 - val_loss: 1.9128e-07 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.4974e-07 - accuracy: 1.0000 - val_loss: 1.8796e-07 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.4703e-07 - accuracy: 1.0000 - val_loss: 1.8435e-07 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.4426e-07 - accuracy: 1.0000 - val_loss: 1.8106e-07 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.4160e-07 - accuracy: 1.0000 - val_loss: 1.7789e-07 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.3900e-07 - accuracy: 1.0000 - val_loss: 1.7462e-07 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.3651e-07 - accuracy: 1.0000 - val_loss: 1.7133e-07 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.3392e-07 - accuracy: 1.0000 - val_loss: 1.6820e-07 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.3148e-07 - accuracy: 1.0000 - val_loss: 1.6517e-07 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.2907e-07 - accuracy: 1.0000 - val_loss: 1.6202e-07 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.2667e-07 - accuracy: 1.0000 - val_loss: 1.5907e-07 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.2433e-07 - accuracy: 1.0000 - val_loss: 1.5627e-07 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.2207e-07 - accuracy: 1.0000 - val_loss: 1.5345e-07 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.1987e-07 - accuracy: 1.0000 - val_loss: 1.5060e-07 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.1767e-07 - accuracy: 1.0000 - val_loss: 1.4772e-07 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.1548e-07 - accuracy: 1.0000 - val_loss: 1.4503e-07 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.1337e-07 - accuracy: 1.0000 - val_loss: 1.4237e-07 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.1129e-07 - accuracy: 1.0000 - val_loss: 1.3991e-07 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0931e-07 - accuracy: 1.0000 - val_loss: 1.3721e-07 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 1.0727e-07 - accuracy: 1.0000 - val_loss: 1.3477e-07 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.0529e-07 - accuracy: 1.0000 - val_loss: 1.3250e-07 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0341e-07 - accuracy: 1.0000 - val_loss: 1.2997e-07 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0148e-07 - accuracy: 1.0000 - val_loss: 1.2774e-07 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 9.9655e-08 - accuracy: 1.0000 - val_loss: 1.2543e-07 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 9.7854e-08 - accuracy: 1.0000 - val_loss: 1.2323e-07 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 9.6077e-08 - accuracy: 1.0000 - val_loss: 1.2088e-07 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 9.4295e-08 - accuracy: 1.0000 - val_loss: 1.1874e-07 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 9.2598e-08 - accuracy: 1.0000 - val_loss: 1.1659e-07 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 9.0969e-08 - accuracy: 1.0000 - val_loss: 1.1431e-07 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 8.9243e-08 - accuracy: 1.0000 - val_loss: 1.1240e-07 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 8.7656e-08 - accuracy: 1.0000 - val_loss: 1.1030e-07 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 8.6067e-08 - accuracy: 1.0000 - val_loss: 1.0826e-07 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 8.4507e-08 - accuracy: 1.0000 - val_loss: 1.0630e-07 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 8.2962e-08 - accuracy: 1.0000 - val_loss: 1.0448e-07 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 8.1498e-08 - accuracy: 1.0000 - val_loss: 1.0254e-07 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.0016e-08 - accuracy: 1.0000 - val_loss: 1.0061e-07 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 7.8554e-08 - accuracy: 1.0000 - val_loss: 9.8797e-08 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.7111e-08 - accuracy: 1.0000 - val_loss: 9.7110e-08 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.5783e-08 - accuracy: 1.0000 - val_loss: 9.5253e-08 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.4344e-08 - accuracy: 1.0000 - val_loss: 9.3658e-08 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 7.3023e-08 - accuracy: 1.0000 - val_loss: 9.2236e-08 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 7.1762e-08 - accuracy: 1.0000 - val_loss: 9.0361e-08 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 7.0431e-08 - accuracy: 1.0000 - val_loss: 8.8691e-08 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.9177e-08 - accuracy: 1.0000 - val_loss: 8.7113e-08 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from datetime import datetime\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ... (previous code for data loading, preprocessing, model creation, and compilation) ...\n",
    "\n",
    "# Train the model and get the history\n",
    "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_data=(X_val_scaled, y_val), callbacks=[tensorboard_callback, early_stopping_callback, checkpoint_callback])\n",
    "\n",
    "# Convert the history to a Pandas DataFrame\n",
    "history_df = pd.DataFrame(history.history)\n",
    "\n",
    "# Plot the training and validation loss\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(history_df['loss'], label='Training Loss')\n",
    "plt.plot(history_df['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n",
    "\n",
    "# Plot the training and validation accuracy\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(history_df['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history_df['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29244902",
   "metadata": {},
   "source": [
    "In this code, we use matplotlib to create two separate plots. The first plot shows the training and validation loss over epochs, while the second plot shows the training and validation accuracy over epochs. The x-axis represents the training epochs, and the y-axis represents the corresponding loss or accuracy values. The legend in each plot distinguishes between training and validation metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df963142",
   "metadata": {},
   "source": [
    "# Q19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2361b4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q19. Evaluate the model's performance using the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1d57f4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 6.7949e-08 - accuracy: 1.0000 - val_loss: 8.5427e-08 - val_accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.6655e-08 - accuracy: 1.0000 - val_loss: 8.4132e-08 - val_accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 6.5512e-08 - accuracy: 1.0000 - val_loss: 8.2494e-08 - val_accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 6.4348e-08 - accuracy: 1.0000 - val_loss: 8.1028e-08 - val_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.3195e-08 - accuracy: 1.0000 - val_loss: 7.9472e-08 - val_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 6.2048e-08 - accuracy: 1.0000 - val_loss: 7.8048e-08 - val_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 6.0930e-08 - accuracy: 1.0000 - val_loss: 7.6674e-08 - val_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 5.9835e-08 - accuracy: 1.0000 - val_loss: 7.5314e-08 - val_accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 5.8748e-08 - accuracy: 1.0000 - val_loss: 7.4154e-08 - val_accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.7766e-08 - accuracy: 1.0000 - val_loss: 7.2658e-08 - val_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.6660e-08 - accuracy: 1.0000 - val_loss: 7.1559e-08 - val_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.5708e-08 - accuracy: 1.0000 - val_loss: 7.0139e-08 - val_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 5.4699e-08 - accuracy: 1.0000 - val_loss: 6.8875e-08 - val_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.3725e-08 - accuracy: 1.0000 - val_loss: 6.7616e-08 - val_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.2733e-08 - accuracy: 1.0000 - val_loss: 6.6529e-08 - val_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.1839e-08 - accuracy: 1.0000 - val_loss: 6.5288e-08 - val_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.0925e-08 - accuracy: 1.0000 - val_loss: 6.4047e-08 - val_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.9972e-08 - accuracy: 1.0000 - val_loss: 6.3004e-08 - val_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.9139e-08 - accuracy: 1.0000 - val_loss: 6.1781e-08 - val_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.8208e-08 - accuracy: 1.0000 - val_loss: 6.0777e-08 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.7378e-08 - accuracy: 1.0000 - val_loss: 5.9760e-08 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.6547e-08 - accuracy: 1.0000 - val_loss: 5.8685e-08 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.5745e-08 - accuracy: 1.0000 - val_loss: 5.7523e-08 - val_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.4917e-08 - accuracy: 1.0000 - val_loss: 5.6497e-08 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.4108e-08 - accuracy: 1.0000 - val_loss: 5.5566e-08 - val_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.3342e-08 - accuracy: 1.0000 - val_loss: 5.4553e-08 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.2562e-08 - accuracy: 1.0000 - val_loss: 5.3657e-08 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.1827e-08 - accuracy: 1.0000 - val_loss: 5.2668e-08 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 4.1079e-08 - accuracy: 1.0000 - val_loss: 5.1844e-08 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.0358e-08 - accuracy: 1.0000 - val_loss: 5.0967e-08 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 3.9680e-08 - accuracy: 1.0000 - val_loss: 4.9931e-08 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 3.8963e-08 - accuracy: 1.0000 - val_loss: 4.9042e-08 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 3.8264e-08 - accuracy: 1.0000 - val_loss: 4.8197e-08 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 3.7620e-08 - accuracy: 1.0000 - val_loss: 4.7302e-08 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 3.6931e-08 - accuracy: 1.0000 - val_loss: 4.6495e-08 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 3.6294e-08 - accuracy: 1.0000 - val_loss: 4.5693e-08 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 3.5648e-08 - accuracy: 1.0000 - val_loss: 4.4951e-08 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 3.5044e-08 - accuracy: 1.0000 - val_loss: 4.4111e-08 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 3.4428e-08 - accuracy: 1.0000 - val_loss: 4.3324e-08 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 3.3804e-08 - accuracy: 1.0000 - val_loss: 4.2648e-08 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.3231e-08 - accuracy: 1.0000 - val_loss: 4.1879e-08 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 3.2659e-08 - accuracy: 1.0000 - val_loss: 4.1107e-08 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 3.2087e-08 - accuracy: 1.0000 - val_loss: 4.0375e-08 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 3.1508e-08 - accuracy: 1.0000 - val_loss: 3.9734e-08 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 3.0975e-08 - accuracy: 1.0000 - val_loss: 3.9038e-08 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 3.0432e-08 - accuracy: 1.0000 - val_loss: 3.8341e-08 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 2.9920e-08 - accuracy: 1.0000 - val_loss: 3.7628e-08 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.9378e-08 - accuracy: 1.0000 - val_loss: 3.7013e-08 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.8882e-08 - accuracy: 1.0000 - val_loss: 3.6335e-08 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 2.8368e-08 - accuracy: 1.0000 - val_loss: 3.5727e-08 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.7883e-08 - accuracy: 1.0000 - val_loss: 3.5101e-08 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 2.7395e-08 - accuracy: 1.0000 - val_loss: 3.4540e-08 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.6919e-08 - accuracy: 1.0000 - val_loss: 3.3949e-08 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 2.6457e-08 - accuracy: 1.0000 - val_loss: 3.3387e-08 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 7ms/step - loss: 2.6033e-08 - accuracy: 1.0000 - val_loss: 3.2699e-08 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.5548e-08 - accuracy: 1.0000 - val_loss: 3.2141e-08 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.5096e-08 - accuracy: 1.0000 - val_loss: 3.1694e-08 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.4706e-08 - accuracy: 1.0000 - val_loss: 3.1056e-08 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.4249e-08 - accuracy: 1.0000 - val_loss: 3.0536e-08 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.3838e-08 - accuracy: 1.0000 - val_loss: 3.0001e-08 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.3441e-08 - accuracy: 1.0000 - val_loss: 2.9444e-08 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.3016e-08 - accuracy: 1.0000 - val_loss: 2.8978e-08 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.2634e-08 - accuracy: 1.0000 - val_loss: 2.8462e-08 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.2236e-08 - accuracy: 1.0000 - val_loss: 2.7992e-08 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.1866e-08 - accuracy: 1.0000 - val_loss: 2.7495e-08 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.1478e-08 - accuracy: 1.0000 - val_loss: 2.7049e-08 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.1107e-08 - accuracy: 1.0000 - val_loss: 2.6660e-08 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.0770e-08 - accuracy: 1.0000 - val_loss: 2.6123e-08 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.0396e-08 - accuracy: 1.0000 - val_loss: 2.5679e-08 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.0060e-08 - accuracy: 1.0000 - val_loss: 2.5219e-08 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.9705e-08 - accuracy: 1.0000 - val_loss: 2.4802e-08 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.9371e-08 - accuracy: 1.0000 - val_loss: 2.4375e-08 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.9037e-08 - accuracy: 1.0000 - val_loss: 2.3986e-08 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.8731e-08 - accuracy: 1.0000 - val_loss: 2.3530e-08 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.8395e-08 - accuracy: 1.0000 - val_loss: 2.3168e-08 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.8082e-08 - accuracy: 1.0000 - val_loss: 2.2772e-08 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.7784e-08 - accuracy: 1.0000 - val_loss: 2.2360e-08 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.7476e-08 - accuracy: 1.0000 - val_loss: 2.1987e-08 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.7177e-08 - accuracy: 1.0000 - val_loss: 2.1651e-08 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.6898e-08 - accuracy: 1.0000 - val_loss: 2.1254e-08 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.6606e-08 - accuracy: 1.0000 - val_loss: 2.0875e-08 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.6327e-08 - accuracy: 1.0000 - val_loss: 2.0521e-08 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.6044e-08 - accuracy: 1.0000 - val_loss: 2.0183e-08 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.5771e-08 - accuracy: 1.0000 - val_loss: 1.9860e-08 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.5515e-08 - accuracy: 1.0000 - val_loss: 1.9506e-08 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.5248e-08 - accuracy: 1.0000 - val_loss: 1.9170e-08 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.4992e-08 - accuracy: 1.0000 - val_loss: 1.8846e-08 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.4744e-08 - accuracy: 1.0000 - val_loss: 1.8534e-08 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.4496e-08 - accuracy: 1.0000 - val_loss: 1.8223e-08 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.4248e-08 - accuracy: 1.0000 - val_loss: 1.7905e-08 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.4011e-08 - accuracy: 1.0000 - val_loss: 1.7602e-08 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.3773e-08 - accuracy: 1.0000 - val_loss: 1.7328e-08 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.3547e-08 - accuracy: 1.0000 - val_loss: 1.7025e-08 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.3320e-08 - accuracy: 1.0000 - val_loss: 1.6736e-08 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.3092e-08 - accuracy: 1.0000 - val_loss: 1.6476e-08 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.2886e-08 - accuracy: 1.0000 - val_loss: 1.6168e-08 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.2663e-08 - accuracy: 1.0000 - val_loss: 1.5900e-08 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.2452e-08 - accuracy: 1.0000 - val_loss: 1.5630e-08 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.2239e-08 - accuracy: 1.0000 - val_loss: 1.5419e-08 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.2050e-08 - accuracy: 1.0000 - val_loss: 1.5127e-08 - val_accuracy: 1.0000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.0857e-08 - accuracy: 1.0000\n",
      "Test Loss: 2.0856759874732234e-08\n",
      "Test Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# ... (previous code for data loading, preprocessing, model creation, and compilation) ...\n",
    "\n",
    "# Train the model and get the history\n",
    "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_data=(X_val_scaled, y_val), callbacks=[tensorboard_callback, early_stopping_callback, checkpoint_callback])\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a85a42",
   "metadata": {},
   "source": [
    "After training the model, we use the model.evaluate() method to evaluate the model's performance on the test set (X_test_scaled and y_test). The evaluate() method returns the test loss and metrics, which are printed to the console in this example.\n",
    "\n",
    "The test accuracy represents how well the model performs on unseen data, which is crucial for understanding the generalization performance of the model. Keep in mind that the model's performance on the test data should be close to the validation accuracy, as we used early stopping to prevent overfitting during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1127fc9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6face89f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
